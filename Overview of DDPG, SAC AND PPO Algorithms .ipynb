{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HWmQAy8EbGCk"
   },
   "source": [
    "### **INTRODUCTION**\n",
    "In the sections below, we cover in depth analysis of some Model- free   RL algorithms such as  Deep Deterministic Policy Gradient Algorithm, Proximal Policy Optimization Algorithm, Soft actor critic algorithms on Mountain-Car Open-AI Gym environment and provide a comparative study of performance with respect to random actions. We have explained terminologies and mechanism of each of the algorithms encompassing intuition, necessity, advantages and probable disadvantages wherever possible.  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hUcWKzbLjiS5"
   },
   "source": [
    "### **ENVIRONMENT:** \n",
    "**Open AI Gym \"MountainCarContinuous-v0\"**\n",
    "\n",
    "An underpowered car must climb a one-dimensional hill to reach a target. Unlike MountainCar v0, the action (engine force applied) is allowed to be a continuous value.\n",
    "\n",
    "The target is on top of a hill on the right-hand side of the car. If the car reaches it or goes beyond, the episode terminates.\n",
    "\n",
    "On the left-hand side, there is another hill. Climbing this hill can be used to gain potential energy and accelerate towards the target. On top of this second hill, the car cannot go further than a position equal to -1, as if there was a wall. Hitting this limit does not generate a penalty (it might in a more challenging version).\n",
    "\n",
    "\n",
    " **States:**\n",
    "\n",
    " Num  |\tObservation |\tMin    |\tMax \n",
    "--- | ---| ---| ---\n",
    " 0   |\tCarPosition |\t-1.2   |\t0.6\n",
    "  1   |\tCarVelocity |-0.07   |\t0.07\n",
    "\n",
    " **Actions**\n",
    "\n",
    "  Num|\tAction\n",
    "--- |---\n",
    "0\t| Push car to the left (negative value) or to the right (positive value)\n",
    "\n",
    "**Rewards**\n",
    "\n",
    "Reward is 100 for reaching the target of the hill on the right hand side, minus the squared sum of actions from start to goal.\n",
    "\n",
    "This reward function raises an exploration challenge, because if the agent does not reach the target soon enough, it will figure out that it is better not to move, and won't find the target anymore.\n",
    "\n",
    "Note that this reward is unusual with respect to most published work, where the goal was to reach the target as fast as possible, hence favouring a bang-bang strategy.\n",
    "\n",
    "\n",
    "**Starting State** \n",
    "\n",
    "Position between -0.6 and -0.4, null velocity.\n",
    "\n",
    "**Episode Termination**\n",
    "\n",
    "Position equal to 0.5. A constraint on velocity might be added in a more challenging version.\n",
    "\n",
    "Adding a maximum number of steps might be a good idea.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B0OtIokbrS3Q"
   },
   "source": [
    "### Starting with Random actions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K5nMYHPH5Y-B"
   },
   "outputs": [],
   "source": [
    "!pip install stable-baselines[mpi]\n",
    "!apt install swig cmake libopenmpi-dev zlib1g-dev\n",
    "!pip install stable-baselines[mpi]==2.8.0 box2d box2d-kengz\n",
    "# Stable Baselines only supports tensorflow 1.x for now\n",
    "%tensorflow_version 1.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6_pm2JlXXsRR"
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wdIigvE0GDRR"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from stable_baselines.ddpg.policies import  MlpPolicy, CnnPolicy\n",
    "from stable_baselines.bench import Monitor\n",
    "from stable_baselines.results_plotter import load_results, ts2xy\n",
    "from stable_baselines import DDPG, PPO2, PPO1, SAC\n",
    "from stable_baselines.ddpg import  AdaptiveParamNoiseSpec, NormalActionNoise, OrnsteinUhlenbeckActionNoise\n",
    "from stable_baselines import results_plotter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "esTLiajlQHHP"
   },
   "outputs": [],
   "source": [
    "# Create log dir to store information of states, actions, rewards, new states in files \n",
    "log_dir = \"tmp/\"\n",
    "os.makedirs(log_dir, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HoINFKbRlp8q"
   },
   "source": [
    "### Baseline by choosing random actions at all states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "colab_type": "code",
    "id": "jLdDJvRhv6WT",
    "outputId": "9bdb452a-2476-4257-f611-2cf83c9f95f4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Rewards')"
      ]
     },
     "execution_count": 64,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#create the environment\n",
    "env = gym.make('MountainCarContinuous-v0')\n",
    "n_games = 1000 #number of Episodes\n",
    "rewards = np.zeros(n_games)\n",
    "#Iterating through all episodes\n",
    "for i in range(n_games):\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    episode_reward = 0\n",
    "    #Stop when done is randomly set to true\n",
    "    while not done:\n",
    "      #Take action by sampling from action space randomly\n",
    "        action = env.action_space.sample()\n",
    "        # Update new state and keep count of rewards and check status of done\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        episode_reward += reward\n",
    "        #env.render()\n",
    "    rewards[i] = episode_reward\n",
    "# Plot progress of agent across all episodes.\n",
    "plt.plot(rewards)\n",
    "plt.xlabel('Episode number')\n",
    "plt.ylabel('Rewards')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sdNtVqg5mzIc"
   },
   "source": [
    "We see that agent almost never reches goal state. In instances that it does reach goal state, it never learns anything and it is not doing specifically good after running for any number of episodes\n",
    "Mountain car gives positive reward only when we reach the goal state so for calculating past 100 rewards we must achieve a score of averaging to near 0 from negative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cRpDPg1Sj_IR"
   },
   "source": [
    "### **Policy:**\n",
    "\n",
    "A Mapping function from states to actions or action probabilities\n",
    "\n",
    "\n",
    "### **Q-Learning**\n",
    "In Q-Learning we  improvise the  value estimate of the  different actions.\n",
    "\n",
    "#### **Disadvantages**\n",
    "*  Q-learning Fails on many simple problems\n",
    "*  Q-Learning uses  deterministic policy and does particularly bad on nvironments using stochastic policies. \n",
    "*  Q learning also doesn't have an intrinsic  exploration strategy but requires us to use inefficient ϵpsilon-greedy exploration\n",
    "*  Q-Learning handles continous actions  relatively poorly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5MjYWhU-yv_K"
   },
   "source": [
    "\n",
    "### **Policy Gradient Methods:**\n",
    "Policy gradient methods uses  gradients with respect to the policy itself thereby constantly improving the policy.\n",
    "\n",
    "#### **Overview** \n",
    "\n",
    "Let $π_θ(a|s)$ represent the probability of taking action a in state s under policy $π$. θ represents the parameters of our policy (the weights of our neural network).\n",
    "\n",
    "We update θ to values optimizes $π_θ$  policy. Because θ  changes, we  use the notation $θ_t$ to represent θ at iteration t. We hence strive to find update rule from $θ_t$ to $θ_{t+1}$ to aid us reach optimal policy.\n",
    "\n",
    "This policy can be represented as a neural network where action space is discrete and output is softmax(probability of taking each action , all sum to one)\n",
    "\n",
    "If we assume that a* is most optimal action, we must acheive \n",
    "$π_θ(a*|s)$ maximum(very close to one).\n",
    "\n",
    "We use gradient ascent algorithm :\n",
    "\n",
    ">$θ_{t+1} = θ_{t}+ α∇π_{θ_t}(a*|s)$\n",
    "\n",
    "The goal here is to increase the value of \n",
    ">$π_{θ_t}(a∗|s)$\n",
    "\n",
    "i.e, probability of taking action a* in state s under optimal policy $π_{θ_t}$\n",
    "\n",
    "We guess values  of action a in state s as $Q̂ (s,a)$ that aids us to make guess values  for all actions in various states and hence change  to\n",
    "\n",
    ">$θ_{t+1} = θ_{t}+ αQ̂(s,a)∇π_{θ_t}(a|s)$\n",
    "\n",
    "#### **On Policy Correction**\n",
    "\n",
    "When we train our agent to update our policy, instead of randomly choosing actions and updating their values the agent tends to follow policy to update itself.\n",
    "On-policy training allows us to focus on more promising areas of state space however we might train wrongly based on bad initialisation of parameters of the policy network.\n",
    "The actions we initialise with higher probabilities of happening have heavy chance of getting picked up even after training the policy, hence we divide the gradients updating their values by their repective probabilities.\n",
    "\n",
    ">$θ_{t+1} = θ_{t}+ α\\frac{Q̂(s,a)∇π_{θ_t}(a|s)}{π_θ(a|s)}$\n",
    "\n",
    "By Chain rule where:\n",
    "\n",
    ">$∇lnf(x)=\\frac{∇f(x)}{f(x)}$\n",
    "\n",
    "Weight update rule becomes:\n",
    "\n",
    ">$θ_{t+1} = θ_{t}+ αQ̂(s,a)∇_θlogπ_θ(s|a)$\n",
    "\n",
    "We finally also update Q to A (advantage function) which we get to know how good or bad is to take the action by following the policy  by subtracting the value of following a policy $V(s)$ the agent incurs.\n",
    "\n",
    ">$A(s_t,a_t)= Q_w(s_t,a_t)- V(s_t)$\n",
    "\n",
    "\n",
    "The Policy Correction rule finally looks like(**Actor's job**):\n",
    ">$θ_{t+1} = θ_{t}+ αA(s,a)∇_θlogπ_θ(s|a)$\n",
    "\n",
    "#### **Disadvantages:**\n",
    "* High Variance\n",
    "* Delayed Reward\n",
    "* Sample inefficiency\n",
    "* Strong impact of learning rate on training\n",
    "Small learning rates causes vanishing gradients and large cause exploding gradients .\n",
    "* Vanilla Policy Gradient methods have very poor data efficiency and robustness(ability to do good on environments without much hyperparameter tuning)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jPgANjRCk2DM"
   },
   "source": [
    "\n",
    "#### **Actor Critic algorithm**\n",
    "\n",
    "Elaborating on Policy Gradient update rule, leads us to  a Q-Actor Critic algorithm where the gradient can be expressed as \n",
    "\n",
    ">![alt text](https://miro.medium.com/max/1400/1*YQqZyAJ1QehPXFW36TKwmw.png)\n",
    "\n",
    "where $E_t[. . .]$ indicates the empirical average over a finite batch of samples, in an\n",
    "algorithm that alternates between sampling and optimization\n",
    "\n",
    "Further Decomposing the expression we get:\n",
    "\n",
    ">![alt text](https://miro.medium.com/max/1400/1*p0R0jWEaUAk2CEo-rk7MrQ.png)\n",
    "\n",
    "Since the expectation is nothing but Q value we arrive at \n",
    "\n",
    ">![alt text](https://miro.medium.com/max/1400/1*JYp-uQrMJKEHadx4RBrR1A.png)\n",
    "\n",
    "since,\n",
    "\n",
    "$Q(s_t,a_t)= E[r_{t+1} + \\gamma{V_v(s_{t+1})}]$  \n",
    "\n",
    "Hence advantage function becomes(**Critic evaluates this**):\n",
    "\n",
    "$A(s_t,a_t)=r_{t+1}+ \\gamma{V_v(s_{t+1})}- V_v{s_t}$\n",
    "\n",
    "![alt text](https://miro.medium.com/max/1400/1*pjE0o_wWTdcjprdDQFnwog.png)  \n",
    "\n",
    "**As discussed earlier the policy network updates uses a \"Critic\" to estimate value function( Q value or  V value or A value) and an \"actor\" updates policy distributions on policy network(The weights)**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5EzIdJBYmmRP"
   },
   "source": [
    "#### **DDPG (Deep Deterministic Policy Gradients)**\n",
    "DDPG helps a great deal to solve problems having **continuous action spaces**.These include problems where controls are required like car driving etc.If we discretize action space it becomes way too large for storage.\n",
    "DDPG follows actor-critic architecture.\n",
    "DDPG is also an **Off-Policy** learning algorithm which means that it can utilise information of another policy to update its policy. \n",
    "\n",
    "It also uses \n",
    "* **Experience relay:**\n",
    "  A buffer of fixed number of past experiences. This records past states, actions taken, respective rewards receieved, next changed state.\n",
    "Past experiences are thus saved as trajectory in replay buffers.\n",
    "No matter how bad policy we start off with there is some positive reward because of these learnings of replay buffer.We sample  a batch of fixed instances(mini-batches) from this buffer during training, Over time, owing to function optimisation power of deep neural networks, we are able to reach Goal states, as we update value and policy networks, faster while learning previous experiences.\n",
    "\n",
    "\n",
    "* **Seperate target network**\n",
    "A second network is used to generate target Q values and compute loss for every action while training. Since the Q network has a very fluctuating behaviour while training, destabilisation is likeliy between estimated Q values and target Q values and in order to solve this , target Q network is kept fixed with slow,time-delayed perodic updates from different function/network.\n",
    "\n",
    "Hence its, architecture consists of a Q network $(\\theta^Q)$, a deterministic policy network $(\\theta^{\\mu})$, a target Q network$(\\theta^{Q'})$ and a target policy network$$(\\theta^{\\mu'})$$\n",
    "Here Qnetwrk and policy network follow Advantage Actor-Critic architecture\n",
    "\n",
    "In DDPG we add noise  on parameter space and action space using Ornstein-Uhlenbeck Process which results in a  noise that is correlated with the previous noise, so as to avoid the noise from canceling out or “freezing” the overall dynamics  .\n",
    "\n",
    "It can be explained as follows:\n",
    "\n",
    "\n",
    "![alt text](https://miro.medium.com/max/1400/1*qV8STzz6mEYIKjOXyibtrQ.png)\n",
    "\n",
    "\n",
    "\n",
    "Simplistically, we initialise parameters in target network and policy network and also actors (update policy) updating these networks. Further we explore and store experiences in  Experience relay and use batches from relay buffer to further train networks and update policy.\n",
    "Minimize loss (KL Divergence) of target w.r.t. expected distribution of action probabilities. Finally, we update target networks after some time instances through separate target network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cPfnpBqrJqNo"
   },
   "outputs": [],
   "source": [
    "def evaluate(model, num_steps=1000):\n",
    "  \"\"\"\n",
    "  Function to evaluate an RL agent\n",
    "  here ,\n",
    "  :param model: (BaseRLModel object) the RL Agent that has learned a Target Policy and Behavioral(exploration) policy\n",
    "  :param num_steps: (int) number of timesteps to evaluate it\n",
    "  :return: (float) Mean reward for the last 100 episodes\n",
    "  \"\"\"\n",
    "  episoderewards = []\n",
    "  obs = env.reset()\n",
    "  for i in range(num_steps):\n",
    "      # _states are only useful when using LSTM policies\n",
    "      action, _states = model.predict(obs)\n",
    "      # here, action, rewards and dones are arrays\n",
    "      # because we are using vectorized env\n",
    "      obs, rewards, dones, info = env.step(action)\n",
    "      \n",
    "      # Stats\n",
    "      episoderewards.append(rewards)\n",
    "      if dones:\n",
    "          obs = env.reset()\n",
    "          episoderewards.append(0.0)\n",
    "  # Compute mean reward for the last 100 episodes\n",
    "  mean_100_episode_reward = round(np.mean(episoderewards[-100:]), 1)\n",
    "  print(\"Mean reward:\", mean_100_episode_reward, \"Num episodes:\", len(episoderewards))\n",
    "  \n",
    "  return mean_100_episode_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7HhKb9RuWhD9"
   },
   "outputs": [],
   "source": [
    "best_mean_reward, n_steps = -np.inf, 0\n",
    "\n",
    "def callback(_locals, _globals):\n",
    "    \"\"\"\n",
    "    Callback called at each step (for DQN an others) or after n steps (see ACER or PPO2)\n",
    "    :param _locals: (dict)\n",
    "    :param _globals: (dict)\n",
    "    \"\"\"\n",
    "    global n_steps, best_mean_reward\n",
    "    # Print stats every 1000 calls\n",
    "    if (n_steps + 1) % 1000 == 0:\n",
    "        # Evaluate policy training performance\n",
    "        x, y = ts2xy(load_results(log_dir), 'timesteps')\n",
    "        if len(x) > 0:\n",
    "            mean_reward = np.mean(y[-100:])\n",
    "            print(x[-1], 'timesteps')\n",
    "            print(\"Best mean reward: {:.2f} - Last mean reward per episode: {:.2f}\".format(best_mean_reward, mean_reward))\n",
    "\n",
    "            # New best model, you could save the agent here\n",
    "            if mean_reward > best_mean_reward:\n",
    "                best_mean_reward = mean_reward\n",
    "                # Example for saving best model\n",
    "                print(\"Saving new best model\")\n",
    "                _locals['self'].save(log_dir + 'best_model.pkl')\n",
    "    n_steps += 1\n",
    "    return True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OAFe1uHBId9P"
   },
   "outputs": [],
   "source": [
    "def moving_average(values, window):\n",
    "    \"\"\"\n",
    "    Smooth values by doing a moving average\n",
    "    :param values: (numpy array)\n",
    "    :param window: (int)\n",
    "    :return: (numpy array)\n",
    "    \"\"\"\n",
    "    weights = np.repeat(1.0, window) / window\n",
    "    return np.convolve(values, weights, 'valid')\n",
    "\n",
    "\n",
    "def plot_results(log_folder, title='Learning Curve'):\n",
    "    \"\"\"\n",
    "    plot the results\n",
    "\n",
    "    :param log_folder: (str) the save location of the results to plot\n",
    "    :param title: (str) the title of the task to plot\n",
    "    \"\"\"\n",
    "    x, y = ts2xy(load_results(log_folder), 'timesteps')\n",
    "    y = moving_average(y, window=50)\n",
    "    # Truncate x\n",
    "    x = x[len(x) - len(y):]\n",
    "\n",
    "    fig = plt.figure(title)\n",
    "    plt.plot(x, y)\n",
    "    plt.xlabel('Number of Timesteps')\n",
    "    plt.ylabel('Rewards')\n",
    "    plt.title(title + \" Smoothed\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "gjIp_Y5ZQLM6",
    "outputId": "1e1794a4-c79b-4c36-c73b-79ee3e07066c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create and wrap the environment\n",
    "env = gym.make('MountainCarContinuous-v0')\n",
    "n_actions = env.action_space.shape[-1]\n",
    "env = Monitor(env, log_dir, allow_early_resets=True)\n",
    "\n",
    "param_noise = None\n",
    "action_noise = NormalActionNoise(mean=np.zeros(n_actions), sigma=float(0.2) * np.ones(n_actions))\n",
    "model = DDPG(MlpPolicy, env, verbose=1, param_noise=param_noise, action_noise=action_noise)\n",
    "# Train the agent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "-29nMpGuVcFO",
    "outputId": "c86d170d-193f-461d-d633-ec39dff9ec2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30969 timesteps\n",
      "Best mean reward: -0.38 - Last mean reward per episode: -1.40\n",
      "31968 timesteps\n",
      "Best mean reward: -0.38 - Last mean reward per episode: -1.49\n",
      "32967 timesteps\n",
      "Best mean reward: -0.38 - Last mean reward per episode: -1.56\n",
      "33966 timesteps\n",
      "Best mean reward: -0.38 - Last mean reward per episode: -1.64\n",
      "34965 timesteps\n",
      "Best mean reward: -0.38 - Last mean reward per episode: -1.71\n",
      "35964 timesteps\n",
      "Best mean reward: -0.38 - Last mean reward per episode: -1.77\n",
      "36963 timesteps\n",
      "Best mean reward: -0.38 - Last mean reward per episode: -1.82\n",
      "37962 timesteps\n",
      "Best mean reward: -0.38 - Last mean reward per episode: -1.88\n",
      "38961 timesteps\n",
      "Best mean reward: -0.38 - Last mean reward per episode: -1.93\n",
      "39960 timesteps\n",
      "Best mean reward: -0.38 - Last mean reward per episode: -1.98\n",
      "--------------------------------------\n",
      "| reference_Q_mean        | -0.00311 |\n",
      "| reference_Q_std         | 0.00805  |\n",
      "| reference_action_mean   | -0.0186  |\n",
      "| reference_action_std    | 0.000621 |\n",
      "| reference_actor_Q_mean  | 0.00169  |\n",
      "| reference_actor_Q_std   | 5.28e-05 |\n",
      "| rollout/Q_mean          | 0.00187  |\n",
      "| rollout/actions_mean    | -0.0137  |\n",
      "| rollout/actions_std     | 0.199    |\n",
      "| rollout/episode_steps   | 999      |\n",
      "| rollout/episodes        | 10       |\n",
      "| rollout/return          | -3.97    |\n",
      "| rollout/return_history  | -3.97    |\n",
      "| total/duration          | 23.5     |\n",
      "| total/episodes          | 10       |\n",
      "| total/epochs            | 1        |\n",
      "| total/steps             | 9998     |\n",
      "| total/steps_per_second  | 425      |\n",
      "| train/loss_actor        | -0.00176 |\n",
      "| train/loss_critic       | 1.65e-08 |\n",
      "| train/param_noise_di... | 0        |\n",
      "--------------------------------------\n",
      "\n",
      "40959 timesteps\n",
      "Best mean reward: -0.38 - Last mean reward per episode: -2.02\n",
      "41958 timesteps\n",
      "Best mean reward: -0.38 - Last mean reward per episode: -2.07\n",
      "42957 timesteps\n",
      "Best mean reward: -0.38 - Last mean reward per episode: -2.12\n",
      "43956 timesteps\n",
      "Best mean reward: -0.38 - Last mean reward per episode: -2.17\n",
      "44955 timesteps\n",
      "Best mean reward: -0.38 - Last mean reward per episode: -2.21\n",
      "45954 timesteps\n",
      "Best mean reward: -0.38 - Last mean reward per episode: -2.26\n",
      "46953 timesteps\n",
      "Best mean reward: -0.38 - Last mean reward per episode: -2.30\n",
      "47952 timesteps\n",
      "Best mean reward: -0.38 - Last mean reward per episode: -2.33\n",
      "48951 timesteps\n",
      "Best mean reward: -0.38 - Last mean reward per episode: -2.36\n",
      "49950 timesteps\n",
      "Best mean reward: -0.38 - Last mean reward per episode: -2.39\n",
      "--------------------------------------\n",
      "| reference_Q_mean        | -0.00319 |\n",
      "| reference_Q_std         | 0.00801  |\n",
      "| reference_action_mean   | -0.0223  |\n",
      "| reference_action_std    | 0.00126  |\n",
      "| reference_actor_Q_mean  | 0.00155  |\n",
      "| reference_actor_Q_std   | 4.14e-05 |\n",
      "| rollout/Q_mean          | 0.00175  |\n",
      "| rollout/actions_mean    | -0.00635 |\n",
      "| rollout/actions_std     | 0.2      |\n",
      "| rollout/episode_steps   | 999      |\n",
      "| rollout/episodes        | 20       |\n",
      "| rollout/return          | -4.01    |\n",
      "| rollout/return_history  | -4.01    |\n",
      "| total/duration          | 47.5     |\n",
      "| total/episodes          | 20       |\n",
      "| total/epochs            | 1        |\n",
      "| total/steps             | 19998    |\n",
      "| total/steps_per_second  | 421      |\n",
      "| train/loss_actor        | -0.00154 |\n",
      "| train/loss_critic       | 8.36e-09 |\n",
      "| train/param_noise_di... | 0        |\n",
      "--------------------------------------\n",
      "\n",
      "50949 timesteps\n",
      "Best mean reward: -0.38 - Last mean reward per episode: -2.43\n",
      "51948 timesteps\n",
      "Best mean reward: -0.38 - Last mean reward per episode: -2.45\n",
      "52947 timesteps\n",
      "Best mean reward: -0.38 - Last mean reward per episode: -2.48\n",
      "53946 timesteps\n",
      "Best mean reward: -0.38 - Last mean reward per episode: -2.50\n",
      "54945 timesteps\n",
      "Best mean reward: -0.38 - Last mean reward per episode: -2.53\n",
      "55944 timesteps\n",
      "Best mean reward: -0.38 - Last mean reward per episode: -2.56\n",
      "56943 timesteps\n",
      "Best mean reward: -0.38 - Last mean reward per episode: -2.58\n",
      "57942 timesteps\n",
      "Best mean reward: -0.38 - Last mean reward per episode: -2.60\n",
      "58941 timesteps\n",
      "Best mean reward: -0.38 - Last mean reward per episode: -2.63\n",
      "59940 timesteps\n",
      "Best mean reward: -0.38 - Last mean reward per episode: -2.65\n",
      "---------------------------------------\n",
      "| reference_Q_mean        | -0.00323  |\n",
      "| reference_Q_std         | 0.00805   |\n",
      "| reference_action_mean   | -0.000262 |\n",
      "| reference_action_std    | 0.00127   |\n",
      "| reference_actor_Q_mean  | 0.0016    |\n",
      "| reference_actor_Q_std   | 5.33e-05  |\n",
      "| rollout/Q_mean          | 0.00167   |\n",
      "| rollout/actions_mean    | -0.0101   |\n",
      "| rollout/actions_std     | 0.2       |\n",
      "| rollout/episode_steps   | 999       |\n",
      "| rollout/episodes        | 30        |\n",
      "| rollout/return          | -3.99     |\n",
      "| rollout/return_history  | -3.99     |\n",
      "| total/duration          | 71.5      |\n",
      "| total/episodes          | 30        |\n",
      "| total/epochs            | 1         |\n",
      "| total/steps             | 29998     |\n",
      "| total/steps_per_second  | 420       |\n",
      "| train/loss_actor        | -0.00157  |\n",
      "| train/loss_critic       | 1.24e-08  |\n",
      "| train/param_noise_di... | 0         |\n",
      "---------------------------------------\n",
      "\n",
      "60939 timesteps\n",
      "Best mean reward: -0.38 - Last mean reward per episode: -2.67\n",
      "61938 timesteps\n",
      "Best mean reward: -0.38 - Last mean reward per episode: -2.69\n",
      "62937 timesteps\n",
      "Best mean reward: -0.38 - Last mean reward per episode: -2.72\n",
      "63936 timesteps\n",
      "Best mean reward: -0.38 - Last mean reward per episode: -2.74\n",
      "64935 timesteps\n",
      "Best mean reward: -0.38 - Last mean reward per episode: -2.75\n",
      "65934 timesteps\n",
      "Best mean reward: -0.38 - Last mean reward per episode: -2.78\n",
      "66933 timesteps\n",
      "Best mean reward: -0.38 - Last mean reward per episode: -2.80\n",
      "67932 timesteps\n",
      "Best mean reward: -0.38 - Last mean reward per episode: -2.81\n",
      "68931 timesteps\n",
      "Best mean reward: -0.38 - Last mean reward per episode: -2.83\n",
      "69930 timesteps\n",
      "Best mean reward: -0.38 - Last mean reward per episode: -2.85\n",
      "--------------------------------------\n",
      "| reference_Q_mean        | -0.00313 |\n",
      "| reference_Q_std         | 0.00806  |\n",
      "| reference_action_mean   | 0.0237   |\n",
      "| reference_action_std    | 0.0034   |\n",
      "| reference_actor_Q_mean  | 0.00163  |\n",
      "| reference_actor_Q_std   | 0.000108 |\n",
      "| rollout/Q_mean          | 0.00167  |\n",
      "| rollout/actions_mean    | -0.00522 |\n",
      "| rollout/actions_std     | 0.2      |\n",
      "| rollout/episode_steps   | 999      |\n",
      "| rollout/episodes        | 40       |\n",
      "| rollout/return          | -4       |\n",
      "| rollout/return_history  | -4       |\n",
      "| total/duration          | 95.4     |\n",
      "| total/episodes          | 40       |\n",
      "| total/epochs            | 1        |\n",
      "| total/steps             | 39998    |\n",
      "| total/steps_per_second  | 419      |\n",
      "| train/loss_actor        | -0.00165 |\n",
      "| train/loss_critic       | 8.93e-09 |\n",
      "| train/param_noise_di... | 0        |\n",
      "--------------------------------------\n",
      "\n",
      "70929 timesteps\n",
      "Best mean reward: -0.38 - Last mean reward per episode: -2.86\n",
      "71928 timesteps\n",
      "Best mean reward: -0.38 - Last mean reward per episode: -2.88\n",
      "72927 timesteps\n",
      "Best mean reward: -0.38 - Last mean reward per episode: -2.90\n",
      "73926 timesteps\n",
      "Best mean reward: -0.38 - Last mean reward per episode: -2.91\n",
      "74925 timesteps\n",
      "Best mean reward: -0.38 - Last mean reward per episode: -2.93\n",
      "75924 timesteps\n",
      "Best mean reward: -0.38 - Last mean reward per episode: -2.94\n",
      "76923 timesteps\n",
      "Best mean reward: -0.38 - Last mean reward per episode: -2.95\n",
      "77922 timesteps\n",
      "Best mean reward: -0.38 - Last mean reward per episode: -2.97\n",
      "78921 timesteps\n",
      "Best mean reward: -0.38 - Last mean reward per episode: -2.98\n",
      "79920 timesteps\n",
      "Best mean reward: -0.38 - Last mean reward per episode: -3.00\n",
      "--------------------------------------\n",
      "| reference_Q_mean        | -0.00331 |\n",
      "| reference_Q_std         | 0.00803  |\n",
      "| reference_action_mean   | -0.0227  |\n",
      "| reference_action_std    | 0.00065  |\n",
      "| reference_actor_Q_mean  | 0.00149  |\n",
      "| reference_actor_Q_std   | 0.000151 |\n",
      "| rollout/Q_mean          | 0.00164  |\n",
      "| rollout/actions_mean    | -0.00447 |\n",
      "| rollout/actions_std     | 0.2      |\n",
      "| rollout/episode_steps   | 999      |\n",
      "| rollout/episodes        | 50       |\n",
      "| rollout/return          | -4.01    |\n",
      "| rollout/return_history  | -4.01    |\n",
      "| total/duration          | 119      |\n",
      "| total/episodes          | 50       |\n",
      "| total/epochs            | 1        |\n",
      "| total/steps             | 49998    |\n",
      "| total/steps_per_second  | 418      |\n",
      "| train/loss_actor        | -0.00147 |\n",
      "| train/loss_critic       | 3.45e-08 |\n",
      "| train/param_noise_di... | 0        |\n",
      "--------------------------------------\n",
      "\n",
      "80919 timesteps\n",
      "Best mean reward: -0.38 - Last mean reward per episode: -3.01\n",
      "81918 timesteps\n",
      "Best mean reward: -0.38 - Last mean reward per episode: -3.02\n",
      "82917 timesteps\n",
      "Best mean reward: -0.38 - Last mean reward per episode: -3.04\n",
      "83916 timesteps\n",
      "Best mean reward: -0.38 - Last mean reward per episode: -3.05\n",
      "84915 timesteps\n",
      "Best mean reward: -0.38 - Last mean reward per episode: -3.06\n",
      "85914 timesteps\n",
      "Best mean reward: -0.38 - Last mean reward per episode: -3.07\n",
      "86913 timesteps\n",
      "Best mean reward: -0.38 - Last mean reward per episode: -3.08\n",
      "87912 timesteps\n",
      "Best mean reward: -0.38 - Last mean reward per episode: -3.10\n",
      "88911 timesteps\n",
      "Best mean reward: -0.38 - Last mean reward per episode: -3.10\n",
      "89910 timesteps\n",
      "Best mean reward: -0.38 - Last mean reward per episode: -3.11\n",
      "--------------------------------------\n",
      "| reference_Q_mean        | -0.00315 |\n",
      "| reference_Q_std         | 0.00801  |\n",
      "| reference_action_mean   | -0.0195  |\n",
      "| reference_action_std    | 0.00026  |\n",
      "| reference_actor_Q_mean  | 0.00166  |\n",
      "| reference_actor_Q_std   | 0.000186 |\n",
      "| rollout/Q_mean          | 0.00162  |\n",
      "| rollout/actions_mean    | -0.00749 |\n",
      "| rollout/actions_std     | 0.2      |\n",
      "| rollout/episode_steps   | 999      |\n",
      "| rollout/episodes        | 60       |\n",
      "| rollout/return          | -4.01    |\n",
      "| rollout/return_history  | -4.01    |\n",
      "| total/duration          | 145      |\n",
      "| total/episodes          | 60       |\n",
      "| total/epochs            | 1        |\n",
      "| total/steps             | 59998    |\n",
      "| total/steps_per_second  | 415      |\n",
      "| train/loss_actor        | -0.00159 |\n",
      "| train/loss_critic       | 9.09e-09 |\n",
      "| train/param_noise_di... | 0        |\n",
      "--------------------------------------\n",
      "\n",
      "90909 timesteps\n",
      "Best mean reward: -0.38 - Last mean reward per episode: -3.12\n",
      "91908 timesteps\n",
      "Best mean reward: -0.38 - Last mean reward per episode: -3.14\n",
      "92907 timesteps\n",
      "Best mean reward: -0.38 - Last mean reward per episode: -3.15\n",
      "93906 timesteps\n",
      "Best mean reward: -0.38 - Last mean reward per episode: -3.16\n",
      "94905 timesteps\n",
      "Best mean reward: -0.38 - Last mean reward per episode: -3.17\n",
      "95904 timesteps\n",
      "Best mean reward: -0.38 - Last mean reward per episode: -3.18\n",
      "96903 timesteps\n",
      "Best mean reward: -0.38 - Last mean reward per episode: -3.19\n",
      "97902 timesteps\n",
      "Best mean reward: -0.38 - Last mean reward per episode: -3.19\n",
      "98901 timesteps\n",
      "Best mean reward: -0.38 - Last mean reward per episode: -3.20\n",
      "99900 timesteps\n",
      "Best mean reward: -0.38 - Last mean reward per episode: -3.21\n",
      "--------------------------------------\n",
      "| reference_Q_mean        | -0.00324 |\n",
      "| reference_Q_std         | 0.00804  |\n",
      "| reference_action_mean   | -0.0251  |\n",
      "| reference_action_std    | 0.000824 |\n",
      "| reference_actor_Q_mean  | 0.00153  |\n",
      "| reference_actor_Q_std   | 0.000209 |\n",
      "| rollout/Q_mean          | 0.00162  |\n",
      "| rollout/actions_mean    | -0.00899 |\n",
      "| rollout/actions_std     | 0.2      |\n",
      "| rollout/episode_steps   | 999      |\n",
      "| rollout/episodes        | 70       |\n",
      "| rollout/return          | -4.02    |\n",
      "| rollout/return_history  | -4.02    |\n",
      "| total/duration          | 169      |\n",
      "| total/episodes          | 70       |\n",
      "| total/epochs            | 1        |\n",
      "| total/steps             | 69998    |\n",
      "| total/steps_per_second  | 415      |\n",
      "| train/loss_actor        | -0.00163 |\n",
      "| train/loss_critic       | 9.76e-09 |\n",
      "| train/param_noise_di... | 0        |\n",
      "--------------------------------------\n",
      "\n",
      "100899 timesteps\n",
      "Best mean reward: -0.38 - Last mean reward per episode: -3.25\n",
      "101898 timesteps\n",
      "Best mean reward: -0.38 - Last mean reward per episode: -3.29\n",
      "102897 timesteps\n",
      "Best mean reward: -0.38 - Last mean reward per episode: -3.33\n",
      "103896 timesteps\n",
      "Best mean reward: -0.38 - Last mean reward per episode: -3.37\n",
      "104895 timesteps\n",
      "Best mean reward: -0.38 - Last mean reward per episode: -3.41\n",
      "105894 timesteps\n",
      "Best mean reward: -0.38 - Last mean reward per episode: -3.45\n",
      "106893 timesteps\n",
      "Best mean reward: -0.38 - Last mean reward per episode: -3.50\n",
      "107892 timesteps\n",
      "Best mean reward: -0.38 - Last mean reward per episode: -3.54\n",
      "108891 timesteps\n",
      "Best mean reward: -0.38 - Last mean reward per episode: -3.58\n",
      "109890 timesteps\n",
      "Best mean reward: -0.38 - Last mean reward per episode: -3.62\n",
      "--------------------------------------\n",
      "| reference_Q_mean        | -0.00325 |\n",
      "| reference_Q_std         | 0.00803  |\n",
      "| reference_action_mean   | -0.027   |\n",
      "| reference_action_std    | 0.000538 |\n",
      "| reference_actor_Q_mean  | 0.00153  |\n",
      "| reference_actor_Q_std   | 0.000196 |\n",
      "| rollout/Q_mean          | 0.00161  |\n",
      "| rollout/actions_mean    | -0.0118  |\n",
      "| rollout/actions_std     | 0.201    |\n",
      "| rollout/episode_steps   | 999      |\n",
      "| rollout/episodes        | 80       |\n",
      "| rollout/return          | -4.04    |\n",
      "| rollout/return_history  | -4.04    |\n",
      "| total/duration          | 193      |\n",
      "| total/episodes          | 80       |\n",
      "| total/epochs            | 1        |\n",
      "| total/steps             | 79998    |\n",
      "| total/steps_per_second  | 415      |\n",
      "| train/loss_actor        | -0.00147 |\n",
      "| train/loss_critic       | 1.28e-08 |\n",
      "| train/param_noise_di... | 0        |\n",
      "--------------------------------------\n",
      "\n",
      "110889 timesteps\n",
      "Best mean reward: -0.38 - Last mean reward per episode: -3.62\n",
      "111888 timesteps\n",
      "Best mean reward: -0.38 - Last mean reward per episode: -3.63\n",
      "112887 timesteps\n",
      "Best mean reward: -0.38 - Last mean reward per episode: -3.63\n",
      "113886 timesteps\n",
      "Best mean reward: -0.38 - Last mean reward per episode: -3.63\n",
      "114885 timesteps\n",
      "Best mean reward: -0.38 - Last mean reward per episode: -3.63\n",
      "115884 timesteps\n",
      "Best mean reward: -0.38 - Last mean reward per episode: -3.63\n",
      "116883 timesteps\n",
      "Best mean reward: -0.38 - Last mean reward per episode: -3.63\n",
      "117882 timesteps\n",
      "Best mean reward: -0.38 - Last mean reward per episode: -3.63\n",
      "118881 timesteps\n",
      "Best mean reward: -0.38 - Last mean reward per episode: -3.64\n",
      "119880 timesteps\n",
      "Best mean reward: -0.38 - Last mean reward per episode: -3.64\n",
      "--------------------------------------\n",
      "| reference_Q_mean        | -0.00334 |\n",
      "| reference_Q_std         | 0.00802  |\n",
      "| reference_action_mean   | -0.0253  |\n",
      "| reference_action_std    | 0.000618 |\n",
      "| reference_actor_Q_mean  | 0.00145  |\n",
      "| reference_actor_Q_std   | 0.000196 |\n",
      "| rollout/Q_mean          | 0.00159  |\n",
      "| rollout/actions_mean    | -0.0132  |\n",
      "| rollout/actions_std     | 0.201    |\n",
      "| rollout/episode_steps   | 999      |\n",
      "| rollout/episodes        | 90       |\n",
      "| rollout/return          | -4.04    |\n",
      "| rollout/return_history  | -4.04    |\n",
      "| total/duration          | 217      |\n",
      "| total/episodes          | 90       |\n",
      "| total/epochs            | 1        |\n",
      "| total/steps             | 89998    |\n",
      "| total/steps_per_second  | 415      |\n",
      "| train/loss_actor        | -0.00137 |\n",
      "| train/loss_critic       | 7.19e-09 |\n",
      "| train/param_noise_di... | 0        |\n",
      "--------------------------------------\n",
      "\n",
      "120879 timesteps\n",
      "Best mean reward: -0.38 - Last mean reward per episode: -3.68\n",
      "121878 timesteps\n",
      "Best mean reward: -0.38 - Last mean reward per episode: -3.72\n",
      "122877 timesteps\n",
      "Best mean reward: -0.38 - Last mean reward per episode: -3.75\n",
      "123876 timesteps\n",
      "Best mean reward: -0.38 - Last mean reward per episode: -3.79\n",
      "124875 timesteps\n",
      "Best mean reward: -0.38 - Last mean reward per episode: -3.83\n",
      "125874 timesteps\n",
      "Best mean reward: -0.38 - Last mean reward per episode: -3.87\n",
      "126873 timesteps\n",
      "Best mean reward: -0.38 - Last mean reward per episode: -3.91\n",
      "127872 timesteps\n",
      "Best mean reward: -0.38 - Last mean reward per episode: -3.95\n",
      "128871 timesteps\n",
      "Best mean reward: -0.38 - Last mean reward per episode: -3.99\n",
      "129870 timesteps\n",
      "Best mean reward: -0.38 - Last mean reward per episode: -4.03\n",
      "--------------------------------------\n",
      "| reference_Q_mean        | -0.00345 |\n",
      "| reference_Q_std         | 0.00802  |\n",
      "| reference_action_mean   | -0.0272  |\n",
      "| reference_action_std    | 0.000932 |\n",
      "| reference_actor_Q_mean  | 0.00131  |\n",
      "| reference_actor_Q_std   | 0.000196 |\n",
      "| rollout/Q_mean          | 0.00157  |\n",
      "| rollout/actions_mean    | -0.0143  |\n",
      "| rollout/actions_std     | 0.2      |\n",
      "| rollout/episode_steps   | 999      |\n",
      "| rollout/episodes        | 100      |\n",
      "| rollout/return          | -4.03    |\n",
      "| rollout/return_history  | -4.03    |\n",
      "| total/duration          | 241      |\n",
      "| total/episodes          | 100      |\n",
      "| total/epochs            | 1        |\n",
      "| total/steps             | 99998    |\n",
      "| total/steps_per_second  | 414      |\n",
      "| train/loss_actor        | -0.00129 |\n",
      "| train/loss_critic       | 8.26e-09 |\n",
      "| train/param_noise_di... | 0        |\n",
      "--------------------------------------\n",
      "\n",
      "Mean reward: -0.0 Num episodes: 10010\n"
     ]
    }
   ],
   "source": [
    "time_steps = 100000\n",
    "model.learn(total_timesteps=int(time_steps), callback=callback)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "ZMdCmQD5WOhc",
    "outputId": "d0f79525-8652-4c56-c323-9e0e0e98ebed"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "results_plotter.plot_results([log_dir], time_steps, results_plotter.X_TIMESTEPS, \"DDPG MountainCar Continuous\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "colab_type": "code",
    "id": "P0QRnqLPIuUJ",
    "outputId": "1b1483f5-72b9-4af0-ee61-66d1ebc6f548"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_results(log_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NahwdKqNpFdP"
   },
   "source": [
    "### **PPO(Proximal Policy Optimisation)**\n",
    "PPO is a scalable(to large models and environments), data efficient and robust(does good on many problems without much hyperparameter tuning) method.\n",
    "\n",
    "With DDPGs the step size hyperparameter has to be tuned correctly for it to achieve good performance and if neglected that could lead to heavy Temporal Difference errors due to vanishing gradients or exploding gradients dependant on magnitude of step size.\n",
    "\n",
    "\n",
    "So far we know  gradient estimator, \n",
    "\n",
    ">$∇_θ J(θ) = ĝ = Ê_t[∇_θ log π_θ(a_t|s_t)Â_t]$\n",
    "\n",
    "Where all terms follow our definitions so far \n",
    "we arrive at $ĝ$ by differentiating:\n",
    "\n",
    ">$L^{PG}= Ê_t[ log π_θ(a_t|s_t)Â_t]$\n",
    "\n",
    "This optimisation of loss function defined while arriving at intuition of policy gradients essentially follows uniform trajectory that leads to large policy updates which we solve introducing TRPO on which PPO is based .\n",
    "\n",
    "#### **Overview of TRPO(Trust Region Policy optimisation)**\n",
    "When we add constraint to our policy optimization problem we ensure that the updated policy lies in trust region.\n",
    "For an entire problem, uniform learning rates are wrong idea.\n",
    "We hence create regions where local approximations hold true and call it trust region. Within a trust region we find local maxima of the policy and iteratively arrive at global maximum of the policy.\n",
    "\n",
    "\n",
    ">$ {maximize \\above 0pt \\ θ}   Ê_t [\\frac{π_θ(a_t| s_t)}{π_{θ_{old}}(a_t| s_t)}Â_t$\n",
    "\n",
    "subject to  \n",
    ">$ Ê_t [KL[π_{θ_{old}}(· | s_t), π_θ(· | s_t)]] ≤ δ{.} $\n",
    "\n",
    "where ${θ_{old}}$\n",
    " is policy parameters before update \n",
    "\n",
    "summarizing with pseudocode:\n",
    ">![alt text](https://miro.medium.com/max/1400/1*BzloIcgP8bTRMslarSQbHw@2x.jpeg)\n",
    "\n",
    "which leads to solving for :\n",
    "\n",
    ">$ {maximize \\above 0pt \\ θ}  Ê_t [\\frac{π_θ(a_t| s_t)}{π_{θ_{old}}(a_t| s_t)}Â_t - \\beta{KL[π_{θ_{old}}(· | s_t), π_θ(· | s_t)]}$\n",
    "\n",
    "We do this by solving using conjugate gradient algorithm(we repeatedly make approximations to sub problems to solve a problem) following linear approximation of the below objective and quadratic approximation of constraint described below by TRPO:\n",
    "\n",
    "\n",
    ">![alt text](https://miro.medium.com/max/1400/1*JspdI6fGh-Cv8OyfqmbwQg@2x.jpeg)\n",
    "\n",
    "Further, The Fisher Information matrix (F) gives information about how sensitive the probability distribution to different direction in parameter space.\n",
    "\n",
    "Computing hashing matrix is very expensive in complexity.\n",
    "\n",
    "We hence solve the problem approximately using conjugate gradient to solve $F.x = g$,  without creating  Fisher matrix $F$.\n",
    "\n",
    "TRPO hence uses a hard constraint  rather than penalty beacuse it is very difficult to find a single $\\beta$ for different problems or complex single problem.\n",
    "\n",
    "\n",
    "#### **Disadvantages/Limitations of TRPO:**\n",
    "* Trust Region Polcy optimisation is not good with noises, dropouts or parameter sharing between policy and value functions\n",
    "* Does poorly on deep CNN, RNN based tasks\n",
    "* Conjugate gradients very inefficient to implement and solve\n",
    "\n",
    "\n",
    "#### **Modifications to TRPO to get PPO**\n",
    "We perform additional modifications to TRPO  such as clipped probability ratios, which forms a pessimistic estimate (i.e., lower bound) of the performance of the policy and  optimizing policies, where we alternate between sampling data from the policy and performing several epochs of optimization on the sampled data to arrive at PPO.\n",
    "\n",
    " * **Clipped Surrogate Objective:**\n",
    "\n",
    "  In PPO we update the policy by minimising the cost function but we ensure that the drift from original policy is small to avoid heavy policy updates.\n",
    "\n",
    " Let probability ratio \n",
    " >$ r_t(θ) = [\\frac{π_θ(a_t| s_t)}{π_{θ_{old}}(a_t| s_t)}]$ \n",
    " \n",
    " such that\n",
    "  $ r(θ_{old})=1 $\n",
    "\n",
    "  Since we know TRPO maximises a \"surrogate objective\"\n",
    ">$L^{CPI}= Ê_t [\\frac{π_θ(a_t| s_t)}{π_{θ_{old}}(a_t| s_t)}Â_t] = Ê_t [r_t(θ)Â_t]$\n",
    "\n",
    "  where CPI is conservative policy iteration method (see TRPO paper)\n",
    "As without constraint $L^{CPI}$ performs large policy updates.\n",
    "in PPO it is suggesested to different constraint:\n",
    ">$L^{CLIP}(θ)= Ê_t [min (r_t(θ)Â_t, clip(r_t(θ), 1-\\epsilon, 1+\\epsilon)Â_t)]$\n",
    "\n",
    "  In addition to minimising TRPO loss, term 1 we modify surrogate objective by clipping the probability ratio. This effectively penalises large policy updates.\n",
    "\n",
    "  It can be demonstrated with the following graph:\n",
    ">![alt text](https://miro.medium.com/max/1400/1*a4M7thPEELKKeu4jjpGpiQ@2x.jpeg)\n",
    "\n",
    "\n",
    "* **Adaptive KL Penalty Coefficient**\n",
    "Another approach within PPO is using a penalty on KL divergergence that avoids heavy policy updates as well. We control the divergence to $d_{targ}$ value at each policy update\n",
    "This looks like \n",
    ">$L^{KLPEN}(θ)= Ê_t [(r_t(θ)Â_t- \\beta KL[π_{θ_{old}}(· | s_t), π_θ(· | s_t)]]$\n",
    "\n",
    "  We compute divergence value as \n",
    ">$d=Ê_t[KL[π_{θ_{old}}(· | s_t), π_θ(· | s_t)]]$\n",
    "\n",
    "  -If  $d< d_{targ}/1.5, \\beta \\longleftarrow \\beta/2 $ \n",
    "\n",
    "  -If  $d> d_{targ} * 1.5, \\beta \\longleftarrow \\beta * 2 $ \n",
    "\n",
    "  This is neither sensitive to heuristic values of 1.5 and 2 nor $\\beta$\n",
    "\n",
    "Summarizing this ,  In proximal policy optimization (PPO) algorithm we  use fixed-length trajectory segments as shown below. Each iteration, each of N (parallel) actors collect T timesteps of data. Then  the surrogate loss on these NT timesteps of data is constructed , and we optimize it with minibatch SGD\n",
    "(or usually for better performance, Adam ), for K epochs as shown in pseudocode below .\n",
    "\n",
    "#### **Pseudocode of PPO** \n",
    "\n",
    ">![alt text](https://i.stack.imgur.com/bVkQH.png)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "NxyfJiBWJzPa",
    "outputId": "9f858079-8f06-4428-d981-65a38bf8cde2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
      "| time_elapsed       | 41.1          |\n",
      "| total_timesteps    | 57344         |\n",
      "| value_loss         | 8.9124886e-05 |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0013350357 |\n",
      "| clipfrac           | 0.001953125  |\n",
      "| ep_len_mean        | 999          |\n",
      "| ep_reward_mean     | -24.5        |\n",
      "| explained_variance | -0.0612      |\n",
      "| fps                | 1441         |\n",
      "| n_updates          | 449          |\n",
      "| policy_entropy     | -0.057704695 |\n",
      "| policy_loss        | -0.00828281  |\n",
      "| serial_timesteps   | 57472        |\n",
      "| time_elapsed       | 41.2         |\n",
      "| total_timesteps    | 57472        |\n",
      "| value_loss         | 0.0001712795 |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 8.873448e-05  |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -24.5         |\n",
      "| explained_variance | -0.00802      |\n",
      "| fps                | 1450          |\n",
      "| n_updates          | 450           |\n",
      "| policy_entropy     | -0.06019079   |\n",
      "| policy_loss        | 0.0006741615  |\n",
      "| serial_timesteps   | 57600         |\n",
      "| time_elapsed       | 41.3          |\n",
      "| total_timesteps    | 57600         |\n",
      "| value_loss         | 0.00013826326 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0012031608  |\n",
      "| clipfrac           | 0.001953125   |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -24.5         |\n",
      "| explained_variance | 0.153         |\n",
      "| fps                | 1312          |\n",
      "| n_updates          | 451           |\n",
      "| policy_entropy     | -0.06293652   |\n",
      "| policy_loss        | -0.0051813014 |\n",
      "| serial_timesteps   | 57728         |\n",
      "| time_elapsed       | 41.4          |\n",
      "| total_timesteps    | 57728         |\n",
      "| value_loss         | 0.00012495909 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00029824616 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -24.5         |\n",
      "| explained_variance | -0.068        |\n",
      "| fps                | 1486          |\n",
      "| n_updates          | 452           |\n",
      "| policy_entropy     | -0.06633955   |\n",
      "| policy_loss        | -0.0025346675 |\n",
      "| serial_timesteps   | 57856         |\n",
      "| time_elapsed       | 41.5          |\n",
      "| total_timesteps    | 57856         |\n",
      "| value_loss         | 0.00011131259 |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 3.113212e-06 |\n",
      "| clipfrac           | 0.0          |\n",
      "| ep_len_mean        | 999          |\n",
      "| ep_reward_mean     | -24.2        |\n",
      "| explained_variance | -0.00406     |\n",
      "| fps                | 1470         |\n",
      "| n_updates          | 453          |\n",
      "| policy_entropy     | -0.06914014  |\n",
      "| policy_loss        | 0.0001291132 |\n",
      "| serial_timesteps   | 57984        |\n",
      "| time_elapsed       | 41.6         |\n",
      "| total_timesteps    | 57984        |\n",
      "| value_loss         | 0.0072032916 |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 4.0467594e-06  |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 999            |\n",
      "| ep_reward_mean     | -24.2          |\n",
      "| explained_variance | 0.233          |\n",
      "| fps                | 1344           |\n",
      "| n_updates          | 454            |\n",
      "| policy_entropy     | -0.07068366    |\n",
      "| policy_loss        | -0.00050530577 |\n",
      "| serial_timesteps   | 58112          |\n",
      "| time_elapsed       | 41.7           |\n",
      "| total_timesteps    | 58112          |\n",
      "| value_loss         | 0.00037107064  |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 5.0241008e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -24.2         |\n",
      "| explained_variance | -0.85         |\n",
      "| fps                | 1361          |\n",
      "| n_updates          | 455           |\n",
      "| policy_entropy     | -0.073873386  |\n",
      "| policy_loss        | -0.0012407615 |\n",
      "| serial_timesteps   | 58240         |\n",
      "| time_elapsed       | 41.8          |\n",
      "| total_timesteps    | 58240         |\n",
      "| value_loss         | 0.00028816078 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 3.4154797e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -24.2         |\n",
      "| explained_variance | -0.0168       |\n",
      "| fps                | 1263          |\n",
      "| n_updates          | 456           |\n",
      "| policy_entropy     | -0.07702178   |\n",
      "| policy_loss        | -0.0008574197 |\n",
      "| serial_timesteps   | 58368         |\n",
      "| time_elapsed       | 41.8          |\n",
      "| total_timesteps    | 58368         |\n",
      "| value_loss         | 0.00019996805 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 7.733779e-05  |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -24.2         |\n",
      "| explained_variance | 0.0223        |\n",
      "| fps                | 1324          |\n",
      "| n_updates          | 457           |\n",
      "| policy_entropy     | -0.08015206   |\n",
      "| policy_loss        | -0.0021595831 |\n",
      "| serial_timesteps   | 58496         |\n",
      "| time_elapsed       | 41.9          |\n",
      "| total_timesteps    | 58496         |\n",
      "| value_loss         | 0.0003612685  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 1.742659e-05  |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -24.2         |\n",
      "| explained_variance | -0.252        |\n",
      "| fps                | 1399          |\n",
      "| n_updates          | 458           |\n",
      "| policy_entropy     | -0.08349909   |\n",
      "| policy_loss        | -0.0006069548 |\n",
      "| serial_timesteps   | 58624         |\n",
      "| time_elapsed       | 42            |\n",
      "| total_timesteps    | 58624         |\n",
      "| value_loss         | 0.00018782905 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 9.406482e-05  |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -24.2         |\n",
      "| explained_variance | -0.23         |\n",
      "| fps                | 1350          |\n",
      "| n_updates          | 459           |\n",
      "| policy_entropy     | -0.08659474   |\n",
      "| policy_loss        | -0.0012971741 |\n",
      "| serial_timesteps   | 58752         |\n",
      "| time_elapsed       | 42.1          |\n",
      "| total_timesteps    | 58752         |\n",
      "| value_loss         | 0.00028305006 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 2.5623529e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -24.2         |\n",
      "| explained_variance | 0.206         |\n",
      "| fps                | 1426          |\n",
      "| n_updates          | 460           |\n",
      "| policy_entropy     | -0.09027451   |\n",
      "| policy_loss        | -0.0014269709 |\n",
      "| serial_timesteps   | 58880         |\n",
      "| time_elapsed       | 42.2          |\n",
      "| total_timesteps    | 58880         |\n",
      "| value_loss         | 0.00023310698 |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 2.8482873e-06  |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 999            |\n",
      "| ep_reward_mean     | -23.9          |\n",
      "| explained_variance | -0.017         |\n",
      "| fps                | 1428           |\n",
      "| n_updates          | 461            |\n",
      "| policy_entropy     | -0.09346318    |\n",
      "| policy_loss        | 1.39322365e-05 |\n",
      "| serial_timesteps   | 59008          |\n",
      "| time_elapsed       | 42.3           |\n",
      "| total_timesteps    | 59008          |\n",
      "| value_loss         | 0.008001673    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 9.673075e-06  |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -23.9         |\n",
      "| explained_variance | -0.145        |\n",
      "| fps                | 1300          |\n",
      "| n_updates          | 462           |\n",
      "| policy_entropy     | -0.09527625   |\n",
      "| policy_loss        | -0.0003658051 |\n",
      "| serial_timesteps   | 59136         |\n",
      "| time_elapsed       | 42.4          |\n",
      "| total_timesteps    | 59136         |\n",
      "| value_loss         | 0.0003445027  |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 7.3831397e-06  |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 999            |\n",
      "| ep_reward_mean     | -23.9          |\n",
      "| explained_variance | 0.0234         |\n",
      "| fps                | 1450           |\n",
      "| n_updates          | 463            |\n",
      "| policy_entropy     | -0.09767267    |\n",
      "| policy_loss        | -0.00085253105 |\n",
      "| serial_timesteps   | 59264          |\n",
      "| time_elapsed       | 42.5           |\n",
      "| total_timesteps    | 59264          |\n",
      "| value_loss         | 0.0001887192   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 7.824723e-06   |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 999            |\n",
      "| ep_reward_mean     | -23.9          |\n",
      "| explained_variance | -0.0852        |\n",
      "| fps                | 1489           |\n",
      "| n_updates          | 464            |\n",
      "| policy_entropy     | -0.10090386    |\n",
      "| policy_loss        | -0.00059356936 |\n",
      "| serial_timesteps   | 59392          |\n",
      "| time_elapsed       | 42.6           |\n",
      "| total_timesteps    | 59392          |\n",
      "| value_loss         | 0.00022451572  |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 1.9065952e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -23.9         |\n",
      "| explained_variance | 0.0273        |\n",
      "| fps                | 1453          |\n",
      "| n_updates          | 465           |\n",
      "| policy_entropy     | -0.104377925  |\n",
      "| policy_loss        | -0.0013403371 |\n",
      "| serial_timesteps   | 59520         |\n",
      "| time_elapsed       | 42.7          |\n",
      "| total_timesteps    | 59520         |\n",
      "| value_loss         | 0.00012944166 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 2.9088897e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -23.9         |\n",
      "| explained_variance | 0.165         |\n",
      "| fps                | 1418          |\n",
      "| n_updates          | 466           |\n",
      "| policy_entropy     | -0.1081826    |\n",
      "| policy_loss        | -0.000578146  |\n",
      "| serial_timesteps   | 59648         |\n",
      "| time_elapsed       | 42.8          |\n",
      "| total_timesteps    | 59648         |\n",
      "| value_loss         | 0.00016142946 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 1.2004275e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -23.9         |\n",
      "| explained_variance | 0.0423        |\n",
      "| fps                | 1371          |\n",
      "| n_updates          | 467           |\n",
      "| policy_entropy     | -0.111755006  |\n",
      "| policy_loss        | -0.0011400718 |\n",
      "| serial_timesteps   | 59776         |\n",
      "| time_elapsed       | 42.9          |\n",
      "| total_timesteps    | 59776         |\n",
      "| value_loss         | 0.0002694191  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 2.7173939e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -23.9         |\n",
      "| explained_variance | -0.0561       |\n",
      "| fps                | 1357          |\n",
      "| n_updates          | 468           |\n",
      "| policy_entropy     | -0.114994965  |\n",
      "| policy_loss        | -0.0009314931 |\n",
      "| serial_timesteps   | 59904         |\n",
      "| time_elapsed       | 43            |\n",
      "| total_timesteps    | 59904         |\n",
      "| value_loss         | 0.00019814678 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 6.677953e-05  |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -23.6         |\n",
      "| explained_variance | -0.00661      |\n",
      "| fps                | 1445          |\n",
      "| n_updates          | 469           |\n",
      "| policy_entropy     | -0.118400134  |\n",
      "| policy_loss        | -0.0012181016 |\n",
      "| serial_timesteps   | 60032         |\n",
      "| time_elapsed       | 43.1          |\n",
      "| total_timesteps    | 60032         |\n",
      "| value_loss         | 0.007228885   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 5.266016e-05   |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 999            |\n",
      "| ep_reward_mean     | -23.6          |\n",
      "| explained_variance | 0.157          |\n",
      "| fps                | 1487           |\n",
      "| n_updates          | 470            |\n",
      "| policy_entropy     | -0.12117209    |\n",
      "| policy_loss        | -0.0012118113  |\n",
      "| serial_timesteps   | 60160          |\n",
      "| time_elapsed       | 43.1           |\n",
      "| total_timesteps    | 60160          |\n",
      "| value_loss         | 0.000117002055 |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 1.3267548e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -23.6         |\n",
      "| explained_variance | -0.148        |\n",
      "| fps                | 1404          |\n",
      "| n_updates          | 471           |\n",
      "| policy_entropy     | -0.12487881   |\n",
      "| policy_loss        | -0.0010106311 |\n",
      "| serial_timesteps   | 60288         |\n",
      "| time_elapsed       | 43.2          |\n",
      "| total_timesteps    | 60288         |\n",
      "| value_loss         | 0.0002016373  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 1.8389735e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -23.6         |\n",
      "| explained_variance | -0.186        |\n",
      "| fps                | 1459          |\n",
      "| n_updates          | 472           |\n",
      "| policy_entropy     | -0.12878916   |\n",
      "| policy_loss        | -0.0011964941 |\n",
      "| serial_timesteps   | 60416         |\n",
      "| time_elapsed       | 43.3          |\n",
      "| total_timesteps    | 60416         |\n",
      "| value_loss         | 8.607629e-05  |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 2.2127817e-05  |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 999            |\n",
      "| ep_reward_mean     | -23.6          |\n",
      "| explained_variance | -0.0574        |\n",
      "| fps                | 1327           |\n",
      "| n_updates          | 473            |\n",
      "| policy_entropy     | -0.13209373    |\n",
      "| policy_loss        | -0.00023900968 |\n",
      "| serial_timesteps   | 60544          |\n",
      "| time_elapsed       | 43.4           |\n",
      "| total_timesteps    | 60544          |\n",
      "| value_loss         | 0.00010922877  |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00019840235 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -23.6         |\n",
      "| explained_variance | 0.404         |\n",
      "| fps                | 1456          |\n",
      "| n_updates          | 474           |\n",
      "| policy_entropy     | -0.13536131   |\n",
      "| policy_loss        | -0.0036517375 |\n",
      "| serial_timesteps   | 60672         |\n",
      "| time_elapsed       | 43.5          |\n",
      "| total_timesteps    | 60672         |\n",
      "| value_loss         | 3.371503e-05  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00018163823 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -23.6         |\n",
      "| explained_variance | 0.249         |\n",
      "| fps                | 1472          |\n",
      "| n_updates          | 475           |\n",
      "| policy_entropy     | -0.13872565   |\n",
      "| policy_loss        | -0.0053063454 |\n",
      "| serial_timesteps   | 60800         |\n",
      "| time_elapsed       | 43.6          |\n",
      "| total_timesteps    | 60800         |\n",
      "| value_loss         | 0.00010858923 |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 5.1011448e-05  |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 999            |\n",
      "| ep_reward_mean     | -23.6          |\n",
      "| explained_variance | 0.0666         |\n",
      "| fps                | 1478           |\n",
      "| n_updates          | 476            |\n",
      "| policy_entropy     | -0.14166057    |\n",
      "| policy_loss        | -0.00042147643 |\n",
      "| serial_timesteps   | 60928          |\n",
      "| time_elapsed       | 43.7           |\n",
      "| total_timesteps    | 60928          |\n",
      "| value_loss         | 0.00010433453  |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 1.5105552e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -23.2         |\n",
      "| explained_variance | -0.00148      |\n",
      "| fps                | 1381          |\n",
      "| n_updates          | 477           |\n",
      "| policy_entropy     | -0.14418969   |\n",
      "| policy_loss        | -0.0003459414 |\n",
      "| serial_timesteps   | 61056         |\n",
      "| time_elapsed       | 43.8          |\n",
      "| total_timesteps    | 61056         |\n",
      "| value_loss         | 0.004432395   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 7.0835005e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -23.2         |\n",
      "| explained_variance | 0.217         |\n",
      "| fps                | 1359          |\n",
      "| n_updates          | 478           |\n",
      "| policy_entropy     | -0.14611277   |\n",
      "| policy_loss        | -0.0020654323 |\n",
      "| serial_timesteps   | 61184         |\n",
      "| time_elapsed       | 43.9          |\n",
      "| total_timesteps    | 61184         |\n",
      "| value_loss         | 4.9421586e-05 |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 2.6553233e-05  |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 999            |\n",
      "| ep_reward_mean     | -23.2          |\n",
      "| explained_variance | 0.0416         |\n",
      "| fps                | 1471           |\n",
      "| n_updates          | 479            |\n",
      "| policy_entropy     | -0.14867845    |\n",
      "| policy_loss        | 6.3975225e-05  |\n",
      "| serial_timesteps   | 61312          |\n",
      "| time_elapsed       | 44             |\n",
      "| total_timesteps    | 61312          |\n",
      "| value_loss         | 0.000115803414 |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 5.7696234e-06  |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 999            |\n",
      "| ep_reward_mean     | -23.2          |\n",
      "| explained_variance | 0.0223         |\n",
      "| fps                | 1453           |\n",
      "| n_updates          | 480            |\n",
      "| policy_entropy     | -0.15173036    |\n",
      "| policy_loss        | -0.00089086976 |\n",
      "| serial_timesteps   | 61440          |\n",
      "| time_elapsed       | 44.1           |\n",
      "| total_timesteps    | 61440          |\n",
      "| value_loss         | 0.00040531642  |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 8.320302e-06  |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -23.2         |\n",
      "| explained_variance | -0.0878       |\n",
      "| fps                | 1492          |\n",
      "| n_updates          | 481           |\n",
      "| policy_entropy     | -0.15595956   |\n",
      "| policy_loss        | -0.0011445704 |\n",
      "| serial_timesteps   | 61568         |\n",
      "| time_elapsed       | 44.1          |\n",
      "| total_timesteps    | 61568         |\n",
      "| value_loss         | 9.469287e-05  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 1.052e-05     |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -23.2         |\n",
      "| explained_variance | -0.62         |\n",
      "| fps                | 1458          |\n",
      "| n_updates          | 482           |\n",
      "| policy_entropy     | -0.15981255   |\n",
      "| policy_loss        | -0.0005174037 |\n",
      "| serial_timesteps   | 61696         |\n",
      "| time_elapsed       | 44.2          |\n",
      "| total_timesteps    | 61696         |\n",
      "| value_loss         | 0.00014982662 |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 8.658318e-06   |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 999            |\n",
      "| ep_reward_mean     | -23.2          |\n",
      "| explained_variance | 0.182          |\n",
      "| fps                | 1457           |\n",
      "| n_updates          | 483            |\n",
      "| policy_entropy     | -0.16270484    |\n",
      "| policy_loss        | -0.00051891815 |\n",
      "| serial_timesteps   | 61824          |\n",
      "| time_elapsed       | 44.3           |\n",
      "| total_timesteps    | 61824          |\n",
      "| value_loss         | 9.509194e-05   |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 3.7124612e-06 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -22.9         |\n",
      "| explained_variance | -0.0143       |\n",
      "| fps                | 1440          |\n",
      "| n_updates          | 484           |\n",
      "| policy_entropy     | -0.16527106   |\n",
      "| policy_loss        | -0.000238952  |\n",
      "| serial_timesteps   | 61952         |\n",
      "| time_elapsed       | 44.4          |\n",
      "| total_timesteps    | 61952         |\n",
      "| value_loss         | 0.0052114744  |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 1.8373491e-06  |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 999            |\n",
      "| ep_reward_mean     | -22.9          |\n",
      "| explained_variance | -0.0859        |\n",
      "| fps                | 1341           |\n",
      "| n_updates          | 485            |\n",
      "| policy_entropy     | -0.1673787     |\n",
      "| policy_loss        | -0.00043140457 |\n",
      "| serial_timesteps   | 62080          |\n",
      "| time_elapsed       | 44.5           |\n",
      "| total_timesteps    | 62080          |\n",
      "| value_loss         | 0.00016480713  |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 9.775427e-06  |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -22.9         |\n",
      "| explained_variance | -0.154        |\n",
      "| fps                | 1303          |\n",
      "| n_updates          | 486           |\n",
      "| policy_entropy     | -0.17008433   |\n",
      "| policy_loss        | -0.0007739145 |\n",
      "| serial_timesteps   | 62208         |\n",
      "| time_elapsed       | 44.6          |\n",
      "| total_timesteps    | 62208         |\n",
      "| value_loss         | 0.00027191965 |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 1.10316705e-05 |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 999            |\n",
      "| ep_reward_mean     | -22.9          |\n",
      "| explained_variance | 0.196          |\n",
      "| fps                | 1467           |\n",
      "| n_updates          | 487            |\n",
      "| policy_entropy     | -0.17307782    |\n",
      "| policy_loss        | -0.0010187675  |\n",
      "| serial_timesteps   | 62336          |\n",
      "| time_elapsed       | 44.7           |\n",
      "| total_timesteps    | 62336          |\n",
      "| value_loss         | 0.00010961541  |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 2.9126017e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -22.9         |\n",
      "| explained_variance | 0.31          |\n",
      "| fps                | 1468          |\n",
      "| n_updates          | 488           |\n",
      "| policy_entropy     | -0.17633942   |\n",
      "| policy_loss        | -0.0006464324 |\n",
      "| serial_timesteps   | 62464         |\n",
      "| time_elapsed       | 44.8          |\n",
      "| total_timesteps    | 62464         |\n",
      "| value_loss         | 0.00020837868 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 1.8543527e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -22.9         |\n",
      "| explained_variance | -0.479        |\n",
      "| fps                | 1406          |\n",
      "| n_updates          | 489           |\n",
      "| policy_entropy     | -0.18008333   |\n",
      "| policy_loss        | -0.0015920894 |\n",
      "| serial_timesteps   | 62592         |\n",
      "| time_elapsed       | 44.9          |\n",
      "| total_timesteps    | 62592         |\n",
      "| value_loss         | 7.1858165e-05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 8.698589e-05  |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -22.9         |\n",
      "| explained_variance | 0.026         |\n",
      "| fps                | 1458          |\n",
      "| n_updates          | 490           |\n",
      "| policy_entropy     | -0.18385252   |\n",
      "| policy_loss        | -0.0027064169 |\n",
      "| serial_timesteps   | 62720         |\n",
      "| time_elapsed       | 45            |\n",
      "| total_timesteps    | 62720         |\n",
      "| value_loss         | 0.00021368689 |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 4.2355252e-05  |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 999            |\n",
      "| ep_reward_mean     | -22.9          |\n",
      "| explained_variance | -0.0978        |\n",
      "| fps                | 1385           |\n",
      "| n_updates          | 491            |\n",
      "| policy_entropy     | -0.18736055    |\n",
      "| policy_loss        | -0.00061234133 |\n",
      "| serial_timesteps   | 62848          |\n",
      "| time_elapsed       | 45             |\n",
      "| total_timesteps    | 62848          |\n",
      "| value_loss         | 8.829617e-05   |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 5.4065e-05    |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -22.6         |\n",
      "| explained_variance | 0.0513        |\n",
      "| fps                | 1448          |\n",
      "| n_updates          | 492           |\n",
      "| policy_entropy     | -0.19011268   |\n",
      "| policy_loss        | -0.0011746655 |\n",
      "| serial_timesteps   | 62976         |\n",
      "| time_elapsed       | 45.1          |\n",
      "| total_timesteps    | 62976         |\n",
      "| value_loss         | 0.0040852074  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 9.084892e-05  |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -22.6         |\n",
      "| explained_variance | 0.302         |\n",
      "| fps                | 1445          |\n",
      "| n_updates          | 493           |\n",
      "| policy_entropy     | -0.19177501   |\n",
      "| policy_loss        | -0.0016054821 |\n",
      "| serial_timesteps   | 63104         |\n",
      "| time_elapsed       | 45.2          |\n",
      "| total_timesteps    | 63104         |\n",
      "| value_loss         | 0.00027628947 |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 1.677978e-05   |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 999            |\n",
      "| ep_reward_mean     | -22.6          |\n",
      "| explained_variance | 0.151          |\n",
      "| fps                | 1420           |\n",
      "| n_updates          | 494            |\n",
      "| policy_entropy     | -0.19473575    |\n",
      "| policy_loss        | -0.00074082415 |\n",
      "| serial_timesteps   | 63232          |\n",
      "| time_elapsed       | 45.3           |\n",
      "| total_timesteps    | 63232          |\n",
      "| value_loss         | 0.00030456868  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 6.1560677e-06  |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 999            |\n",
      "| ep_reward_mean     | -22.6          |\n",
      "| explained_variance | -0.0359        |\n",
      "| fps                | 1395           |\n",
      "| n_updates          | 495            |\n",
      "| policy_entropy     | -0.19853894    |\n",
      "| policy_loss        | -0.00082894857 |\n",
      "| serial_timesteps   | 63360          |\n",
      "| time_elapsed       | 45.4           |\n",
      "| total_timesteps    | 63360          |\n",
      "| value_loss         | 0.00011566153  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 2.2146702e-05  |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 999            |\n",
      "| ep_reward_mean     | -22.6          |\n",
      "| explained_variance | -0.022         |\n",
      "| fps                | 1323           |\n",
      "| n_updates          | 496            |\n",
      "| policy_entropy     | -0.20170428    |\n",
      "| policy_loss        | -0.001166269   |\n",
      "| serial_timesteps   | 63488          |\n",
      "| time_elapsed       | 45.5           |\n",
      "| total_timesteps    | 63488          |\n",
      "| value_loss         | 0.000101086844 |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 1.8926447e-05  |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 999            |\n",
      "| ep_reward_mean     | -22.6          |\n",
      "| explained_variance | 0.263          |\n",
      "| fps                | 1439           |\n",
      "| n_updates          | 497            |\n",
      "| policy_entropy     | -0.20458463    |\n",
      "| policy_loss        | -0.00075765327 |\n",
      "| serial_timesteps   | 63616          |\n",
      "| time_elapsed       | 45.6           |\n",
      "| total_timesteps    | 63616          |\n",
      "| value_loss         | 3.992412e-05   |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 7.098034e-06  |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -22.6         |\n",
      "| explained_variance | 0.229         |\n",
      "| fps                | 1439          |\n",
      "| n_updates          | 498           |\n",
      "| policy_entropy     | -0.20788884   |\n",
      "| policy_loss        | -0.0010295997 |\n",
      "| serial_timesteps   | 63744         |\n",
      "| time_elapsed       | 45.7          |\n",
      "| total_timesteps    | 63744         |\n",
      "| value_loss         | 5.405228e-05  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 8.067536e-06  |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -22.6         |\n",
      "| explained_variance | 0.233         |\n",
      "| fps                | 1446          |\n",
      "| n_updates          | 499           |\n",
      "| policy_entropy     | -0.21120037   |\n",
      "| policy_loss        | -0.0005447485 |\n",
      "| serial_timesteps   | 63872         |\n",
      "| time_elapsed       | 45.8          |\n",
      "| total_timesteps    | 63872         |\n",
      "| value_loss         | 7.8879326e-05 |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 9.542953e-06   |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 999            |\n",
      "| ep_reward_mean     | -22.3          |\n",
      "| explained_variance | 0.0792         |\n",
      "| fps                | 1343           |\n",
      "| n_updates          | 500            |\n",
      "| policy_entropy     | -0.21358965    |\n",
      "| policy_loss        | -0.00024310697 |\n",
      "| serial_timesteps   | 64000          |\n",
      "| time_elapsed       | 45.9           |\n",
      "| total_timesteps    | 64000          |\n",
      "| value_loss         | 0.003883293    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 1.4511915e-06  |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 999            |\n",
      "| ep_reward_mean     | -22.3          |\n",
      "| explained_variance | -0.225         |\n",
      "| fps                | 1431           |\n",
      "| n_updates          | 501            |\n",
      "| policy_entropy     | -0.21523628    |\n",
      "| policy_loss        | -0.00024920644 |\n",
      "| serial_timesteps   | 64128          |\n",
      "| time_elapsed       | 46             |\n",
      "| total_timesteps    | 64128          |\n",
      "| value_loss         | 0.00021330983  |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 4.0745103e-06 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -22.3         |\n",
      "| explained_variance | 0.0411        |\n",
      "| fps                | 1301          |\n",
      "| n_updates          | 502           |\n",
      "| policy_entropy     | -0.21774036   |\n",
      "| policy_loss        | -0.0006048877 |\n",
      "| serial_timesteps   | 64256         |\n",
      "| time_elapsed       | 46            |\n",
      "| total_timesteps    | 64256         |\n",
      "| value_loss         | 0.00026805323 |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 6.64253e-06    |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 999            |\n",
      "| ep_reward_mean     | -22.3          |\n",
      "| explained_variance | -0.0491        |\n",
      "| fps                | 1443           |\n",
      "| n_updates          | 503            |\n",
      "| policy_entropy     | -0.22076617    |\n",
      "| policy_loss        | -0.00044674217 |\n",
      "| serial_timesteps   | 64384          |\n",
      "| time_elapsed       | 46.1           |\n",
      "| total_timesteps    | 64384          |\n",
      "| value_loss         | 9.5207084e-05  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 6.989907e-06   |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 999            |\n",
      "| ep_reward_mean     | -22.3          |\n",
      "| explained_variance | 0.33           |\n",
      "| fps                | 1450           |\n",
      "| n_updates          | 504            |\n",
      "| policy_entropy     | -0.22370821    |\n",
      "| policy_loss        | -0.00073545123 |\n",
      "| serial_timesteps   | 64512          |\n",
      "| time_elapsed       | 46.2           |\n",
      "| total_timesteps    | 64512          |\n",
      "| value_loss         | 6.503458e-05   |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 3.8408056e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -22.3         |\n",
      "| explained_variance | 0.249         |\n",
      "| fps                | 1455          |\n",
      "| n_updates          | 505           |\n",
      "| policy_entropy     | -0.22722165   |\n",
      "| policy_loss        | -0.0016165116 |\n",
      "| serial_timesteps   | 64640         |\n",
      "| time_elapsed       | 46.3          |\n",
      "| total_timesteps    | 64640         |\n",
      "| value_loss         | 0.00012285204 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0001717481  |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -22.3         |\n",
      "| explained_variance | 0.112         |\n",
      "| fps                | 1406          |\n",
      "| n_updates          | 506           |\n",
      "| policy_entropy     | -0.23065501   |\n",
      "| policy_loss        | -0.0043176985 |\n",
      "| serial_timesteps   | 64768         |\n",
      "| time_elapsed       | 46.4          |\n",
      "| total_timesteps    | 64768         |\n",
      "| value_loss         | 4.7412464e-05 |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 0.00019873545  |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 999            |\n",
      "| ep_reward_mean     | -22.3          |\n",
      "| explained_variance | -0.117         |\n",
      "| fps                | 1314           |\n",
      "| n_updates          | 507            |\n",
      "| policy_entropy     | -0.23393023    |\n",
      "| policy_loss        | -2.2020424e-05 |\n",
      "| serial_timesteps   | 64896          |\n",
      "| time_elapsed       | 46.5           |\n",
      "| total_timesteps    | 64896          |\n",
      "| value_loss         | 9.613793e-05   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 1.6928418e-05  |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 999            |\n",
      "| ep_reward_mean     | -22.1          |\n",
      "| explained_variance | -0.0203        |\n",
      "| fps                | 1443           |\n",
      "| n_updates          | 508            |\n",
      "| policy_entropy     | -0.2375134     |\n",
      "| policy_loss        | -0.00024243526 |\n",
      "| serial_timesteps   | 65024          |\n",
      "| time_elapsed       | 46.6           |\n",
      "| total_timesteps    | 65024          |\n",
      "| value_loss         | 0.004321916    |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0004228478 |\n",
      "| clipfrac           | 0.0          |\n",
      "| ep_len_mean        | 999          |\n",
      "| ep_reward_mean     | -22.1        |\n",
      "| explained_variance | -0.766       |\n",
      "| fps                | 1411         |\n",
      "| n_updates          | 509          |\n",
      "| policy_entropy     | -0.24035564  |\n",
      "| policy_loss        | -0.005580432 |\n",
      "| serial_timesteps   | 65152        |\n",
      "| time_elapsed       | 46.7         |\n",
      "| total_timesteps    | 65152        |\n",
      "| value_loss         | 0.0002864141 |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00034955234 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -22.1         |\n",
      "| explained_variance | -0.42         |\n",
      "| fps                | 1489          |\n",
      "| n_updates          | 510           |\n",
      "| policy_entropy     | -0.24292992   |\n",
      "| policy_loss        | 0.00308449    |\n",
      "| serial_timesteps   | 65280         |\n",
      "| time_elapsed       | 46.8          |\n",
      "| total_timesteps    | 65280         |\n",
      "| value_loss         | 0.0001663532  |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 0.00035946784  |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 999            |\n",
      "| ep_reward_mean     | -22.1          |\n",
      "| explained_variance | -0.41          |\n",
      "| fps                | 1365           |\n",
      "| n_updates          | 511            |\n",
      "| policy_entropy     | -0.24511999    |\n",
      "| policy_loss        | -0.00038488966 |\n",
      "| serial_timesteps   | 65408          |\n",
      "| time_elapsed       | 46.9           |\n",
      "| total_timesteps    | 65408          |\n",
      "| value_loss         | 9.681429e-05   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 1.5580177e-05  |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 999            |\n",
      "| ep_reward_mean     | -22.1          |\n",
      "| explained_variance | 0.147          |\n",
      "| fps                | 1407           |\n",
      "| n_updates          | 512            |\n",
      "| policy_entropy     | -0.24747577    |\n",
      "| policy_loss        | -0.00078856654 |\n",
      "| serial_timesteps   | 65536          |\n",
      "| time_elapsed       | 47             |\n",
      "| total_timesteps    | 65536          |\n",
      "| value_loss         | 5.304401e-05   |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0002830888  |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -22.1         |\n",
      "| explained_variance | -0.127        |\n",
      "| fps                | 1451          |\n",
      "| n_updates          | 513           |\n",
      "| policy_entropy     | -0.25002995   |\n",
      "| policy_loss        | -0.004030852  |\n",
      "| serial_timesteps   | 65664         |\n",
      "| time_elapsed       | 47.1          |\n",
      "| total_timesteps    | 65664         |\n",
      "| value_loss         | 0.00012561442 |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 0.0002331801   |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 999            |\n",
      "| ep_reward_mean     | -22.1          |\n",
      "| explained_variance | 0.142          |\n",
      "| fps                | 1436           |\n",
      "| n_updates          | 514            |\n",
      "| policy_entropy     | -0.25238535    |\n",
      "| policy_loss        | -0.00033498812 |\n",
      "| serial_timesteps   | 65792          |\n",
      "| time_elapsed       | 47.1           |\n",
      "| total_timesteps    | 65792          |\n",
      "| value_loss         | 5.704235e-05   |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00015683404 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -22.1         |\n",
      "| explained_variance | 0.0976        |\n",
      "| fps                | 1478          |\n",
      "| n_updates          | 515           |\n",
      "| policy_entropy     | -0.2557248    |\n",
      "| policy_loss        | -0.0026717908 |\n",
      "| serial_timesteps   | 65920         |\n",
      "| time_elapsed       | 47.2          |\n",
      "| total_timesteps    | 65920         |\n",
      "| value_loss         | 6.833576e-05  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 4.1279938e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -21.8         |\n",
      "| explained_variance | -0.0755       |\n",
      "| fps                | 1477          |\n",
      "| n_updates          | 516           |\n",
      "| policy_entropy     | -0.2587403    |\n",
      "| policy_loss        | 0.0004719738  |\n",
      "| serial_timesteps   | 66048         |\n",
      "| time_elapsed       | 47.3          |\n",
      "| total_timesteps    | 66048         |\n",
      "| value_loss         | 0.003270576   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00016652961 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -21.8         |\n",
      "| explained_variance | -1.12         |\n",
      "| fps                | 1410          |\n",
      "| n_updates          | 517           |\n",
      "| policy_entropy     | -0.2612093    |\n",
      "| policy_loss        | -0.0012223804 |\n",
      "| serial_timesteps   | 66176         |\n",
      "| time_elapsed       | 47.4          |\n",
      "| total_timesteps    | 66176         |\n",
      "| value_loss         | 0.0001360338  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 2.0268268e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -21.8         |\n",
      "| explained_variance | 0.105         |\n",
      "| fps                | 1319          |\n",
      "| n_updates          | 518           |\n",
      "| policy_entropy     | -0.26375297   |\n",
      "| policy_loss        | -0.0007944518 |\n",
      "| serial_timesteps   | 66304         |\n",
      "| time_elapsed       | 47.5          |\n",
      "| total_timesteps    | 66304         |\n",
      "| value_loss         | 7.936639e-05  |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 5.26481e-05  |\n",
      "| clipfrac           | 0.0          |\n",
      "| ep_len_mean        | 999          |\n",
      "| ep_reward_mean     | -21.8        |\n",
      "| explained_variance | 0.348        |\n",
      "| fps                | 1407         |\n",
      "| n_updates          | 519          |\n",
      "| policy_entropy     | -0.26619956  |\n",
      "| policy_loss        | 3.520155e-05 |\n",
      "| serial_timesteps   | 66432        |\n",
      "| time_elapsed       | 47.6         |\n",
      "| total_timesteps    | 66432        |\n",
      "| value_loss         | 8.854432e-05 |\n",
      "-------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 1.8169541e-05  |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 999            |\n",
      "| ep_reward_mean     | -21.8          |\n",
      "| explained_variance | -0.701         |\n",
      "| fps                | 1437           |\n",
      "| n_updates          | 520            |\n",
      "| policy_entropy     | -0.2686838     |\n",
      "| policy_loss        | -0.00079757196 |\n",
      "| serial_timesteps   | 66560          |\n",
      "| time_elapsed       | 47.7           |\n",
      "| total_timesteps    | 66560          |\n",
      "| value_loss         | 8.059044e-05   |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 3.593067e-05  |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -21.8         |\n",
      "| explained_variance | 0.409         |\n",
      "| fps                | 1420          |\n",
      "| n_updates          | 521           |\n",
      "| policy_entropy     | -0.27110916   |\n",
      "| policy_loss        | -0.0015535249 |\n",
      "| serial_timesteps   | 66688         |\n",
      "| time_elapsed       | 47.8          |\n",
      "| total_timesteps    | 66688         |\n",
      "| value_loss         | 3.7597303e-05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 7.729489e-05  |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -21.8         |\n",
      "| explained_variance | -1.13         |\n",
      "| fps                | 1422          |\n",
      "| n_updates          | 522           |\n",
      "| policy_entropy     | -0.2740752    |\n",
      "| policy_loss        | -0.0017917673 |\n",
      "| serial_timesteps   | 66816         |\n",
      "| time_elapsed       | 47.9          |\n",
      "| total_timesteps    | 66816         |\n",
      "| value_loss         | 6.480443e-05  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00043570026 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -21.5         |\n",
      "| explained_variance | 0.0875        |\n",
      "| fps                | 1489          |\n",
      "| n_updates          | 523           |\n",
      "| policy_entropy     | -0.27697247   |\n",
      "| policy_loss        | -0.001169909  |\n",
      "| serial_timesteps   | 66944         |\n",
      "| time_elapsed       | 48            |\n",
      "| total_timesteps    | 66944         |\n",
      "| value_loss         | 0.0031533407  |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 1.8053088e-05  |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 999            |\n",
      "| ep_reward_mean     | -21.5          |\n",
      "| explained_variance | 0.0503         |\n",
      "| fps                | 1445           |\n",
      "| n_updates          | 524            |\n",
      "| policy_entropy     | -0.27955934    |\n",
      "| policy_loss        | -0.00047223864 |\n",
      "| serial_timesteps   | 67072          |\n",
      "| time_elapsed       | 48.1           |\n",
      "| total_timesteps    | 67072          |\n",
      "| value_loss         | 0.00016973776  |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00045054482 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -21.5         |\n",
      "| explained_variance | 0.0491        |\n",
      "| fps                | 1473          |\n",
      "| n_updates          | 525           |\n",
      "| policy_entropy     | -0.28322726   |\n",
      "| policy_loss        | -0.0033535846 |\n",
      "| serial_timesteps   | 67200         |\n",
      "| time_elapsed       | 48.1          |\n",
      "| total_timesteps    | 67200         |\n",
      "| value_loss         | 5.968319e-05  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0004167162  |\n",
      "| clipfrac           | 0.001953125   |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -21.5         |\n",
      "| explained_variance | -0.418        |\n",
      "| fps                | 1472          |\n",
      "| n_updates          | 526           |\n",
      "| policy_entropy     | -0.2868298    |\n",
      "| policy_loss        | -0.0031526312 |\n",
      "| serial_timesteps   | 67328         |\n",
      "| time_elapsed       | 48.2          |\n",
      "| total_timesteps    | 67328         |\n",
      "| value_loss         | 0.00022758593 |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 2.8787286e-05  |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 999            |\n",
      "| ep_reward_mean     | -21.5          |\n",
      "| explained_variance | -1.62          |\n",
      "| fps                | 1442           |\n",
      "| n_updates          | 527            |\n",
      "| policy_entropy     | -0.29014567    |\n",
      "| policy_loss        | -0.00097219273 |\n",
      "| serial_timesteps   | 67456          |\n",
      "| time_elapsed       | 48.3           |\n",
      "| total_timesteps    | 67456          |\n",
      "| value_loss         | 0.00018249643  |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 2.8259794e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -21.5         |\n",
      "| explained_variance | -0.33         |\n",
      "| fps                | 1377          |\n",
      "| n_updates          | 528           |\n",
      "| policy_entropy     | -0.29334775   |\n",
      "| policy_loss        | -0.0011192835 |\n",
      "| serial_timesteps   | 67584         |\n",
      "| time_elapsed       | 48.4          |\n",
      "| total_timesteps    | 67584         |\n",
      "| value_loss         | 0.00014898542 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0004842191  |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -21.5         |\n",
      "| explained_variance | 0.429         |\n",
      "| fps                | 1358          |\n",
      "| n_updates          | 529           |\n",
      "| policy_entropy     | -0.2963803    |\n",
      "| policy_loss        | -0.0054813675 |\n",
      "| serial_timesteps   | 67712         |\n",
      "| time_elapsed       | 48.5          |\n",
      "| total_timesteps    | 67712         |\n",
      "| value_loss         | 4.689261e-05  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00038921367 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -21.5         |\n",
      "| explained_variance | -0.367        |\n",
      "| fps                | 1321          |\n",
      "| n_updates          | 530           |\n",
      "| policy_entropy     | -0.2991248    |\n",
      "| policy_loss        | 0.00026243052 |\n",
      "| serial_timesteps   | 67840         |\n",
      "| time_elapsed       | 48.6          |\n",
      "| total_timesteps    | 67840         |\n",
      "| value_loss         | 8.849066e-05  |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 0.00020736098  |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 999            |\n",
      "| ep_reward_mean     | -21.2          |\n",
      "| explained_variance | 0.0654         |\n",
      "| fps                | 1473           |\n",
      "| n_updates          | 531            |\n",
      "| policy_entropy     | -0.30189347    |\n",
      "| policy_loss        | -0.00030907744 |\n",
      "| serial_timesteps   | 67968          |\n",
      "| time_elapsed       | 48.7           |\n",
      "| total_timesteps    | 67968          |\n",
      "| value_loss         | 0.0029902272   |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00025153413 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -21.2         |\n",
      "| explained_variance | -0.34         |\n",
      "| fps                | 1475          |\n",
      "| n_updates          | 532           |\n",
      "| policy_entropy     | -0.30425775   |\n",
      "| policy_loss        | -0.0019525733 |\n",
      "| serial_timesteps   | 68096         |\n",
      "| time_elapsed       | 48.8          |\n",
      "| total_timesteps    | 68096         |\n",
      "| value_loss         | 9.877514e-05  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 2.3763709e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -21.2         |\n",
      "| explained_variance | 0.294         |\n",
      "| fps                | 1497          |\n",
      "| n_updates          | 533           |\n",
      "| policy_entropy     | -0.30801696   |\n",
      "| policy_loss        | -0.0007128492 |\n",
      "| serial_timesteps   | 68224         |\n",
      "| time_elapsed       | 48.9          |\n",
      "| total_timesteps    | 68224         |\n",
      "| value_loss         | 9.56474e-05   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 1.7399996e-05  |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 999            |\n",
      "| ep_reward_mean     | -21.2          |\n",
      "| explained_variance | -0.457         |\n",
      "| fps                | 1449           |\n",
      "| n_updates          | 534            |\n",
      "| policy_entropy     | -0.31192577    |\n",
      "| policy_loss        | -7.7063916e-05 |\n",
      "| serial_timesteps   | 68352          |\n",
      "| time_elapsed       | 49             |\n",
      "| total_timesteps    | 68352          |\n",
      "| value_loss         | 4.368772e-05   |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0002662045  |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -21.2         |\n",
      "| explained_variance | 0.221         |\n",
      "| fps                | 1431          |\n",
      "| n_updates          | 535           |\n",
      "| policy_entropy     | -0.31505117   |\n",
      "| policy_loss        | -0.0009160567 |\n",
      "| serial_timesteps   | 68480         |\n",
      "| time_elapsed       | 49            |\n",
      "| total_timesteps    | 68480         |\n",
      "| value_loss         | 4.811675e-05  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 8.79514e-05   |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -21.2         |\n",
      "| explained_variance | -0.142        |\n",
      "| fps                | 1371          |\n",
      "| n_updates          | 536           |\n",
      "| policy_entropy     | -0.31821436   |\n",
      "| policy_loss        | -0.0018086258 |\n",
      "| serial_timesteps   | 68608         |\n",
      "| time_elapsed       | 49.1          |\n",
      "| total_timesteps    | 68608         |\n",
      "| value_loss         | 0.00017729703 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 6.2372186e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -21.2         |\n",
      "| explained_variance | 0.034         |\n",
      "| fps                | 1442          |\n",
      "| n_updates          | 537           |\n",
      "| policy_entropy     | -0.32135832   |\n",
      "| policy_loss        | -0.0019202671 |\n",
      "| serial_timesteps   | 68736         |\n",
      "| time_elapsed       | 49.2          |\n",
      "| total_timesteps    | 68736         |\n",
      "| value_loss         | 0.00017165969 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00010995228 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -21.2         |\n",
      "| explained_variance | -0.777        |\n",
      "| fps                | 1425          |\n",
      "| n_updates          | 538           |\n",
      "| policy_entropy     | -0.32408753   |\n",
      "| policy_loss        | 9.6177915e-05 |\n",
      "| serial_timesteps   | 68864         |\n",
      "| time_elapsed       | 49.3          |\n",
      "| total_timesteps    | 68864         |\n",
      "| value_loss         | 7.532444e-05  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0005143859  |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -21           |\n",
      "| explained_variance | -0.126        |\n",
      "| fps                | 1377          |\n",
      "| n_updates          | 539           |\n",
      "| policy_entropy     | -0.32593292   |\n",
      "| policy_loss        | -0.0035479544 |\n",
      "| serial_timesteps   | 68992         |\n",
      "| time_elapsed       | 49.4          |\n",
      "| total_timesteps    | 68992         |\n",
      "| value_loss         | 0.0026615325  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 2.7782713e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -21           |\n",
      "| explained_variance | -0.249        |\n",
      "| fps                | 1402          |\n",
      "| n_updates          | 540           |\n",
      "| policy_entropy     | -0.327731     |\n",
      "| policy_loss        | 0.00021384156 |\n",
      "| serial_timesteps   | 69120         |\n",
      "| time_elapsed       | 49.5          |\n",
      "| total_timesteps    | 69120         |\n",
      "| value_loss         | 0.00010213959 |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 1.4264437e-05  |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 999            |\n",
      "| ep_reward_mean     | -21            |\n",
      "| explained_variance | 0.0343         |\n",
      "| fps                | 1337           |\n",
      "| n_updates          | 541            |\n",
      "| policy_entropy     | -0.33063152    |\n",
      "| policy_loss        | -0.00032775197 |\n",
      "| serial_timesteps   | 69248          |\n",
      "| time_elapsed       | 49.6           |\n",
      "| total_timesteps    | 69248          |\n",
      "| value_loss         | 3.649017e-05   |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0005317476  |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -21           |\n",
      "| explained_variance | -0.255        |\n",
      "| fps                | 1461          |\n",
      "| n_updates          | 542           |\n",
      "| policy_entropy     | -0.33348256   |\n",
      "| policy_loss        | -0.0060571143 |\n",
      "| serial_timesteps   | 69376         |\n",
      "| time_elapsed       | 49.7          |\n",
      "| total_timesteps    | 69376         |\n",
      "| value_loss         | 4.2424504e-05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0014297952  |\n",
      "| clipfrac           | 0.0078125     |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -21           |\n",
      "| explained_variance | -0.85         |\n",
      "| fps                | 1448          |\n",
      "| n_updates          | 543           |\n",
      "| policy_entropy     | -0.3355713    |\n",
      "| policy_loss        | -0.011297748  |\n",
      "| serial_timesteps   | 69504         |\n",
      "| time_elapsed       | 49.8          |\n",
      "| total_timesteps    | 69504         |\n",
      "| value_loss         | 0.00021990176 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 8.3035484e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -21           |\n",
      "| explained_variance | 0.164         |\n",
      "| fps                | 1446          |\n",
      "| n_updates          | 544           |\n",
      "| policy_entropy     | -0.33856308   |\n",
      "| policy_loss        | -0.0007232233 |\n",
      "| serial_timesteps   | 69632         |\n",
      "| time_elapsed       | 49.9          |\n",
      "| total_timesteps    | 69632         |\n",
      "| value_loss         | 3.731672e-05  |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 1.28350475e-05 |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 999            |\n",
      "| ep_reward_mean     | -21            |\n",
      "| explained_variance | -1.08          |\n",
      "| fps                | 1350           |\n",
      "| n_updates          | 545            |\n",
      "| policy_entropy     | -0.34235007    |\n",
      "| policy_loss        | -0.00078104064 |\n",
      "| serial_timesteps   | 69760          |\n",
      "| time_elapsed       | 50             |\n",
      "| total_timesteps    | 69760          |\n",
      "| value_loss         | 9.8891214e-05  |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 1.4420584e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -21           |\n",
      "| explained_variance | -0.143        |\n",
      "| fps                | 1439          |\n",
      "| n_updates          | 546           |\n",
      "| policy_entropy     | -0.34563935   |\n",
      "| policy_loss        | -0.001273257  |\n",
      "| serial_timesteps   | 69888         |\n",
      "| time_elapsed       | 50            |\n",
      "| total_timesteps    | 69888         |\n",
      "| value_loss         | 7.7429955e-05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 1.0512561e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -20.7         |\n",
      "| explained_variance | -0.0522       |\n",
      "| fps                | 1425          |\n",
      "| n_updates          | 547           |\n",
      "| policy_entropy     | -0.34932366   |\n",
      "| policy_loss        | -0.0002634906 |\n",
      "| serial_timesteps   | 70016         |\n",
      "| time_elapsed       | 50.1          |\n",
      "| total_timesteps    | 70016         |\n",
      "| value_loss         | 0.0025785316  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 6.8084346e-06 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -20.7         |\n",
      "| explained_variance | 0.39          |\n",
      "| fps                | 1399          |\n",
      "| n_updates          | 548           |\n",
      "| policy_entropy     | -0.35148746   |\n",
      "| policy_loss        | -0.0007020219 |\n",
      "| serial_timesteps   | 70144         |\n",
      "| time_elapsed       | 50.2          |\n",
      "| total_timesteps    | 70144         |\n",
      "| value_loss         | 6.3603744e-05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 6.948295e-06  |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -20.7         |\n",
      "| explained_variance | 0.272         |\n",
      "| fps                | 1452          |\n",
      "| n_updates          | 549           |\n",
      "| policy_entropy     | -0.35424778   |\n",
      "| policy_loss        | -0.0006174003 |\n",
      "| serial_timesteps   | 70272         |\n",
      "| time_elapsed       | 50.3          |\n",
      "| total_timesteps    | 70272         |\n",
      "| value_loss         | 4.609602e-05  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 1.6224594e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -20.7         |\n",
      "| explained_variance | 0.235         |\n",
      "| fps                | 1408          |\n",
      "| n_updates          | 550           |\n",
      "| policy_entropy     | -0.3578214    |\n",
      "| policy_loss        | -0.0009895924 |\n",
      "| serial_timesteps   | 70400         |\n",
      "| time_elapsed       | 50.4          |\n",
      "| total_timesteps    | 70400         |\n",
      "| value_loss         | 2.0360447e-05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 2.9452185e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -20.7         |\n",
      "| explained_variance | 0.143         |\n",
      "| fps                | 1457          |\n",
      "| n_updates          | 551           |\n",
      "| policy_entropy     | -0.36147487   |\n",
      "| policy_loss        | -0.001333589  |\n",
      "| serial_timesteps   | 70528         |\n",
      "| time_elapsed       | 50.5          |\n",
      "| total_timesteps    | 70528         |\n",
      "| value_loss         | 6.134634e-05  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 6.913547e-05  |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -20.7         |\n",
      "| explained_variance | -0.925        |\n",
      "| fps                | 1383          |\n",
      "| n_updates          | 552           |\n",
      "| policy_entropy     | -0.36494496   |\n",
      "| policy_loss        | -0.0012994376 |\n",
      "| serial_timesteps   | 70656         |\n",
      "| time_elapsed       | 50.6          |\n",
      "| total_timesteps    | 70656         |\n",
      "| value_loss         | 7.3832656e-05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 3.6587157e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -20.7         |\n",
      "| explained_variance | -0.256        |\n",
      "| fps                | 1446          |\n",
      "| n_updates          | 553           |\n",
      "| policy_entropy     | -0.36851516   |\n",
      "| policy_loss        | -0.0010112516 |\n",
      "| serial_timesteps   | 70784         |\n",
      "| time_elapsed       | 50.7          |\n",
      "| total_timesteps    | 70784         |\n",
      "| value_loss         | 0.00010366703 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 1.0155575e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -20.7         |\n",
      "| explained_variance | 0.0468        |\n",
      "| fps                | 1395          |\n",
      "| n_updates          | 554           |\n",
      "| policy_entropy     | -0.37209767   |\n",
      "| policy_loss        | -0.0010752188 |\n",
      "| serial_timesteps   | 70912         |\n",
      "| time_elapsed       | 50.8          |\n",
      "| total_timesteps    | 70912         |\n",
      "| value_loss         | 0.00014477946 |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 3.2864664e-06  |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 999            |\n",
      "| ep_reward_mean     | -20.5          |\n",
      "| explained_variance | -0.0218        |\n",
      "| fps                | 1455           |\n",
      "| n_updates          | 555            |\n",
      "| policy_entropy     | -0.37551725    |\n",
      "| policy_loss        | -0.00017743174 |\n",
      "| serial_timesteps   | 71040          |\n",
      "| time_elapsed       | 50.9           |\n",
      "| total_timesteps    | 71040          |\n",
      "| value_loss         | 0.002320575    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00013768687 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -20.5         |\n",
      "| explained_variance | 0.0566        |\n",
      "| fps                | 1385          |\n",
      "| n_updates          | 556           |\n",
      "| policy_entropy     | -0.3782373    |\n",
      "| policy_loss        | -0.0028437353 |\n",
      "| serial_timesteps   | 71168         |\n",
      "| time_elapsed       | 51            |\n",
      "| total_timesteps    | 71168         |\n",
      "| value_loss         | 4.438082e-05  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00013797023 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -20.5         |\n",
      "| explained_variance | -0.237        |\n",
      "| fps                | 1359          |\n",
      "| n_updates          | 557           |\n",
      "| policy_entropy     | -0.38150936   |\n",
      "| policy_loss        | -0.0019438759 |\n",
      "| serial_timesteps   | 71296         |\n",
      "| time_elapsed       | 51            |\n",
      "| total_timesteps    | 71296         |\n",
      "| value_loss         | 7.431912e-05  |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 6.0106636e-06  |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 999            |\n",
      "| ep_reward_mean     | -20.5          |\n",
      "| explained_variance | -0.00634       |\n",
      "| fps                | 1415           |\n",
      "| n_updates          | 558            |\n",
      "| policy_entropy     | -0.38515353    |\n",
      "| policy_loss        | -0.00085737684 |\n",
      "| serial_timesteps   | 71424          |\n",
      "| time_elapsed       | 51.1           |\n",
      "| total_timesteps    | 71424          |\n",
      "| value_loss         | 4.1255753e-05  |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 2.659327e-05  |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -20.5         |\n",
      "| explained_variance | -0.0754       |\n",
      "| fps                | 1394          |\n",
      "| n_updates          | 559           |\n",
      "| policy_entropy     | -0.3888731    |\n",
      "| policy_loss        | -0.0009222928 |\n",
      "| serial_timesteps   | 71552         |\n",
      "| time_elapsed       | 51.2          |\n",
      "| total_timesteps    | 71552         |\n",
      "| value_loss         | 4.4038727e-05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 5.7008856e-06 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -20.5         |\n",
      "| explained_variance | -0.427        |\n",
      "| fps                | 1425          |\n",
      "| n_updates          | 560           |\n",
      "| policy_entropy     | -0.3925367    |\n",
      "| policy_loss        | -0.0005798107 |\n",
      "| serial_timesteps   | 71680         |\n",
      "| time_elapsed       | 51.3          |\n",
      "| total_timesteps    | 71680         |\n",
      "| value_loss         | 4.1217907e-05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 3.055425e-05  |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -20.5         |\n",
      "| explained_variance | 0.261         |\n",
      "| fps                | 1425          |\n",
      "| n_updates          | 561           |\n",
      "| policy_entropy     | -0.39606807   |\n",
      "| policy_loss        | -0.0012315975 |\n",
      "| serial_timesteps   | 71808         |\n",
      "| time_elapsed       | 51.4          |\n",
      "| total_timesteps    | 71808         |\n",
      "| value_loss         | 5.5689474e-05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 7.2487055e-06 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -20.2         |\n",
      "| explained_variance | 0.0395        |\n",
      "| fps                | 1427          |\n",
      "| n_updates          | 562           |\n",
      "| policy_entropy     | -0.39940208   |\n",
      "| policy_loss        | -0.0004299085 |\n",
      "| serial_timesteps   | 71936         |\n",
      "| time_elapsed       | 51.5          |\n",
      "| total_timesteps    | 71936         |\n",
      "| value_loss         | 0.0021646381  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 5.7491437e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -20.2         |\n",
      "| explained_variance | -0.0875       |\n",
      "| fps                | 1283          |\n",
      "| n_updates          | 563           |\n",
      "| policy_entropy     | -0.40218148   |\n",
      "| policy_loss        | -0.0016542121 |\n",
      "| serial_timesteps   | 72064         |\n",
      "| time_elapsed       | 51.6          |\n",
      "| total_timesteps    | 72064         |\n",
      "| value_loss         | 9.5268275e-05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 5.985448e-06  |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -20.2         |\n",
      "| explained_variance | -0.286        |\n",
      "| fps                | 1429          |\n",
      "| n_updates          | 564           |\n",
      "| policy_entropy     | -0.4050483    |\n",
      "| policy_loss        | -0.0006610043 |\n",
      "| serial_timesteps   | 72192         |\n",
      "| time_elapsed       | 51.7          |\n",
      "| total_timesteps    | 72192         |\n",
      "| value_loss         | 8.334375e-05  |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 3.1486095e-05  |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 999            |\n",
      "| ep_reward_mean     | -20.2          |\n",
      "| explained_variance | -0.262         |\n",
      "| fps                | 1452           |\n",
      "| n_updates          | 565            |\n",
      "| policy_entropy     | -0.40809005    |\n",
      "| policy_loss        | -0.00081315014 |\n",
      "| serial_timesteps   | 72320          |\n",
      "| time_elapsed       | 51.8           |\n",
      "| total_timesteps    | 72320          |\n",
      "| value_loss         | 8.227542e-05   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 9.394047e-06   |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 999            |\n",
      "| ep_reward_mean     | -20.2          |\n",
      "| explained_variance | -1.34          |\n",
      "| fps                | 1391           |\n",
      "| n_updates          | 566            |\n",
      "| policy_entropy     | -0.41085047    |\n",
      "| policy_loss        | -0.00064057915 |\n",
      "| serial_timesteps   | 72448          |\n",
      "| time_elapsed       | 51.9           |\n",
      "| total_timesteps    | 72448          |\n",
      "| value_loss         | 7.530471e-05   |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 1.7760889e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -20.2         |\n",
      "| explained_variance | -0.869        |\n",
      "| fps                | 1324          |\n",
      "| n_updates          | 567           |\n",
      "| policy_entropy     | -0.41384283   |\n",
      "| policy_loss        | -0.0011946158 |\n",
      "| serial_timesteps   | 72576         |\n",
      "| time_elapsed       | 52            |\n",
      "| total_timesteps    | 72576         |\n",
      "| value_loss         | 0.00011126777 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 2.6669934e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -20.2         |\n",
      "| explained_variance | -3.76         |\n",
      "| fps                | 1455          |\n",
      "| n_updates          | 568           |\n",
      "| policy_entropy     | -0.41702473   |\n",
      "| policy_loss        | -0.0012918825 |\n",
      "| serial_timesteps   | 72704         |\n",
      "| time_elapsed       | 52.1          |\n",
      "| total_timesteps    | 72704         |\n",
      "| value_loss         | 9.215415e-05  |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| approxkl           | 6.8535956e-05   |\n",
      "| clipfrac           | 0.0             |\n",
      "| ep_len_mean        | 999             |\n",
      "| ep_reward_mean     | -20.2           |\n",
      "| explained_variance | -0.704          |\n",
      "| fps                | 1451            |\n",
      "| n_updates          | 569             |\n",
      "| policy_entropy     | -0.42008775     |\n",
      "| policy_loss        | -0.000118176686 |\n",
      "| serial_timesteps   | 72832           |\n",
      "| time_elapsed       | 52.2            |\n",
      "| total_timesteps    | 72832           |\n",
      "| value_loss         | 5.357583e-05    |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 1.9814923e-05  |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 999            |\n",
      "| ep_reward_mean     | -20            |\n",
      "| explained_variance | 0.0491         |\n",
      "| fps                | 1473           |\n",
      "| n_updates          | 570            |\n",
      "| policy_entropy     | -0.42261308    |\n",
      "| policy_loss        | -0.00074195326 |\n",
      "| serial_timesteps   | 72960          |\n",
      "| time_elapsed       | 52.2           |\n",
      "| total_timesteps    | 72960          |\n",
      "| value_loss         | 0.001762825    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00035787723 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -20           |\n",
      "| explained_variance | -0.195        |\n",
      "| fps                | 1453          |\n",
      "| n_updates          | 571           |\n",
      "| policy_entropy     | -0.42442954   |\n",
      "| policy_loss        | -0.0035030453 |\n",
      "| serial_timesteps   | 73088         |\n",
      "| time_elapsed       | 52.3          |\n",
      "| total_timesteps    | 73088         |\n",
      "| value_loss         | 9.249248e-05  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 7.7979086e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -20           |\n",
      "| explained_variance | -0.511        |\n",
      "| fps                | 1346          |\n",
      "| n_updates          | 572           |\n",
      "| policy_entropy     | -0.42654765   |\n",
      "| policy_loss        | -0.0016021893 |\n",
      "| serial_timesteps   | 73216         |\n",
      "| time_elapsed       | 52.4          |\n",
      "| total_timesteps    | 73216         |\n",
      "| value_loss         | 0.00011195014 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 4.8942416e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -20           |\n",
      "| explained_variance | 0.555         |\n",
      "| fps                | 1323          |\n",
      "| n_updates          | 573           |\n",
      "| policy_entropy     | -0.4287607    |\n",
      "| policy_loss        | 0.00038644322 |\n",
      "| serial_timesteps   | 73344         |\n",
      "| time_elapsed       | 52.5          |\n",
      "| total_timesteps    | 73344         |\n",
      "| value_loss         | 2.667832e-05  |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 5.064595e-05   |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 999            |\n",
      "| ep_reward_mean     | -20            |\n",
      "| explained_variance | -0.246         |\n",
      "| fps                | 1225           |\n",
      "| n_updates          | 574            |\n",
      "| policy_entropy     | -0.43175936    |\n",
      "| policy_loss        | -0.00045350794 |\n",
      "| serial_timesteps   | 73472          |\n",
      "| time_elapsed       | 52.6           |\n",
      "| total_timesteps    | 73472          |\n",
      "| value_loss         | 7.365041e-05   |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 1.700005e-05  |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -20           |\n",
      "| explained_variance | 0.111         |\n",
      "| fps                | 1449          |\n",
      "| n_updates          | 575           |\n",
      "| policy_entropy     | -0.43508372   |\n",
      "| policy_loss        | -0.0007306745 |\n",
      "| serial_timesteps   | 73600         |\n",
      "| time_elapsed       | 52.7          |\n",
      "| total_timesteps    | 73600         |\n",
      "| value_loss         | 3.285163e-05  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00021681181 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -20           |\n",
      "| explained_variance | -0.229        |\n",
      "| fps                | 1427          |\n",
      "| n_updates          | 576           |\n",
      "| policy_entropy     | -0.43819132   |\n",
      "| policy_loss        | -0.002405514  |\n",
      "| serial_timesteps   | 73728         |\n",
      "| time_elapsed       | 52.8          |\n",
      "| total_timesteps    | 73728         |\n",
      "| value_loss         | 6.75913e-05   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 3.9126702e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -20           |\n",
      "| explained_variance | -0.615        |\n",
      "| fps                | 1442          |\n",
      "| n_updates          | 577           |\n",
      "| policy_entropy     | -0.442336     |\n",
      "| policy_loss        | -0.0011432874 |\n",
      "| serial_timesteps   | 73856         |\n",
      "| time_elapsed       | 52.9          |\n",
      "| total_timesteps    | 73856         |\n",
      "| value_loss         | 2.6471636e-05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.000390366   |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -19.8         |\n",
      "| explained_variance | 0.045         |\n",
      "| fps                | 1396          |\n",
      "| n_updates          | 578           |\n",
      "| policy_entropy     | -0.44502917   |\n",
      "| policy_loss        | -0.0042854073 |\n",
      "| serial_timesteps   | 73984         |\n",
      "| time_elapsed       | 53            |\n",
      "| total_timesteps    | 73984         |\n",
      "| value_loss         | 0.001517693   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00051591225 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -19.8         |\n",
      "| explained_variance | 0.109         |\n",
      "| fps                | 1476          |\n",
      "| n_updates          | 579           |\n",
      "| policy_entropy     | -0.44612744   |\n",
      "| policy_loss        | 0.002432007   |\n",
      "| serial_timesteps   | 74112         |\n",
      "| time_elapsed       | 53.1          |\n",
      "| total_timesteps    | 74112         |\n",
      "| value_loss         | 1.7668928e-05 |\n",
      "--------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.0015551182 |\n",
      "| clipfrac           | 0.001953125  |\n",
      "| ep_len_mean        | 999          |\n",
      "| ep_reward_mean     | -19.8        |\n",
      "| explained_variance | -0.0388      |\n",
      "| fps                | 1480         |\n",
      "| n_updates          | 580          |\n",
      "| policy_entropy     | -0.44808578  |\n",
      "| policy_loss        | -0.009487022 |\n",
      "| serial_timesteps   | 74240        |\n",
      "| time_elapsed       | 53.2         |\n",
      "| total_timesteps    | 74240        |\n",
      "| value_loss         | 2.91425e-05  |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00064612593 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -19.8         |\n",
      "| explained_variance | 0.0951        |\n",
      "| fps                | 1255          |\n",
      "| n_updates          | 581           |\n",
      "| policy_entropy     | -0.45039594   |\n",
      "| policy_loss        | -0.0037700082 |\n",
      "| serial_timesteps   | 74368         |\n",
      "| time_elapsed       | 53.3          |\n",
      "| total_timesteps    | 74368         |\n",
      "| value_loss         | 3.542362e-05  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 3.585676e-05  |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -19.8         |\n",
      "| explained_variance | 0.163         |\n",
      "| fps                | 1425          |\n",
      "| n_updates          | 582           |\n",
      "| policy_entropy     | -0.4532752    |\n",
      "| policy_loss        | -0.000943801  |\n",
      "| serial_timesteps   | 74496         |\n",
      "| time_elapsed       | 53.4          |\n",
      "| total_timesteps    | 74496         |\n",
      "| value_loss         | 1.2661252e-05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 1.3262532e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -19.8         |\n",
      "| explained_variance | -0.0446       |\n",
      "| fps                | 1429          |\n",
      "| n_updates          | 583           |\n",
      "| policy_entropy     | -0.45655704   |\n",
      "| policy_loss        | -0.0012875525 |\n",
      "| serial_timesteps   | 74624         |\n",
      "| time_elapsed       | 53.4          |\n",
      "| total_timesteps    | 74624         |\n",
      "| value_loss         | 0.00013790504 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 4.9518185e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -19.8         |\n",
      "| explained_variance | 0.0906        |\n",
      "| fps                | 1427          |\n",
      "| n_updates          | 584           |\n",
      "| policy_entropy     | -0.45980906   |\n",
      "| policy_loss        | -0.001226054  |\n",
      "| serial_timesteps   | 74752         |\n",
      "| time_elapsed       | 53.5          |\n",
      "| total_timesteps    | 74752         |\n",
      "| value_loss         | 2.1979697e-05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00017069266 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -19.8         |\n",
      "| explained_variance | -0.791        |\n",
      "| fps                | 1337          |\n",
      "| n_updates          | 585           |\n",
      "| policy_entropy     | -0.46250314   |\n",
      "| policy_loss        | -0.0024047676 |\n",
      "| serial_timesteps   | 74880         |\n",
      "| time_elapsed       | 53.6          |\n",
      "| total_timesteps    | 74880         |\n",
      "| value_loss         | 1.8503464e-05 |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 3.1719857e-05  |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 999            |\n",
      "| ep_reward_mean     | -19.5          |\n",
      "| explained_variance | 0.0402         |\n",
      "| fps                | 1463           |\n",
      "| n_updates          | 586            |\n",
      "| policy_entropy     | -0.4647277     |\n",
      "| policy_loss        | -0.00023506058 |\n",
      "| serial_timesteps   | 75008          |\n",
      "| time_elapsed       | 53.7           |\n",
      "| total_timesteps    | 75008          |\n",
      "| value_loss         | 0.0012859887   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 1.0215348e-05  |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 999            |\n",
      "| ep_reward_mean     | -19.5          |\n",
      "| explained_variance | 0.00254        |\n",
      "| fps                | 1472           |\n",
      "| n_updates          | 587            |\n",
      "| policy_entropy     | -0.46619618    |\n",
      "| policy_loss        | -1.1216151e-05 |\n",
      "| serial_timesteps   | 75136          |\n",
      "| time_elapsed       | 53.8           |\n",
      "| total_timesteps    | 75136          |\n",
      "| value_loss         | 6.936336e-05   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 1.3964777e-05  |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 999            |\n",
      "| ep_reward_mean     | -19.5          |\n",
      "| explained_variance | 0.214          |\n",
      "| fps                | 1465           |\n",
      "| n_updates          | 588            |\n",
      "| policy_entropy     | -0.46958733    |\n",
      "| policy_loss        | -0.00079338555 |\n",
      "| serial_timesteps   | 75264          |\n",
      "| time_elapsed       | 53.9           |\n",
      "| total_timesteps    | 75264          |\n",
      "| value_loss         | 1.872097e-05   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 6.140338e-06   |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 999            |\n",
      "| ep_reward_mean     | -19.5          |\n",
      "| explained_variance | -0.00725       |\n",
      "| fps                | 1410           |\n",
      "| n_updates          | 589            |\n",
      "| policy_entropy     | -0.47360885    |\n",
      "| policy_loss        | -0.00081787165 |\n",
      "| serial_timesteps   | 75392          |\n",
      "| time_elapsed       | 54             |\n",
      "| total_timesteps    | 75392          |\n",
      "| value_loss         | 3.4930013e-05  |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 4.6995488e-06 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -19.5         |\n",
      "| explained_variance | 0.0524        |\n",
      "| fps                | 1507          |\n",
      "| n_updates          | 590           |\n",
      "| policy_entropy     | -0.47729918   |\n",
      "| policy_loss        | -0.0007420109 |\n",
      "| serial_timesteps   | 75520         |\n",
      "| time_elapsed       | 54.1          |\n",
      "| total_timesteps    | 75520         |\n",
      "| value_loss         | 5.70444e-05   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 8.266585e-06  |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -19.5         |\n",
      "| explained_variance | -0.331        |\n",
      "| fps                | 1449          |\n",
      "| n_updates          | 591           |\n",
      "| policy_entropy     | -0.48080987   |\n",
      "| policy_loss        | -0.0008798862 |\n",
      "| serial_timesteps   | 75648         |\n",
      "| time_elapsed       | 54.2          |\n",
      "| total_timesteps    | 75648         |\n",
      "| value_loss         | 4.548087e-05  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 2.681129e-05  |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -19.5         |\n",
      "| explained_variance | -0.453        |\n",
      "| fps                | 1442          |\n",
      "| n_updates          | 592           |\n",
      "| policy_entropy     | -0.48431978   |\n",
      "| policy_loss        | -0.0009519924 |\n",
      "| serial_timesteps   | 75776         |\n",
      "| time_elapsed       | 54.3          |\n",
      "| total_timesteps    | 75776         |\n",
      "| value_loss         | 3.8390746e-05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 4.934182e-05  |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -19.5         |\n",
      "| explained_variance | -0.615        |\n",
      "| fps                | 1361          |\n",
      "| n_updates          | 593           |\n",
      "| policy_entropy     | -0.4872192    |\n",
      "| policy_loss        | -0.0011408139 |\n",
      "| serial_timesteps   | 75904         |\n",
      "| time_elapsed       | 54.3          |\n",
      "| total_timesteps    | 75904         |\n",
      "| value_loss         | 3.4908157e-05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 1.7839431e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -19.3         |\n",
      "| explained_variance | 0.024         |\n",
      "| fps                | 1433          |\n",
      "| n_updates          | 594           |\n",
      "| policy_entropy     | -0.48953798   |\n",
      "| policy_loss        | 0.00022418355 |\n",
      "| serial_timesteps   | 76032         |\n",
      "| time_elapsed       | 54.4          |\n",
      "| total_timesteps    | 76032         |\n",
      "| value_loss         | 0.0012146473  |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 6.7255377e-07  |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 999            |\n",
      "| ep_reward_mean     | -19.3          |\n",
      "| explained_variance | 0.0156         |\n",
      "| fps                | 1411           |\n",
      "| n_updates          | 595            |\n",
      "| policy_entropy     | -0.49073705    |\n",
      "| policy_loss        | -0.00027478556 |\n",
      "| serial_timesteps   | 76160          |\n",
      "| time_elapsed       | 54.5           |\n",
      "| total_timesteps    | 76160          |\n",
      "| value_loss         | 7.392293e-05   |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 2.1456068e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -19.3         |\n",
      "| explained_variance | -0.524        |\n",
      "| fps                | 1444          |\n",
      "| n_updates          | 596           |\n",
      "| policy_entropy     | -0.49276862   |\n",
      "| policy_loss        | -0.0008287218 |\n",
      "| serial_timesteps   | 76288         |\n",
      "| time_elapsed       | 54.6          |\n",
      "| total_timesteps    | 76288         |\n",
      "| value_loss         | 1.5979243e-05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 7.611715e-05  |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -19.3         |\n",
      "| explained_variance | -0.511        |\n",
      "| fps                | 1428          |\n",
      "| n_updates          | 597           |\n",
      "| policy_entropy     | -0.4955228    |\n",
      "| policy_loss        | -0.0010941103 |\n",
      "| serial_timesteps   | 76416         |\n",
      "| time_elapsed       | 54.7          |\n",
      "| total_timesteps    | 76416         |\n",
      "| value_loss         | 3.223369e-05  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 1.9130643e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -19.3         |\n",
      "| explained_variance | 0.057         |\n",
      "| fps                | 1464          |\n",
      "| n_updates          | 598           |\n",
      "| policy_entropy     | -0.49843788   |\n",
      "| policy_loss        | -0.0010884809 |\n",
      "| serial_timesteps   | 76544         |\n",
      "| time_elapsed       | 54.8          |\n",
      "| total_timesteps    | 76544         |\n",
      "| value_loss         | 2.420543e-05  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 6.666225e-05  |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -19.3         |\n",
      "| explained_variance | -0.138        |\n",
      "| fps                | 1480          |\n",
      "| n_updates          | 599           |\n",
      "| policy_entropy     | -0.50084716   |\n",
      "| policy_loss        | -0.0008675986 |\n",
      "| serial_timesteps   | 76672         |\n",
      "| time_elapsed       | 54.9          |\n",
      "| total_timesteps    | 76672         |\n",
      "| value_loss         | 4.9071903e-05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 3.4926968e-06 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -19.3         |\n",
      "| explained_variance | -0.844        |\n",
      "| fps                | 1386          |\n",
      "| n_updates          | 600           |\n",
      "| policy_entropy     | -0.50329655   |\n",
      "| policy_loss        | -0.0005286685 |\n",
      "| serial_timesteps   | 76800         |\n",
      "| time_elapsed       | 55            |\n",
      "| total_timesteps    | 76800         |\n",
      "| value_loss         | 5.0515664e-05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 7.0587903e-06 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -19.1         |\n",
      "| explained_variance | 0.00708       |\n",
      "| fps                | 1437          |\n",
      "| n_updates          | 601           |\n",
      "| policy_entropy     | -0.5052352    |\n",
      "| policy_loss        | -0.0002927325 |\n",
      "| serial_timesteps   | 76928         |\n",
      "| time_elapsed       | 55.1          |\n",
      "| total_timesteps    | 76928         |\n",
      "| value_loss         | 0.0008557596  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 8.1457576e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -19.1         |\n",
      "| explained_variance | 0.0106        |\n",
      "| fps                | 1424          |\n",
      "| n_updates          | 602           |\n",
      "| policy_entropy     | -0.50542176   |\n",
      "| policy_loss        | -0.0015434442 |\n",
      "| serial_timesteps   | 77056         |\n",
      "| time_elapsed       | 55.2          |\n",
      "| total_timesteps    | 77056         |\n",
      "| value_loss         | 5.0174913e-05 |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 1.42332465e-05 |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 999            |\n",
      "| ep_reward_mean     | -19.1          |\n",
      "| explained_variance | -0.000715      |\n",
      "| fps                | 1463           |\n",
      "| n_updates          | 603            |\n",
      "| policy_entropy     | -0.5081622     |\n",
      "| policy_loss        | -0.00078160514 |\n",
      "| serial_timesteps   | 77184          |\n",
      "| time_elapsed       | 55.2           |\n",
      "| total_timesteps    | 77184          |\n",
      "| value_loss         | 4.5158813e-05  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 7.641911e-06   |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 999            |\n",
      "| ep_reward_mean     | -19.1          |\n",
      "| explained_variance | 0.0909         |\n",
      "| fps                | 1379           |\n",
      "| n_updates          | 604            |\n",
      "| policy_entropy     | -0.5116601     |\n",
      "| policy_loss        | -0.00086193834 |\n",
      "| serial_timesteps   | 77312          |\n",
      "| time_elapsed       | 55.3           |\n",
      "| total_timesteps    | 77312          |\n",
      "| value_loss         | 2.3152417e-05  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 3.6366878e-06  |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 999            |\n",
      "| ep_reward_mean     | -19.1          |\n",
      "| explained_variance | -0.126         |\n",
      "| fps                | 1361           |\n",
      "| n_updates          | 605            |\n",
      "| policy_entropy     | -0.5150608     |\n",
      "| policy_loss        | -0.00066056114 |\n",
      "| serial_timesteps   | 77440          |\n",
      "| time_elapsed       | 55.4           |\n",
      "| total_timesteps    | 77440          |\n",
      "| value_loss         | 1.7717193e-05  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 1.9210482e-05  |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 999            |\n",
      "| ep_reward_mean     | -19.1          |\n",
      "| explained_variance | -0.0502        |\n",
      "| fps                | 1463           |\n",
      "| n_updates          | 606            |\n",
      "| policy_entropy     | -0.5181253     |\n",
      "| policy_loss        | -0.00081084133 |\n",
      "| serial_timesteps   | 77568          |\n",
      "| time_elapsed       | 55.5           |\n",
      "| total_timesteps    | 77568          |\n",
      "| value_loss         | 3.5104236e-05  |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 2.8014663e-06 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -19.1         |\n",
      "| explained_variance | -0.257        |\n",
      "| fps                | 1485          |\n",
      "| n_updates          | 607           |\n",
      "| policy_entropy     | -0.5210799    |\n",
      "| policy_loss        | -0.0005709536 |\n",
      "| serial_timesteps   | 77696         |\n",
      "| time_elapsed       | 55.6          |\n",
      "| total_timesteps    | 77696         |\n",
      "| value_loss         | 3.2334585e-05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 1.9694785e-06 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -19.1         |\n",
      "| explained_variance | 0.0422        |\n",
      "| fps                | 1367          |\n",
      "| n_updates          | 608           |\n",
      "| policy_entropy     | -0.52409554   |\n",
      "| policy_loss        | -0.0004895035 |\n",
      "| serial_timesteps   | 77824         |\n",
      "| time_elapsed       | 55.7          |\n",
      "| total_timesteps    | 77824         |\n",
      "| value_loss         | 2.1203472e-05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 2.367944e-06  |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -18.8         |\n",
      "| explained_variance | -0.0162       |\n",
      "| fps                | 1449          |\n",
      "| n_updates          | 609           |\n",
      "| policy_entropy     | -0.52670866   |\n",
      "| policy_loss        | -7.285387e-05 |\n",
      "| serial_timesteps   | 77952         |\n",
      "| time_elapsed       | 55.8          |\n",
      "| total_timesteps    | 77952         |\n",
      "| value_loss         | 0.000941125   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 2.5794798e-06  |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 999            |\n",
      "| ep_reward_mean     | -18.8          |\n",
      "| explained_variance | 0.208          |\n",
      "| fps                | 1449           |\n",
      "| n_updates          | 610            |\n",
      "| policy_entropy     | -0.52807015    |\n",
      "| policy_loss        | -0.00036202092 |\n",
      "| serial_timesteps   | 78080          |\n",
      "| time_elapsed       | 55.9           |\n",
      "| total_timesteps    | 78080          |\n",
      "| value_loss         | 6.637409e-05   |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 6.5095464e-06 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -18.8         |\n",
      "| explained_variance | 0.0736        |\n",
      "| fps                | 1393          |\n",
      "| n_updates          | 611           |\n",
      "| policy_entropy     | -0.5305473    |\n",
      "| policy_loss        | -0.0005169534 |\n",
      "| serial_timesteps   | 78208         |\n",
      "| time_elapsed       | 56            |\n",
      "| total_timesteps    | 78208         |\n",
      "| value_loss         | 6.683029e-05  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 5.63357e-05   |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -18.8         |\n",
      "| explained_variance | -0.55         |\n",
      "| fps                | 1448          |\n",
      "| n_updates          | 612           |\n",
      "| policy_entropy     | -0.53358245   |\n",
      "| policy_loss        | -0.0018949553 |\n",
      "| serial_timesteps   | 78336         |\n",
      "| time_elapsed       | 56.1          |\n",
      "| total_timesteps    | 78336         |\n",
      "| value_loss         | 5.720108e-05  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 3.234177e-05  |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -18.8         |\n",
      "| explained_variance | 0.213         |\n",
      "| fps                | 1387          |\n",
      "| n_updates          | 613           |\n",
      "| policy_entropy     | -0.5371609    |\n",
      "| policy_loss        | -0.0006554801 |\n",
      "| serial_timesteps   | 78464         |\n",
      "| time_elapsed       | 56.2          |\n",
      "| total_timesteps    | 78464         |\n",
      "| value_loss         | 3.0168694e-05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 9.680352e-06  |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -18.8         |\n",
      "| explained_variance | -2.05         |\n",
      "| fps                | 1451          |\n",
      "| n_updates          | 614           |\n",
      "| policy_entropy     | -0.5409928    |\n",
      "| policy_loss        | -0.0004984421 |\n",
      "| serial_timesteps   | 78592         |\n",
      "| time_elapsed       | 56.2          |\n",
      "| total_timesteps    | 78592         |\n",
      "| value_loss         | 4.293426e-05  |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 1.1820147e-05  |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 999            |\n",
      "| ep_reward_mean     | -18.8          |\n",
      "| explained_variance | -0.45          |\n",
      "| fps                | 1387           |\n",
      "| n_updates          | 615            |\n",
      "| policy_entropy     | -0.5442388     |\n",
      "| policy_loss        | -0.00048358063 |\n",
      "| serial_timesteps   | 78720          |\n",
      "| time_elapsed       | 56.3           |\n",
      "| total_timesteps    | 78720          |\n",
      "| value_loss         | 3.590704e-05   |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 1.0601594e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -18.8         |\n",
      "| explained_variance | 0.472         |\n",
      "| fps                | 1423          |\n",
      "| n_updates          | 616           |\n",
      "| policy_entropy     | -0.5471012    |\n",
      "| policy_loss        | -0.000852261  |\n",
      "| serial_timesteps   | 78848         |\n",
      "| time_elapsed       | 56.4          |\n",
      "| total_timesteps    | 78848         |\n",
      "| value_loss         | 1.09501e-05   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 2.2839472e-06  |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 999            |\n",
      "| ep_reward_mean     | -18.6          |\n",
      "| explained_variance | -0.0708        |\n",
      "| fps                | 1497           |\n",
      "| n_updates          | 617            |\n",
      "| policy_entropy     | -0.5490975     |\n",
      "| policy_loss        | -0.00015983544 |\n",
      "| serial_timesteps   | 78976          |\n",
      "| time_elapsed       | 56.5           |\n",
      "| total_timesteps    | 78976          |\n",
      "| value_loss         | 0.001058558    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 2.4990226e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -18.6         |\n",
      "| explained_variance | -0.256        |\n",
      "| fps                | 1510          |\n",
      "| n_updates          | 618           |\n",
      "| policy_entropy     | -0.55119425   |\n",
      "| policy_loss        | -0.001387909  |\n",
      "| serial_timesteps   | 79104         |\n",
      "| time_elapsed       | 56.6          |\n",
      "| total_timesteps    | 79104         |\n",
      "| value_loss         | 7.188022e-05  |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 1.538595e-05   |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 999            |\n",
      "| ep_reward_mean     | -18.6          |\n",
      "| explained_variance | 0.0325         |\n",
      "| fps                | 1340           |\n",
      "| n_updates          | 619            |\n",
      "| policy_entropy     | -0.55456674    |\n",
      "| policy_loss        | -0.00068948173 |\n",
      "| serial_timesteps   | 79232          |\n",
      "| time_elapsed       | 56.7           |\n",
      "| total_timesteps    | 79232          |\n",
      "| value_loss         | 6.539196e-05   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 3.985167e-06   |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 999            |\n",
      "| ep_reward_mean     | -18.6          |\n",
      "| explained_variance | -0.391         |\n",
      "| fps                | 1418           |\n",
      "| n_updates          | 620            |\n",
      "| policy_entropy     | -0.557803      |\n",
      "| policy_loss        | -0.00063036586 |\n",
      "| serial_timesteps   | 79360          |\n",
      "| time_elapsed       | 56.8           |\n",
      "| total_timesteps    | 79360          |\n",
      "| value_loss         | 3.7342026e-05  |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 2.1764929e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -18.6         |\n",
      "| explained_variance | 0.147         |\n",
      "| fps                | 1468          |\n",
      "| n_updates          | 621           |\n",
      "| policy_entropy     | -0.56085443   |\n",
      "| policy_loss        | -0.0015544647 |\n",
      "| serial_timesteps   | 79488         |\n",
      "| time_elapsed       | 56.9          |\n",
      "| total_timesteps    | 79488         |\n",
      "| value_loss         | 2.7480964e-05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 1.3927218e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -18.6         |\n",
      "| explained_variance | 0.161         |\n",
      "| fps                | 1403          |\n",
      "| n_updates          | 622           |\n",
      "| policy_entropy     | -0.56377375   |\n",
      "| policy_loss        | -0.0011419967 |\n",
      "| serial_timesteps   | 79616         |\n",
      "| time_elapsed       | 57            |\n",
      "| total_timesteps    | 79616         |\n",
      "| value_loss         | 1.8176273e-05 |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 6.228374e-06   |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 999            |\n",
      "| ep_reward_mean     | -18.6          |\n",
      "| explained_variance | -0.262         |\n",
      "| fps                | 1424           |\n",
      "| n_updates          | 623            |\n",
      "| policy_entropy     | -0.56707144    |\n",
      "| policy_loss        | -0.00052686967 |\n",
      "| serial_timesteps   | 79744          |\n",
      "| time_elapsed       | 57.1           |\n",
      "| total_timesteps    | 79744          |\n",
      "| value_loss         | 1.8960623e-05  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 3.660572e-06   |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 999            |\n",
      "| ep_reward_mean     | -18.6          |\n",
      "| explained_variance | 0.00391        |\n",
      "| fps                | 1476           |\n",
      "| n_updates          | 624            |\n",
      "| policy_entropy     | -0.57023335    |\n",
      "| policy_loss        | -0.00047482608 |\n",
      "| serial_timesteps   | 79872          |\n",
      "| time_elapsed       | 57.1           |\n",
      "| total_timesteps    | 79872          |\n",
      "| value_loss         | 2.417203e-05   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 6.799485e-06   |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 999            |\n",
      "| ep_reward_mean     | -18.4          |\n",
      "| explained_variance | 0.0224         |\n",
      "| fps                | 1452           |\n",
      "| n_updates          | 625            |\n",
      "| policy_entropy     | -0.5727419     |\n",
      "| policy_loss        | -0.00028628344 |\n",
      "| serial_timesteps   | 80000          |\n",
      "| time_elapsed       | 57.2           |\n",
      "| total_timesteps    | 80000          |\n",
      "| value_loss         | 0.00093166647  |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 3.0941928e-06 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -18.4         |\n",
      "| explained_variance | -0.0461       |\n",
      "| fps                | 1456          |\n",
      "| n_updates          | 626           |\n",
      "| policy_entropy     | -0.57437974   |\n",
      "| policy_loss        | -0.0004256107 |\n",
      "| serial_timesteps   | 80128         |\n",
      "| time_elapsed       | 57.3          |\n",
      "| total_timesteps    | 80128         |\n",
      "| value_loss         | 2.3256489e-05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 5.092285e-05  |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -18.4         |\n",
      "| explained_variance | 0.0581        |\n",
      "| fps                | 1376          |\n",
      "| n_updates          | 627           |\n",
      "| policy_entropy     | -0.57721114   |\n",
      "| policy_loss        | -0.00203604   |\n",
      "| serial_timesteps   | 80256         |\n",
      "| time_elapsed       | 57.4          |\n",
      "| total_timesteps    | 80256         |\n",
      "| value_loss         | 1.5143703e-05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 5.0149152e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -18.4         |\n",
      "| explained_variance | -0.0997       |\n",
      "| fps                | 1287          |\n",
      "| n_updates          | 628           |\n",
      "| policy_entropy     | -0.58022344   |\n",
      "| policy_loss        | 0.00054045604 |\n",
      "| serial_timesteps   | 80384         |\n",
      "| time_elapsed       | 57.5          |\n",
      "| total_timesteps    | 80384         |\n",
      "| value_loss         | 1.4684278e-05 |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 2.8596096e-05  |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 999            |\n",
      "| ep_reward_mean     | -18.4          |\n",
      "| explained_variance | 0.0634         |\n",
      "| fps                | 1311           |\n",
      "| n_updates          | 629            |\n",
      "| policy_entropy     | -0.5833912     |\n",
      "| policy_loss        | -0.00093761506 |\n",
      "| serial_timesteps   | 80512          |\n",
      "| time_elapsed       | 57.6           |\n",
      "| total_timesteps    | 80512          |\n",
      "| value_loss         | 1.0133529e-05  |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 5.1499646e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -18.4         |\n",
      "| explained_variance | 0.00137       |\n",
      "| fps                | 1296          |\n",
      "| n_updates          | 630           |\n",
      "| policy_entropy     | -0.5869333    |\n",
      "| policy_loss        | -0.0013329714 |\n",
      "| serial_timesteps   | 80640         |\n",
      "| time_elapsed       | 57.7          |\n",
      "| total_timesteps    | 80640         |\n",
      "| value_loss         | 9.2484595e-05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 2.6774716e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -18.4         |\n",
      "| explained_variance | 0.0827        |\n",
      "| fps                | 1436          |\n",
      "| n_updates          | 631           |\n",
      "| policy_entropy     | -0.59039855   |\n",
      "| policy_loss        | -0.0014493682 |\n",
      "| serial_timesteps   | 80768         |\n",
      "| time_elapsed       | 57.8          |\n",
      "| total_timesteps    | 80768         |\n",
      "| value_loss         | 4.244139e-05  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 4.599663e-06  |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -18.4         |\n",
      "| explained_variance | -0.00801      |\n",
      "| fps                | 1466          |\n",
      "| n_updates          | 632           |\n",
      "| policy_entropy     | -0.5938037    |\n",
      "| policy_loss        | -0.0004320555 |\n",
      "| serial_timesteps   | 80896         |\n",
      "| time_elapsed       | 57.9          |\n",
      "| total_timesteps    | 80896         |\n",
      "| value_loss         | 1.5703072e-05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00010511518 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -18.2         |\n",
      "| explained_variance | 0.0196        |\n",
      "| fps                | 1437          |\n",
      "| n_updates          | 633           |\n",
      "| policy_entropy     | -0.59624773   |\n",
      "| policy_loss        | -0.0007947369 |\n",
      "| serial_timesteps   | 81024         |\n",
      "| time_elapsed       | 58            |\n",
      "| total_timesteps    | 81024         |\n",
      "| value_loss         | 0.0008186625  |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 3.601018e-05   |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 999            |\n",
      "| ep_reward_mean     | -18.2          |\n",
      "| explained_variance | 0.0439         |\n",
      "| fps                | 1426           |\n",
      "| n_updates          | 634            |\n",
      "| policy_entropy     | -0.597554      |\n",
      "| policy_loss        | -0.00012601342 |\n",
      "| serial_timesteps   | 81152          |\n",
      "| time_elapsed       | 58.1           |\n",
      "| total_timesteps    | 81152          |\n",
      "| value_loss         | 2.2552758e-05  |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 2.7173795e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -18.2         |\n",
      "| explained_variance | 0.0813        |\n",
      "| fps                | 1480          |\n",
      "| n_updates          | 635           |\n",
      "| policy_entropy     | -0.60084295   |\n",
      "| policy_loss        | -0.001076299  |\n",
      "| serial_timesteps   | 81280         |\n",
      "| time_elapsed       | 58.2          |\n",
      "| total_timesteps    | 81280         |\n",
      "| value_loss         | 2.2364122e-05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0007063596  |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -18.2         |\n",
      "| explained_variance | -0.0265       |\n",
      "| fps                | 1460          |\n",
      "| n_updates          | 636           |\n",
      "| policy_entropy     | -0.6040508    |\n",
      "| policy_loss        | -0.008015364  |\n",
      "| serial_timesteps   | 81408         |\n",
      "| time_elapsed       | 58.3          |\n",
      "| total_timesteps    | 81408         |\n",
      "| value_loss         | 1.1479704e-05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00012133196 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -18.2         |\n",
      "| explained_variance | -0.114        |\n",
      "| fps                | 1423          |\n",
      "| n_updates          | 637           |\n",
      "| policy_entropy     | -0.6067977    |\n",
      "| policy_loss        | 0.00035353098 |\n",
      "| serial_timesteps   | 81536         |\n",
      "| time_elapsed       | 58.3          |\n",
      "| total_timesteps    | 81536         |\n",
      "| value_loss         | 2.4312649e-05 |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 0.000310101    |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 999            |\n",
      "| ep_reward_mean     | -18.2          |\n",
      "| explained_variance | -0.357         |\n",
      "| fps                | 1375           |\n",
      "| n_updates          | 638            |\n",
      "| policy_entropy     | -0.60960376    |\n",
      "| policy_loss        | -2.3196917e-05 |\n",
      "| serial_timesteps   | 81664          |\n",
      "| time_elapsed       | 58.4           |\n",
      "| total_timesteps    | 81664          |\n",
      "| value_loss         | 3.96322e-05    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00014471161 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -18.2         |\n",
      "| explained_variance | 0.113         |\n",
      "| fps                | 1458          |\n",
      "| n_updates          | 639           |\n",
      "| policy_entropy     | -0.61277944   |\n",
      "| policy_loss        | -0.0023572599 |\n",
      "| serial_timesteps   | 81792         |\n",
      "| time_elapsed       | 58.5          |\n",
      "| total_timesteps    | 81792         |\n",
      "| value_loss         | 1.2977927e-05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 2.2366788e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -18           |\n",
      "| explained_variance | 0.0397        |\n",
      "| fps                | 1455          |\n",
      "| n_updates          | 640           |\n",
      "| policy_entropy     | -0.61582464   |\n",
      "| policy_loss        | -0.0006249165 |\n",
      "| serial_timesteps   | 81920         |\n",
      "| time_elapsed       | 58.6          |\n",
      "| total_timesteps    | 81920         |\n",
      "| value_loss         | 0.0008604424  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00016633522 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -18           |\n",
      "| explained_variance | -0.0834       |\n",
      "| fps                | 1357          |\n",
      "| n_updates          | 641           |\n",
      "| policy_entropy     | -0.6175496    |\n",
      "| policy_loss        | -0.0006111098 |\n",
      "| serial_timesteps   | 82048         |\n",
      "| time_elapsed       | 58.7          |\n",
      "| total_timesteps    | 82048         |\n",
      "| value_loss         | 4.315961e-05  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00023918661 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -18           |\n",
      "| explained_variance | -0.287        |\n",
      "| fps                | 1438          |\n",
      "| n_updates          | 642           |\n",
      "| policy_entropy     | -0.6201113    |\n",
      "| policy_loss        | -0.0027757045 |\n",
      "| serial_timesteps   | 82176         |\n",
      "| time_elapsed       | 58.8          |\n",
      "| total_timesteps    | 82176         |\n",
      "| value_loss         | 2.7967228e-05 |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 2.116489e-05   |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 999            |\n",
      "| ep_reward_mean     | -18            |\n",
      "| explained_variance | 0.143          |\n",
      "| fps                | 1468           |\n",
      "| n_updates          | 643            |\n",
      "| policy_entropy     | -0.62295634    |\n",
      "| policy_loss        | -0.00015075004 |\n",
      "| serial_timesteps   | 82304          |\n",
      "| time_elapsed       | 58.9           |\n",
      "| total_timesteps    | 82304          |\n",
      "| value_loss         | 2.575053e-05   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 2.4045692e-05  |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 999            |\n",
      "| ep_reward_mean     | -18            |\n",
      "| explained_variance | 0.336          |\n",
      "| fps                | 1446           |\n",
      "| n_updates          | 644            |\n",
      "| policy_entropy     | -0.6261819     |\n",
      "| policy_loss        | -0.00057176035 |\n",
      "| serial_timesteps   | 82432          |\n",
      "| time_elapsed       | 59             |\n",
      "| total_timesteps    | 82432          |\n",
      "| value_loss         | 2.030711e-05   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 3.6463662e-06  |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 999            |\n",
      "| ep_reward_mean     | -18            |\n",
      "| explained_variance | -1.34          |\n",
      "| fps                | 1421           |\n",
      "| n_updates          | 645            |\n",
      "| policy_entropy     | -0.6294316     |\n",
      "| policy_loss        | -0.00050217484 |\n",
      "| serial_timesteps   | 82560          |\n",
      "| time_elapsed       | 59.1           |\n",
      "| total_timesteps    | 82560          |\n",
      "| value_loss         | 3.1089843e-05  |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00037681375 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -18           |\n",
      "| explained_variance | -0.311        |\n",
      "| fps                | 1476          |\n",
      "| n_updates          | 646           |\n",
      "| policy_entropy     | -0.6326373    |\n",
      "| policy_loss        | -0.0018301192 |\n",
      "| serial_timesteps   | 82688         |\n",
      "| time_elapsed       | 59.2          |\n",
      "| total_timesteps    | 82688         |\n",
      "| value_loss         | 1.5031823e-05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0005035919  |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -18           |\n",
      "| explained_variance | -0.687        |\n",
      "| fps                | 1479          |\n",
      "| n_updates          | 647           |\n",
      "| policy_entropy     | -0.6350792    |\n",
      "| policy_loss        | -0.0015681146 |\n",
      "| serial_timesteps   | 82816         |\n",
      "| time_elapsed       | 59.2          |\n",
      "| total_timesteps    | 82816         |\n",
      "| value_loss         | 1.0511003e-05 |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 0.00028816634  |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 999            |\n",
      "| ep_reward_mean     | -17.8          |\n",
      "| explained_variance | 0.0326         |\n",
      "| fps                | 1354           |\n",
      "| n_updates          | 648            |\n",
      "| policy_entropy     | -0.63695055    |\n",
      "| policy_loss        | -0.00030183187 |\n",
      "| serial_timesteps   | 82944          |\n",
      "| time_elapsed       | 59.3           |\n",
      "| total_timesteps    | 82944          |\n",
      "| value_loss         | 0.00070321787  |\n",
      "---------------------------------------\n",
      "-------------------------------------\n",
      "| approxkl           | 0.00170628   |\n",
      "| clipfrac           | 0.0078125    |\n",
      "| ep_len_mean        | 999          |\n",
      "| ep_reward_mean     | -17.8        |\n",
      "| explained_variance | 0.0162       |\n",
      "| fps                | 1336         |\n",
      "| n_updates          | 649          |\n",
      "| policy_entropy     | -0.6380504   |\n",
      "| policy_loss        | -0.01597473  |\n",
      "| serial_timesteps   | 83072        |\n",
      "| time_elapsed       | 59.4         |\n",
      "| total_timesteps    | 83072        |\n",
      "| value_loss         | 4.060988e-05 |\n",
      "-------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0002615378  |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -17.8         |\n",
      "| explained_variance | 0.0387        |\n",
      "| fps                | 1437          |\n",
      "| n_updates          | 650           |\n",
      "| policy_entropy     | -0.64002305   |\n",
      "| policy_loss        | -0.0003786137 |\n",
      "| serial_timesteps   | 83200         |\n",
      "| time_elapsed       | 59.5          |\n",
      "| total_timesteps    | 83200         |\n",
      "| value_loss         | 1.4704476e-05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 2.211806e-05  |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -17.8         |\n",
      "| explained_variance | -0.258        |\n",
      "| fps                | 1415          |\n",
      "| n_updates          | 651           |\n",
      "| policy_entropy     | -0.64329976   |\n",
      "| policy_loss        | -0.0009267465 |\n",
      "| serial_timesteps   | 83328         |\n",
      "| time_elapsed       | 59.6          |\n",
      "| total_timesteps    | 83328         |\n",
      "| value_loss         | 2.6644182e-05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 2.9097011e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -17.8         |\n",
      "| explained_variance | -0.153        |\n",
      "| fps                | 1478          |\n",
      "| n_updates          | 652           |\n",
      "| policy_entropy     | -0.64671457   |\n",
      "| policy_loss        | -0.0003889217 |\n",
      "| serial_timesteps   | 83456         |\n",
      "| time_elapsed       | 59.7          |\n",
      "| total_timesteps    | 83456         |\n",
      "| value_loss         | 1.6300932e-05 |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 4.6760262e-05  |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 999            |\n",
      "| ep_reward_mean     | -17.8          |\n",
      "| explained_variance | 0.0404         |\n",
      "| fps                | 1368           |\n",
      "| n_updates          | 653            |\n",
      "| policy_entropy     | -0.6499329     |\n",
      "| policy_loss        | -0.00090499315 |\n",
      "| serial_timesteps   | 83584          |\n",
      "| time_elapsed       | 59.8           |\n",
      "| total_timesteps    | 83584          |\n",
      "| value_loss         | 1.33255035e-05 |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 2.5927246e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -17.8         |\n",
      "| explained_variance | -0.0751       |\n",
      "| fps                | 1458          |\n",
      "| n_updates          | 654           |\n",
      "| policy_entropy     | -0.6537985    |\n",
      "| policy_loss        | -0.0013646048 |\n",
      "| serial_timesteps   | 83712         |\n",
      "| time_elapsed       | 59.9          |\n",
      "| total_timesteps    | 83712         |\n",
      "| value_loss         | 1.7073766e-05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 7.294391e-05  |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -17.8         |\n",
      "| explained_variance | -0.0213       |\n",
      "| fps                | 1425          |\n",
      "| n_updates          | 655           |\n",
      "| policy_entropy     | -0.6579398    |\n",
      "| policy_loss        | -0.0019553872 |\n",
      "| serial_timesteps   | 83840         |\n",
      "| time_elapsed       | 60            |\n",
      "| total_timesteps    | 83840         |\n",
      "| value_loss         | 2.0728945e-05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00030018983 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -17.6         |\n",
      "| explained_variance | -0.0398       |\n",
      "| fps                | 1369          |\n",
      "| n_updates          | 656           |\n",
      "| policy_entropy     | -0.66103715   |\n",
      "| policy_loss        | -0.0017310375 |\n",
      "| serial_timesteps   | 83968         |\n",
      "| time_elapsed       | 60.1          |\n",
      "| total_timesteps    | 83968         |\n",
      "| value_loss         | 0.000873453   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 6.3059386e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -17.6         |\n",
      "| explained_variance | -0.335        |\n",
      "| fps                | 1407          |\n",
      "| n_updates          | 657           |\n",
      "| policy_entropy     | -0.6638928    |\n",
      "| policy_loss        | -0.0007866707 |\n",
      "| serial_timesteps   | 84096         |\n",
      "| time_elapsed       | 60.2          |\n",
      "| total_timesteps    | 84096         |\n",
      "| value_loss         | 7.274783e-05  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 7.06726e-06   |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -17.6         |\n",
      "| explained_variance | 0.0274        |\n",
      "| fps                | 1462          |\n",
      "| n_updates          | 658           |\n",
      "| policy_entropy     | -0.6672702    |\n",
      "| policy_loss        | -0.0008929421 |\n",
      "| serial_timesteps   | 84224         |\n",
      "| time_elapsed       | 60.2          |\n",
      "| total_timesteps    | 84224         |\n",
      "| value_loss         | 2.3225262e-05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 1.7240069e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -17.6         |\n",
      "| explained_variance | 0.182         |\n",
      "| fps                | 1283          |\n",
      "| n_updates          | 659           |\n",
      "| policy_entropy     | -0.67036027   |\n",
      "| policy_loss        | -0.0009824575 |\n",
      "| serial_timesteps   | 84352         |\n",
      "| time_elapsed       | 60.3          |\n",
      "| total_timesteps    | 84352         |\n",
      "| value_loss         | 3.3441214e-05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00015119086 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -17.6         |\n",
      "| explained_variance | 0.15          |\n",
      "| fps                | 1421          |\n",
      "| n_updates          | 660           |\n",
      "| policy_entropy     | -0.6732403    |\n",
      "| policy_loss        | -0.002818368  |\n",
      "| serial_timesteps   | 84480         |\n",
      "| time_elapsed       | 60.4          |\n",
      "| total_timesteps    | 84480         |\n",
      "| value_loss         | 1.8602004e-05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0003749972  |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -17.6         |\n",
      "| explained_variance | -0.864        |\n",
      "| fps                | 1416          |\n",
      "| n_updates          | 661           |\n",
      "| policy_entropy     | -0.67612475   |\n",
      "| policy_loss        | -0.0050124894 |\n",
      "| serial_timesteps   | 84608         |\n",
      "| time_elapsed       | 60.5          |\n",
      "| total_timesteps    | 84608         |\n",
      "| value_loss         | 2.2975008e-05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 7.571836e-05  |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -17.6         |\n",
      "| explained_variance | -0.529        |\n",
      "| fps                | 1415          |\n",
      "| n_updates          | 662           |\n",
      "| policy_entropy     | -0.67863524   |\n",
      "| policy_loss        | 0.0007299358  |\n",
      "| serial_timesteps   | 84736         |\n",
      "| time_elapsed       | 60.6          |\n",
      "| total_timesteps    | 84736         |\n",
      "| value_loss         | 1.6245003e-05 |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 0.000110479654 |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 999            |\n",
      "| ep_reward_mean     | -17.6          |\n",
      "| explained_variance | -0.246         |\n",
      "| fps                | 1445           |\n",
      "| n_updates          | 663            |\n",
      "| policy_entropy     | -0.6811439     |\n",
      "| policy_loss        | -0.0030742288  |\n",
      "| serial_timesteps   | 84864          |\n",
      "| time_elapsed       | 60.7           |\n",
      "| total_timesteps    | 84864          |\n",
      "| value_loss         | 1.5019895e-05  |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 8.994757e-06  |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -17.4         |\n",
      "| explained_variance | -0.0178       |\n",
      "| fps                | 1361          |\n",
      "| n_updates          | 664           |\n",
      "| policy_entropy     | -0.6835115    |\n",
      "| policy_loss        | -7.424725e-05 |\n",
      "| serial_timesteps   | 84992         |\n",
      "| time_elapsed       | 60.8          |\n",
      "| total_timesteps    | 84992         |\n",
      "| value_loss         | 0.00077542826 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 1.3299516e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -17.4         |\n",
      "| explained_variance | -0.422        |\n",
      "| fps                | 1432          |\n",
      "| n_updates          | 665           |\n",
      "| policy_entropy     | -0.685313     |\n",
      "| policy_loss        | -0.0002249481 |\n",
      "| serial_timesteps   | 85120         |\n",
      "| time_elapsed       | 60.9          |\n",
      "| total_timesteps    | 85120         |\n",
      "| value_loss         | 2.2947408e-05 |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 7.62969e-06    |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 999            |\n",
      "| ep_reward_mean     | -17.4          |\n",
      "| explained_variance | 0.201          |\n",
      "| fps                | 1405           |\n",
      "| n_updates          | 666            |\n",
      "| policy_entropy     | -0.6882279     |\n",
      "| policy_loss        | -0.00073265785 |\n",
      "| serial_timesteps   | 85248          |\n",
      "| time_elapsed       | 61             |\n",
      "| total_timesteps    | 85248          |\n",
      "| value_loss         | 8.3015875e-06  |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 1.1783394e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -17.4         |\n",
      "| explained_variance | 0.0167        |\n",
      "| fps                | 1377          |\n",
      "| n_updates          | 667           |\n",
      "| policy_entropy     | -0.6916664    |\n",
      "| policy_loss        | -0.0012640584 |\n",
      "| serial_timesteps   | 85376         |\n",
      "| time_elapsed       | 61.1          |\n",
      "| total_timesteps    | 85376         |\n",
      "| value_loss         | 1.812515e-05  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 1.1606818e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -17.4         |\n",
      "| explained_variance | -0.125        |\n",
      "| fps                | 1393          |\n",
      "| n_updates          | 668           |\n",
      "| policy_entropy     | -0.69560236   |\n",
      "| policy_loss        | -0.0009960795 |\n",
      "| serial_timesteps   | 85504         |\n",
      "| time_elapsed       | 61.2          |\n",
      "| total_timesteps    | 85504         |\n",
      "| value_loss         | 1.2779837e-05 |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 7.527364e-06   |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 999            |\n",
      "| ep_reward_mean     | -17.4          |\n",
      "| explained_variance | 0.067          |\n",
      "| fps                | 1484           |\n",
      "| n_updates          | 669            |\n",
      "| policy_entropy     | -0.6993115     |\n",
      "| policy_loss        | -0.00087447476 |\n",
      "| serial_timesteps   | 85632          |\n",
      "| time_elapsed       | 61.3           |\n",
      "| total_timesteps    | 85632          |\n",
      "| value_loss         | 2.6044934e-05  |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 5.270434e-05  |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -17.4         |\n",
      "| explained_variance | 0.198         |\n",
      "| fps                | 1417          |\n",
      "| n_updates          | 670           |\n",
      "| policy_entropy     | -0.7024183    |\n",
      "| policy_loss        | -0.0008244115 |\n",
      "| serial_timesteps   | 85760         |\n",
      "| time_elapsed       | 61.3          |\n",
      "| total_timesteps    | 85760         |\n",
      "| value_loss         | 1.5844127e-05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 1.3189664e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -17.4         |\n",
      "| explained_variance | 0.329         |\n",
      "| fps                | 1474          |\n",
      "| n_updates          | 671           |\n",
      "| policy_entropy     | -0.7049966    |\n",
      "| policy_loss        | -0.0006921374 |\n",
      "| serial_timesteps   | 85888         |\n",
      "| time_elapsed       | 61.4          |\n",
      "| total_timesteps    | 85888         |\n",
      "| value_loss         | 9.053466e-06  |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 1.2434284e-05  |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 999            |\n",
      "| ep_reward_mean     | -17.3          |\n",
      "| explained_variance | -0.058         |\n",
      "| fps                | 1471           |\n",
      "| n_updates          | 672            |\n",
      "| policy_entropy     | -0.7075592     |\n",
      "| policy_loss        | -0.00033446494 |\n",
      "| serial_timesteps   | 86016          |\n",
      "| time_elapsed       | 61.5           |\n",
      "| total_timesteps    | 86016          |\n",
      "| value_loss         | 0.0007050468   |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 1.2802692e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -17.3         |\n",
      "| explained_variance | -0.168        |\n",
      "| fps                | 1458          |\n",
      "| n_updates          | 673           |\n",
      "| policy_entropy     | -0.7095435    |\n",
      "| policy_loss        | -0.0006650557 |\n",
      "| serial_timesteps   | 86144         |\n",
      "| time_elapsed       | 61.6          |\n",
      "| total_timesteps    | 86144         |\n",
      "| value_loss         | 1.0306821e-05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 8.477462e-06  |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -17.3         |\n",
      "| explained_variance | 0.137         |\n",
      "| fps                | 1459          |\n",
      "| n_updates          | 674           |\n",
      "| policy_entropy     | -0.7128152    |\n",
      "| policy_loss        | -0.0007963374 |\n",
      "| serial_timesteps   | 86272         |\n",
      "| time_elapsed       | 61.7          |\n",
      "| total_timesteps    | 86272         |\n",
      "| value_loss         | 1.8873981e-05 |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 7.189748e-05   |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 999            |\n",
      "| ep_reward_mean     | -17.3          |\n",
      "| explained_variance | 0.231          |\n",
      "| fps                | 1309           |\n",
      "| n_updates          | 675            |\n",
      "| policy_entropy     | -0.7158578     |\n",
      "| policy_loss        | -0.0013878553  |\n",
      "| serial_timesteps   | 86400          |\n",
      "| time_elapsed       | 61.8           |\n",
      "| total_timesteps    | 86400          |\n",
      "| value_loss         | 1.29416985e-05 |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 1.4721371e-05  |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 999            |\n",
      "| ep_reward_mean     | -17.3          |\n",
      "| explained_variance | -0.475         |\n",
      "| fps                | 1506           |\n",
      "| n_updates          | 676            |\n",
      "| policy_entropy     | -0.7186421     |\n",
      "| policy_loss        | -0.00072215847 |\n",
      "| serial_timesteps   | 86528          |\n",
      "| time_elapsed       | 61.9           |\n",
      "| total_timesteps    | 86528          |\n",
      "| value_loss         | 1.3895809e-05  |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 1.5221504e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -17.3         |\n",
      "| explained_variance | -0.24         |\n",
      "| fps                | 1418          |\n",
      "| n_updates          | 677           |\n",
      "| policy_entropy     | -0.7212754    |\n",
      "| policy_loss        | -0.0003589053 |\n",
      "| serial_timesteps   | 86656         |\n",
      "| time_elapsed       | 62            |\n",
      "| total_timesteps    | 86656         |\n",
      "| value_loss         | 9.572677e-06  |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 6.5167997e-06  |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 999            |\n",
      "| ep_reward_mean     | -17.3          |\n",
      "| explained_variance | 0.0297         |\n",
      "| fps                | 1332           |\n",
      "| n_updates          | 678            |\n",
      "| policy_entropy     | -0.7242508     |\n",
      "| policy_loss        | -0.00048768788 |\n",
      "| serial_timesteps   | 86784          |\n",
      "| time_elapsed       | 62.1           |\n",
      "| total_timesteps    | 86784          |\n",
      "| value_loss         | 1.1619649e-05  |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 7.0223205e-06 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -17.3         |\n",
      "| explained_variance | 0.0613        |\n",
      "| fps                | 1490          |\n",
      "| n_updates          | 679           |\n",
      "| policy_entropy     | -0.7278356    |\n",
      "| policy_loss        | -0.0008207583 |\n",
      "| serial_timesteps   | 86912         |\n",
      "| time_elapsed       | 62.2          |\n",
      "| total_timesteps    | 86912         |\n",
      "| value_loss         | 1.6502756e-05 |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 1.6058984e-05  |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 999            |\n",
      "| ep_reward_mean     | -17.1          |\n",
      "| explained_variance | -0.0427        |\n",
      "| fps                | 1478           |\n",
      "| n_updates          | 680            |\n",
      "| policy_entropy     | -0.7321518     |\n",
      "| policy_loss        | -0.00090536353 |\n",
      "| serial_timesteps   | 87040          |\n",
      "| time_elapsed       | 62.2           |\n",
      "| total_timesteps    | 87040          |\n",
      "| value_loss         | 9.099665e-05   |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 5.4629045e-06 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -17.1         |\n",
      "| explained_variance | -0.0376       |\n",
      "| fps                | 1463          |\n",
      "| n_updates          | 681           |\n",
      "| policy_entropy     | -0.7357943    |\n",
      "| policy_loss        | -0.0006262186 |\n",
      "| serial_timesteps   | 87168         |\n",
      "| time_elapsed       | 62.3          |\n",
      "| total_timesteps    | 87168         |\n",
      "| value_loss         | 1.0233902e-05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 2.487026e-05  |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -17.1         |\n",
      "| explained_variance | -0.0149       |\n",
      "| fps                | 1433          |\n",
      "| n_updates          | 682           |\n",
      "| policy_entropy     | -0.73948336   |\n",
      "| policy_loss        | -0.0009720954 |\n",
      "| serial_timesteps   | 87296         |\n",
      "| time_elapsed       | 62.4          |\n",
      "| total_timesteps    | 87296         |\n",
      "| value_loss         | 1.4772331e-05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 1.0974964e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -17.1         |\n",
      "| explained_variance | -0.221        |\n",
      "| fps                | 1464          |\n",
      "| n_updates          | 683           |\n",
      "| policy_entropy     | -0.74328417   |\n",
      "| policy_loss        | -0.0014001859 |\n",
      "| serial_timesteps   | 87424         |\n",
      "| time_elapsed       | 62.5          |\n",
      "| total_timesteps    | 87424         |\n",
      "| value_loss         | 1.480801e-05  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 3.9712355e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -17.1         |\n",
      "| explained_variance | -0.148        |\n",
      "| fps                | 1430          |\n",
      "| n_updates          | 684           |\n",
      "| policy_entropy     | -0.74719274   |\n",
      "| policy_loss        | -0.0011651265 |\n",
      "| serial_timesteps   | 87552         |\n",
      "| time_elapsed       | 62.6          |\n",
      "| total_timesteps    | 87552         |\n",
      "| value_loss         | 1.5727157e-05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 7.844388e-05  |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -17.1         |\n",
      "| explained_variance | 0.0163        |\n",
      "| fps                | 1412          |\n",
      "| n_updates          | 685           |\n",
      "| policy_entropy     | -0.75033695   |\n",
      "| policy_loss        | -0.0026096124 |\n",
      "| serial_timesteps   | 87680         |\n",
      "| time_elapsed       | 62.7          |\n",
      "| total_timesteps    | 87680         |\n",
      "| value_loss         | 1.4298723e-05 |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 7.7693694e-05  |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 999            |\n",
      "| ep_reward_mean     | -17.1          |\n",
      "| explained_variance | 0.166          |\n",
      "| fps                | 1255           |\n",
      "| n_updates          | 686            |\n",
      "| policy_entropy     | -0.7534397     |\n",
      "| policy_loss        | -3.2727025e-05 |\n",
      "| serial_timesteps   | 87808          |\n",
      "| time_elapsed       | 62.8           |\n",
      "| total_timesteps    | 87808          |\n",
      "| value_loss         | 2.0902688e-05  |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 5.860439e-05  |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -16.9         |\n",
      "| explained_variance | -0.0279       |\n",
      "| fps                | 1312          |\n",
      "| n_updates          | 687           |\n",
      "| policy_entropy     | -0.75607926   |\n",
      "| policy_loss        | -0.0014910797 |\n",
      "| serial_timesteps   | 87936         |\n",
      "| time_elapsed       | 62.9          |\n",
      "| total_timesteps    | 87936         |\n",
      "| value_loss         | 0.0005794013  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 7.6921744e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -16.9         |\n",
      "| explained_variance | 0.0392        |\n",
      "| fps                | 1435          |\n",
      "| n_updates          | 688           |\n",
      "| policy_entropy     | -0.7574572    |\n",
      "| policy_loss        | -0.0010292195 |\n",
      "| serial_timesteps   | 88064         |\n",
      "| time_elapsed       | 63            |\n",
      "| total_timesteps    | 88064         |\n",
      "| value_loss         | 2.4233952e-05 |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 1.8242e-05     |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 999            |\n",
      "| ep_reward_mean     | -16.9          |\n",
      "| explained_variance | -0.00705       |\n",
      "| fps                | 1395           |\n",
      "| n_updates          | 689            |\n",
      "| policy_entropy     | -0.7606384     |\n",
      "| policy_loss        | -0.00063395244 |\n",
      "| serial_timesteps   | 88192          |\n",
      "| time_elapsed       | 63.1           |\n",
      "| total_timesteps    | 88192          |\n",
      "| value_loss         | 1.5557263e-05  |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 3.3038123e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -16.9         |\n",
      "| explained_variance | 0.0028        |\n",
      "| fps                | 1438          |\n",
      "| n_updates          | 690           |\n",
      "| policy_entropy     | -0.764267     |\n",
      "| policy_loss        | -0.0009840725 |\n",
      "| serial_timesteps   | 88320         |\n",
      "| time_elapsed       | 63.2          |\n",
      "| total_timesteps    | 88320         |\n",
      "| value_loss         | 5.8552696e-06 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 1.4515781e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -16.9         |\n",
      "| explained_variance | 0.0164        |\n",
      "| fps                | 1458          |\n",
      "| n_updates          | 691           |\n",
      "| policy_entropy     | -0.76761174   |\n",
      "| policy_loss        | -0.000797763  |\n",
      "| serial_timesteps   | 88448         |\n",
      "| time_elapsed       | 63.3          |\n",
      "| total_timesteps    | 88448         |\n",
      "| value_loss         | 1.556483e-05  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00017731146 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -16.9         |\n",
      "| explained_variance | -0.0883       |\n",
      "| fps                | 1325          |\n",
      "| n_updates          | 692           |\n",
      "| policy_entropy     | -0.77052873   |\n",
      "| policy_loss        | -0.003693273  |\n",
      "| serial_timesteps   | 88576         |\n",
      "| time_elapsed       | 63.3          |\n",
      "| total_timesteps    | 88576         |\n",
      "| value_loss         | 1.3384708e-05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 1.3107239e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -16.9         |\n",
      "| explained_variance | 0.0666        |\n",
      "| fps                | 1431          |\n",
      "| n_updates          | 693           |\n",
      "| policy_entropy     | -0.77321076   |\n",
      "| policy_loss        | -0.0003283663 |\n",
      "| serial_timesteps   | 88704         |\n",
      "| time_elapsed       | 63.4          |\n",
      "| total_timesteps    | 88704         |\n",
      "| value_loss         | 4.4354747e-06 |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 2.8039081e-05  |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 999            |\n",
      "| ep_reward_mean     | -16.9          |\n",
      "| explained_variance | -0.469         |\n",
      "| fps                | 1396           |\n",
      "| n_updates          | 694            |\n",
      "| policy_entropy     | -0.7757857     |\n",
      "| policy_loss        | -0.00036191265 |\n",
      "| serial_timesteps   | 88832          |\n",
      "| time_elapsed       | 63.5           |\n",
      "| total_timesteps    | 88832          |\n",
      "| value_loss         | 1.1835882e-05  |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 6.427973e-06  |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -16.7         |\n",
      "| explained_variance | -0.0306       |\n",
      "| fps                | 1480          |\n",
      "| n_updates          | 695           |\n",
      "| policy_entropy     | -0.77807623   |\n",
      "| policy_loss        | -6.373355e-05 |\n",
      "| serial_timesteps   | 88960         |\n",
      "| time_elapsed       | 63.6          |\n",
      "| total_timesteps    | 88960         |\n",
      "| value_loss         | 0.00048984244 |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 2.2360339e-06  |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 999            |\n",
      "| ep_reward_mean     | -16.7          |\n",
      "| explained_variance | 0.0115         |\n",
      "| fps                | 1456           |\n",
      "| n_updates          | 696            |\n",
      "| policy_entropy     | -0.780192      |\n",
      "| policy_loss        | -0.00047635275 |\n",
      "| serial_timesteps   | 89088          |\n",
      "| time_elapsed       | 63.7           |\n",
      "| total_timesteps    | 89088          |\n",
      "| value_loss         | 1.5571864e-05  |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 9.9392255e-06 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -16.7         |\n",
      "| explained_variance | -0.0389       |\n",
      "| fps                | 1482          |\n",
      "| n_updates          | 697           |\n",
      "| policy_entropy     | -0.78360724   |\n",
      "| policy_loss        | -0.0011538803 |\n",
      "| serial_timesteps   | 89216         |\n",
      "| time_elapsed       | 63.8          |\n",
      "| total_timesteps    | 89216         |\n",
      "| value_loss         | 2.3398714e-05 |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 4.2341544e-06  |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 999            |\n",
      "| ep_reward_mean     | -16.7          |\n",
      "| explained_variance | -0.00965       |\n",
      "| fps                | 1433           |\n",
      "| n_updates          | 698            |\n",
      "| policy_entropy     | -0.7874192     |\n",
      "| policy_loss        | -0.00078479573 |\n",
      "| serial_timesteps   | 89344          |\n",
      "| time_elapsed       | 63.9           |\n",
      "| total_timesteps    | 89344          |\n",
      "| value_loss         | 1.1888141e-05  |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 9.424937e-06  |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -16.7         |\n",
      "| explained_variance | 0.0175        |\n",
      "| fps                | 1391          |\n",
      "| n_updates          | 699           |\n",
      "| policy_entropy     | -0.79089475   |\n",
      "| policy_loss        | -0.0009143099 |\n",
      "| serial_timesteps   | 89472         |\n",
      "| time_elapsed       | 64            |\n",
      "| total_timesteps    | 89472         |\n",
      "| value_loss         | 6.2353715e-06 |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 2.3139975e-05  |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 999            |\n",
      "| ep_reward_mean     | -16.7          |\n",
      "| explained_variance | -0.0645        |\n",
      "| fps                | 1404           |\n",
      "| n_updates          | 700            |\n",
      "| policy_entropy     | -0.7941541     |\n",
      "| policy_loss        | -0.00043400074 |\n",
      "| serial_timesteps   | 89600          |\n",
      "| time_elapsed       | 64.1           |\n",
      "| total_timesteps    | 89600          |\n",
      "| value_loss         | 6.3599896e-06  |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 3.7224158e-06 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -16.7         |\n",
      "| explained_variance | 0.0269        |\n",
      "| fps                | 1471          |\n",
      "| n_updates          | 701           |\n",
      "| policy_entropy     | -0.79721993   |\n",
      "| policy_loss        | -0.0007559657 |\n",
      "| serial_timesteps   | 89728         |\n",
      "| time_elapsed       | 64.2          |\n",
      "| total_timesteps    | 89728         |\n",
      "| value_loss         | 1.7085074e-05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 2.4128836e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -16.7         |\n",
      "| explained_variance | -0.0345       |\n",
      "| fps                | 1476          |\n",
      "| n_updates          | 702           |\n",
      "| policy_entropy     | -0.80059373   |\n",
      "| policy_loss        | -0.0013069855 |\n",
      "| serial_timesteps   | 89856         |\n",
      "| time_elapsed       | 64.3          |\n",
      "| total_timesteps    | 89856         |\n",
      "| value_loss         | 1.2709043e-05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 5.6066343e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -16.5         |\n",
      "| explained_variance | 0.00356       |\n",
      "| fps                | 1434          |\n",
      "| n_updates          | 703           |\n",
      "| policy_entropy     | -0.80395037   |\n",
      "| policy_loss        | -0.0007430874 |\n",
      "| serial_timesteps   | 89984         |\n",
      "| time_elapsed       | 64.3          |\n",
      "| total_timesteps    | 89984         |\n",
      "| value_loss         | 0.00039316138 |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 4.7948743e-05  |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 999            |\n",
      "| ep_reward_mean     | -16.5          |\n",
      "| explained_variance | -0.056         |\n",
      "| fps                | 1417           |\n",
      "| n_updates          | 704            |\n",
      "| policy_entropy     | -0.8061085     |\n",
      "| policy_loss        | -0.00043995457 |\n",
      "| serial_timesteps   | 90112          |\n",
      "| time_elapsed       | 64.4           |\n",
      "| total_timesteps    | 90112          |\n",
      "| value_loss         | 8.720983e-06   |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00014201924 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -16.5         |\n",
      "| explained_variance | -0.0511       |\n",
      "| fps                | 1486          |\n",
      "| n_updates          | 705           |\n",
      "| policy_entropy     | -0.80955863   |\n",
      "| policy_loss        | -0.002522864  |\n",
      "| serial_timesteps   | 90240         |\n",
      "| time_elapsed       | 64.5          |\n",
      "| total_timesteps    | 90240         |\n",
      "| value_loss         | 9.632795e-06  |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 3.681384e-05   |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 999            |\n",
      "| ep_reward_mean     | -16.5          |\n",
      "| explained_variance | 0.158          |\n",
      "| fps                | 1458           |\n",
      "| n_updates          | 706            |\n",
      "| policy_entropy     | -0.8129534     |\n",
      "| policy_loss        | -0.00051653467 |\n",
      "| serial_timesteps   | 90368          |\n",
      "| time_elapsed       | 64.6           |\n",
      "| total_timesteps    | 90368          |\n",
      "| value_loss         | 4.427867e-06   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 1.52271505e-05 |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 999            |\n",
      "| ep_reward_mean     | -16.5          |\n",
      "| explained_variance | -0.0201        |\n",
      "| fps                | 1392           |\n",
      "| n_updates          | 707            |\n",
      "| policy_entropy     | -0.8163946     |\n",
      "| policy_loss        | -0.0010099908  |\n",
      "| serial_timesteps   | 90496          |\n",
      "| time_elapsed       | 64.7           |\n",
      "| total_timesteps    | 90496          |\n",
      "| value_loss         | 1.683654e-05   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 4.8154648e-06  |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 999            |\n",
      "| ep_reward_mean     | -16.5          |\n",
      "| explained_variance | 0.0123         |\n",
      "| fps                | 1433           |\n",
      "| n_updates          | 708            |\n",
      "| policy_entropy     | -0.819548      |\n",
      "| policy_loss        | -0.00018828246 |\n",
      "| serial_timesteps   | 90624          |\n",
      "| time_elapsed       | 64.8           |\n",
      "| total_timesteps    | 90624          |\n",
      "| value_loss         | 1.34923675e-05 |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 8.7397275e-06  |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 999            |\n",
      "| ep_reward_mean     | -16.5          |\n",
      "| explained_variance | -0.0869        |\n",
      "| fps                | 1325           |\n",
      "| n_updates          | 709            |\n",
      "| policy_entropy     | -0.8218648     |\n",
      "| policy_loss        | -0.00020499737 |\n",
      "| serial_timesteps   | 90752          |\n",
      "| time_elapsed       | 64.9           |\n",
      "| total_timesteps    | 90752          |\n",
      "| value_loss         | 8.03643e-06    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 4.4467192e-06 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -16.5         |\n",
      "| explained_variance | -0.00487      |\n",
      "| fps                | 1472          |\n",
      "| n_updates          | 710           |\n",
      "| policy_entropy     | -0.82404387   |\n",
      "| policy_loss        | -0.0007822936 |\n",
      "| serial_timesteps   | 90880         |\n",
      "| time_elapsed       | 65            |\n",
      "| total_timesteps    | 90880         |\n",
      "| value_loss         | 1.7639544e-05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 1.1881434e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -16.4         |\n",
      "| explained_variance | 0.00144       |\n",
      "| fps                | 1453          |\n",
      "| n_updates          | 711           |\n",
      "| policy_entropy     | -0.82623136   |\n",
      "| policy_loss        | 0.0002730114  |\n",
      "| serial_timesteps   | 91008         |\n",
      "| time_elapsed       | 65.1          |\n",
      "| total_timesteps    | 91008         |\n",
      "| value_loss         | 0.0003240754  |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 2.926439e-06   |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 999            |\n",
      "| ep_reward_mean     | -16.4          |\n",
      "| explained_variance | -0.0364        |\n",
      "| fps                | 1436           |\n",
      "| n_updates          | 712            |\n",
      "| policy_entropy     | -0.8277417     |\n",
      "| policy_loss        | -0.00039419986 |\n",
      "| serial_timesteps   | 91136          |\n",
      "| time_elapsed       | 65.1           |\n",
      "| total_timesteps    | 91136          |\n",
      "| value_loss         | 8.68909e-06    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 8.259482e-05  |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -16.4         |\n",
      "| explained_variance | -0.0244       |\n",
      "| fps                | 1487          |\n",
      "| n_updates          | 713           |\n",
      "| policy_entropy     | -0.8307517    |\n",
      "| policy_loss        | -0.0021359245 |\n",
      "| serial_timesteps   | 91264         |\n",
      "| time_elapsed       | 65.2          |\n",
      "| total_timesteps    | 91264         |\n",
      "| value_loss         | 1.1193094e-05 |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 1.840426e-05   |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 999            |\n",
      "| ep_reward_mean     | -16.4          |\n",
      "| explained_variance | 0.0997         |\n",
      "| fps                | 1425           |\n",
      "| n_updates          | 714            |\n",
      "| policy_entropy     | -0.833961      |\n",
      "| policy_loss        | -0.00047227438 |\n",
      "| serial_timesteps   | 91392          |\n",
      "| time_elapsed       | 65.3           |\n",
      "| total_timesteps    | 91392          |\n",
      "| value_loss         | 5.718827e-06   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 6.1372e-06     |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 999            |\n",
      "| ep_reward_mean     | -16.4          |\n",
      "| explained_variance | -0.0256        |\n",
      "| fps                | 1389           |\n",
      "| n_updates          | 715            |\n",
      "| policy_entropy     | -0.8373154     |\n",
      "| policy_loss        | -0.00057415036 |\n",
      "| serial_timesteps   | 91520          |\n",
      "| time_elapsed       | 65.4           |\n",
      "| total_timesteps    | 91520          |\n",
      "| value_loss         | 8.876733e-06   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 1.43558555e-05 |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 999            |\n",
      "| ep_reward_mean     | -16.4          |\n",
      "| explained_variance | -0.0351        |\n",
      "| fps                | 1335           |\n",
      "| n_updates          | 716            |\n",
      "| policy_entropy     | -0.84083855    |\n",
      "| policy_loss        | -0.0011521707  |\n",
      "| serial_timesteps   | 91648          |\n",
      "| time_elapsed       | 65.5           |\n",
      "| total_timesteps    | 91648          |\n",
      "| value_loss         | 7.493711e-06   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 8.301328e-06   |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 999            |\n",
      "| ep_reward_mean     | -16.4          |\n",
      "| explained_variance | -0.377         |\n",
      "| fps                | 1406           |\n",
      "| n_updates          | 717            |\n",
      "| policy_entropy     | -0.84459746    |\n",
      "| policy_loss        | -0.00097513234 |\n",
      "| serial_timesteps   | 91776          |\n",
      "| time_elapsed       | 65.6           |\n",
      "| total_timesteps    | 91776          |\n",
      "| value_loss         | 1.0600364e-05  |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 8.844681e-06  |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -16.4         |\n",
      "| explained_variance | 0.121         |\n",
      "| fps                | 1364          |\n",
      "| n_updates          | 718           |\n",
      "| policy_entropy     | -0.8486427    |\n",
      "| policy_loss        | -0.0009789402 |\n",
      "| serial_timesteps   | 91904         |\n",
      "| time_elapsed       | 65.7          |\n",
      "| total_timesteps    | 91904         |\n",
      "| value_loss         | 7.5723124e-06 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 7.4416224e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -16.2         |\n",
      "| explained_variance | 8.85e-05      |\n",
      "| fps                | 1407          |\n",
      "| n_updates          | 719           |\n",
      "| policy_entropy     | -0.85176027   |\n",
      "| policy_loss        | -0.0012068367 |\n",
      "| serial_timesteps   | 92032         |\n",
      "| time_elapsed       | 65.8          |\n",
      "| total_timesteps    | 92032         |\n",
      "| value_loss         | 0.00013651246 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 2.8488073e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -16.2         |\n",
      "| explained_variance | -0.124        |\n",
      "| fps                | 1288          |\n",
      "| n_updates          | 720           |\n",
      "| policy_entropy     | -0.85411453   |\n",
      "| policy_loss        | -0.0004724526 |\n",
      "| serial_timesteps   | 92160         |\n",
      "| time_elapsed       | 65.9          |\n",
      "| total_timesteps    | 92160         |\n",
      "| value_loss         | 6.810544e-06  |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 4.6263385e-06  |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 999            |\n",
      "| ep_reward_mean     | -16.2          |\n",
      "| explained_variance | -0.000979      |\n",
      "| fps                | 1440           |\n",
      "| n_updates          | 721            |\n",
      "| policy_entropy     | -0.8577036     |\n",
      "| policy_loss        | -0.00087133306 |\n",
      "| serial_timesteps   | 92288          |\n",
      "| time_elapsed       | 66             |\n",
      "| total_timesteps    | 92288          |\n",
      "| value_loss         | 1.414861e-05   |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 1.1991582e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -16.2         |\n",
      "| explained_variance | 0.124         |\n",
      "| fps                | 1502          |\n",
      "| n_updates          | 722           |\n",
      "| policy_entropy     | -0.8614774    |\n",
      "| policy_loss        | -0.0012166206 |\n",
      "| serial_timesteps   | 92416         |\n",
      "| time_elapsed       | 66.1          |\n",
      "| total_timesteps    | 92416         |\n",
      "| value_loss         | 3.7412221e-06 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 2.4022465e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -16.2         |\n",
      "| explained_variance | -0.0859       |\n",
      "| fps                | 1442          |\n",
      "| n_updates          | 723           |\n",
      "| policy_entropy     | -0.8647586    |\n",
      "| policy_loss        | -0.0010310588 |\n",
      "| serial_timesteps   | 92544         |\n",
      "| time_elapsed       | 66.2          |\n",
      "| total_timesteps    | 92544         |\n",
      "| value_loss         | 9.111921e-06  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0001124135  |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -16.2         |\n",
      "| explained_variance | -0.0135       |\n",
      "| fps                | 1466          |\n",
      "| n_updates          | 724           |\n",
      "| policy_entropy     | -0.8678395    |\n",
      "| policy_loss        | -0.0009323375 |\n",
      "| serial_timesteps   | 92672         |\n",
      "| time_elapsed       | 66.3          |\n",
      "| total_timesteps    | 92672         |\n",
      "| value_loss         | 1.129112e-05  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00015480709 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -16.2         |\n",
      "| explained_variance | -0.0756       |\n",
      "| fps                | 1381          |\n",
      "| n_updates          | 725           |\n",
      "| policy_entropy     | -0.87154984   |\n",
      "| policy_loss        | -0.0019891225 |\n",
      "| serial_timesteps   | 92800         |\n",
      "| time_elapsed       | 66.3          |\n",
      "| total_timesteps    | 92800         |\n",
      "| value_loss         | 1.0522996e-05 |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 1.5448702e-05  |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 999            |\n",
      "| ep_reward_mean     | -16.1          |\n",
      "| explained_variance | 0.00163        |\n",
      "| fps                | 1386           |\n",
      "| n_updates          | 726            |\n",
      "| policy_entropy     | -0.87506044    |\n",
      "| policy_loss        | -5.9646554e-06 |\n",
      "| serial_timesteps   | 92928          |\n",
      "| time_elapsed       | 66.4           |\n",
      "| total_timesteps    | 92928          |\n",
      "| value_loss         | 0.00032346172  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 0.00026251684  |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 999            |\n",
      "| ep_reward_mean     | -16.1          |\n",
      "| explained_variance | -0.0392        |\n",
      "| fps                | 1398           |\n",
      "| n_updates          | 727            |\n",
      "| policy_entropy     | -0.8772739     |\n",
      "| policy_loss        | -0.00055988855 |\n",
      "| serial_timesteps   | 93056          |\n",
      "| time_elapsed       | 66.5           |\n",
      "| total_timesteps    | 93056          |\n",
      "| value_loss         | 1.2340579e-05  |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 3.1359927e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -16.1         |\n",
      "| explained_variance | -0.0562       |\n",
      "| fps                | 1486          |\n",
      "| n_updates          | 728           |\n",
      "| policy_entropy     | -0.8801452    |\n",
      "| policy_loss        | -0.0008468032 |\n",
      "| serial_timesteps   | 93184         |\n",
      "| time_elapsed       | 66.6          |\n",
      "| total_timesteps    | 93184         |\n",
      "| value_loss         | 1.0550583e-05 |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 5.7018456e-06  |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 999            |\n",
      "| ep_reward_mean     | -16.1          |\n",
      "| explained_variance | -0.0223        |\n",
      "| fps                | 1393           |\n",
      "| n_updates          | 729            |\n",
      "| policy_entropy     | -0.8831259     |\n",
      "| policy_loss        | -0.00064022944 |\n",
      "| serial_timesteps   | 93312          |\n",
      "| time_elapsed       | 66.7           |\n",
      "| total_timesteps    | 93312          |\n",
      "| value_loss         | 3.938385e-06   |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 8.9369256e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -16.1         |\n",
      "| explained_variance | -0.00442      |\n",
      "| fps                | 1287          |\n",
      "| n_updates          | 730           |\n",
      "| policy_entropy     | -0.88641715   |\n",
      "| policy_loss        | -0.0016665667 |\n",
      "| serial_timesteps   | 93440         |\n",
      "| time_elapsed       | 66.8          |\n",
      "| total_timesteps    | 93440         |\n",
      "| value_loss         | 3.246379e-06  |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 7.816525e-06   |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 999            |\n",
      "| ep_reward_mean     | -16.1          |\n",
      "| explained_variance | 0.0173         |\n",
      "| fps                | 1331           |\n",
      "| n_updates          | 731            |\n",
      "| policy_entropy     | -0.88965875    |\n",
      "| policy_loss        | -0.00040896446 |\n",
      "| serial_timesteps   | 93568          |\n",
      "| time_elapsed       | 66.9           |\n",
      "| total_timesteps    | 93568          |\n",
      "| value_loss         | 7.930911e-06   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 0.00010288332  |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 999            |\n",
      "| ep_reward_mean     | -16.1          |\n",
      "| explained_variance | 0.0358         |\n",
      "| fps                | 1444           |\n",
      "| n_updates          | 732            |\n",
      "| policy_entropy     | -0.8927891     |\n",
      "| policy_loss        | -5.5851415e-06 |\n",
      "| serial_timesteps   | 93696          |\n",
      "| time_elapsed       | 67             |\n",
      "| total_timesteps    | 93696          |\n",
      "| value_loss         | 7.466485e-06   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 1.6147362e-05  |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 999            |\n",
      "| ep_reward_mean     | -16.1          |\n",
      "| explained_variance | -0.0661        |\n",
      "| fps                | 1443           |\n",
      "| n_updates          | 733            |\n",
      "| policy_entropy     | -0.89558655    |\n",
      "| policy_loss        | -0.00084846653 |\n",
      "| serial_timesteps   | 93824          |\n",
      "| time_elapsed       | 67.1           |\n",
      "| total_timesteps    | 93824          |\n",
      "| value_loss         | 9.110946e-06   |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 4.455433e-05  |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -15.9         |\n",
      "| explained_variance | -0.0178       |\n",
      "| fps                | 1379          |\n",
      "| n_updates          | 734           |\n",
      "| policy_entropy     | -0.8979749    |\n",
      "| policy_loss        | 0.00024096575 |\n",
      "| serial_timesteps   | 93952         |\n",
      "| time_elapsed       | 67.2          |\n",
      "| total_timesteps    | 93952         |\n",
      "| value_loss         | 0.00022550055 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 2.3231994e-06 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -15.9         |\n",
      "| explained_variance | 0.0444        |\n",
      "| fps                | 1486          |\n",
      "| n_updates          | 735           |\n",
      "| policy_entropy     | -0.8992076    |\n",
      "| policy_loss        | -0.0003139698 |\n",
      "| serial_timesteps   | 94080         |\n",
      "| time_elapsed       | 67.3          |\n",
      "| total_timesteps    | 94080         |\n",
      "| value_loss         | 2.2088838e-05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 1.4365318e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -15.9         |\n",
      "| explained_variance | -0.0078       |\n",
      "| fps                | 1362          |\n",
      "| n_updates          | 736           |\n",
      "| policy_entropy     | -0.901673     |\n",
      "| policy_loss        | -0.0007837403 |\n",
      "| serial_timesteps   | 94208         |\n",
      "| time_elapsed       | 67.4          |\n",
      "| total_timesteps    | 94208         |\n",
      "| value_loss         | 1.9201141e-05 |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 5.760558e-06   |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 999            |\n",
      "| ep_reward_mean     | -15.9          |\n",
      "| explained_variance | -0.0494        |\n",
      "| fps                | 1437           |\n",
      "| n_updates          | 737            |\n",
      "| policy_entropy     | -0.9050341     |\n",
      "| policy_loss        | -0.00073394924 |\n",
      "| serial_timesteps   | 94336          |\n",
      "| time_elapsed       | 67.4           |\n",
      "| total_timesteps    | 94336          |\n",
      "| value_loss         | 9.8580695e-06  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 1.5588794e-05  |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 999            |\n",
      "| ep_reward_mean     | -15.9          |\n",
      "| explained_variance | 0.0385         |\n",
      "| fps                | 1440           |\n",
      "| n_updates          | 738            |\n",
      "| policy_entropy     | -0.9084547     |\n",
      "| policy_loss        | -0.00088554726 |\n",
      "| serial_timesteps   | 94464          |\n",
      "| time_elapsed       | 67.5           |\n",
      "| total_timesteps    | 94464          |\n",
      "| value_loss         | 4.424306e-06   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 4.986906e-06   |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 999            |\n",
      "| ep_reward_mean     | -15.9          |\n",
      "| explained_variance | 0.129          |\n",
      "| fps                | 1495           |\n",
      "| n_updates          | 739            |\n",
      "| policy_entropy     | -0.911478      |\n",
      "| policy_loss        | -0.00071346987 |\n",
      "| serial_timesteps   | 94592          |\n",
      "| time_elapsed       | 67.6           |\n",
      "| total_timesteps    | 94592          |\n",
      "| value_loss         | 2.8285733e-06  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 1.1133691e-05  |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 999            |\n",
      "| ep_reward_mean     | -15.9          |\n",
      "| explained_variance | 0.00107        |\n",
      "| fps                | 1482           |\n",
      "| n_updates          | 740            |\n",
      "| policy_entropy     | -0.91480607    |\n",
      "| policy_loss        | -0.00090668304 |\n",
      "| serial_timesteps   | 94720          |\n",
      "| time_elapsed       | 67.7           |\n",
      "| total_timesteps    | 94720          |\n",
      "| value_loss         | 4.768357e-06   |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 4.956487e-05  |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -15.9         |\n",
      "| explained_variance | 0.0262        |\n",
      "| fps                | 1478          |\n",
      "| n_updates          | 741           |\n",
      "| policy_entropy     | -0.9182029    |\n",
      "| policy_loss        | -0.0019886051 |\n",
      "| serial_timesteps   | 94848         |\n",
      "| time_elapsed       | 67.8          |\n",
      "| total_timesteps    | 94848         |\n",
      "| value_loss         | 5.4558864e-06 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00027528318 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -15.7         |\n",
      "| explained_variance | -0.00708      |\n",
      "| fps                | 1393          |\n",
      "| n_updates          | 742           |\n",
      "| policy_entropy     | -0.9205951    |\n",
      "| policy_loss        | -0.0018588529 |\n",
      "| serial_timesteps   | 94976         |\n",
      "| time_elapsed       | 67.9          |\n",
      "| total_timesteps    | 94976         |\n",
      "| value_loss         | 0.00023760356 |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 1.5311394e-05  |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 999            |\n",
      "| ep_reward_mean     | -15.7          |\n",
      "| explained_variance | 0.106          |\n",
      "| fps                | 1359           |\n",
      "| n_updates          | 743            |\n",
      "| policy_entropy     | -0.92220014    |\n",
      "| policy_loss        | -0.00044559827 |\n",
      "| serial_timesteps   | 95104          |\n",
      "| time_elapsed       | 68             |\n",
      "| total_timesteps    | 95104          |\n",
      "| value_loss         | 4.3642567e-06  |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00028656636 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -15.7         |\n",
      "| explained_variance | 0.14          |\n",
      "| fps                | 1472          |\n",
      "| n_updates          | 744           |\n",
      "| policy_entropy     | -0.9243175    |\n",
      "| policy_loss        | -0.003314542  |\n",
      "| serial_timesteps   | 95232         |\n",
      "| time_elapsed       | 68.1          |\n",
      "| total_timesteps    | 95232         |\n",
      "| value_loss         | 3.8544804e-06 |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 8.350673e-05   |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 999            |\n",
      "| ep_reward_mean     | -15.7          |\n",
      "| explained_variance | 0.222          |\n",
      "| fps                | 1339           |\n",
      "| n_updates          | 745            |\n",
      "| policy_entropy     | -0.92684627    |\n",
      "| policy_loss        | -0.00078340026 |\n",
      "| serial_timesteps   | 95360          |\n",
      "| time_elapsed       | 68.2           |\n",
      "| total_timesteps    | 95360          |\n",
      "| value_loss         | 3.2536698e-06  |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 2.3424707e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -15.7         |\n",
      "| explained_variance | 0.158         |\n",
      "| fps                | 1379          |\n",
      "| n_updates          | 746           |\n",
      "| policy_entropy     | -0.9295094    |\n",
      "| policy_loss        | -0.0008639154 |\n",
      "| serial_timesteps   | 95488         |\n",
      "| time_elapsed       | 68.3          |\n",
      "| total_timesteps    | 95488         |\n",
      "| value_loss         | 5.548097e-06  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 6.340186e-06  |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -15.7         |\n",
      "| explained_variance | -0.115        |\n",
      "| fps                | 1440          |\n",
      "| n_updates          | 747           |\n",
      "| policy_entropy     | -0.93307704   |\n",
      "| policy_loss        | -0.0007743385 |\n",
      "| serial_timesteps   | 95616         |\n",
      "| time_elapsed       | 68.4          |\n",
      "| total_timesteps    | 95616         |\n",
      "| value_loss         | 1.1991783e-05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 1.4462342e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -15.7         |\n",
      "| explained_variance | 0.116         |\n",
      "| fps                | 1429          |\n",
      "| n_updates          | 748           |\n",
      "| policy_entropy     | -0.9370051    |\n",
      "| policy_loss        | -0.0009632455 |\n",
      "| serial_timesteps   | 95744         |\n",
      "| time_elapsed       | 68.4          |\n",
      "| total_timesteps    | 95744         |\n",
      "| value_loss         | 9.120302e-06  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00015852755 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -15.7         |\n",
      "| explained_variance | -0.0609       |\n",
      "| fps                | 1457          |\n",
      "| n_updates          | 749           |\n",
      "| policy_entropy     | -0.9408124    |\n",
      "| policy_loss        | -0.0029004933 |\n",
      "| serial_timesteps   | 95872         |\n",
      "| time_elapsed       | 68.5          |\n",
      "| total_timesteps    | 95872         |\n",
      "| value_loss         | 5.2199534e-06 |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 1.31840425e-05 |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 999            |\n",
      "| ep_reward_mean     | -15.6          |\n",
      "| explained_variance | 0.0284         |\n",
      "| fps                | 1488           |\n",
      "| n_updates          | 750            |\n",
      "| policy_entropy     | -0.9436041     |\n",
      "| policy_loss        | 5.3443364e-05  |\n",
      "| serial_timesteps   | 96000          |\n",
      "| time_elapsed       | 68.6           |\n",
      "| total_timesteps    | 96000          |\n",
      "| value_loss         | 0.00024574343  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 3.48942e-05    |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 999            |\n",
      "| ep_reward_mean     | -15.6          |\n",
      "| explained_variance | -0.36          |\n",
      "| fps                | 1461           |\n",
      "| n_updates          | 751            |\n",
      "| policy_entropy     | -0.94583654    |\n",
      "| policy_loss        | -0.00087117054 |\n",
      "| serial_timesteps   | 96128          |\n",
      "| time_elapsed       | 68.7           |\n",
      "| total_timesteps    | 96128          |\n",
      "| value_loss         | 1.7672583e-05  |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 2.0159805e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -15.6         |\n",
      "| explained_variance | 0.14          |\n",
      "| fps                | 1441          |\n",
      "| n_updates          | 752           |\n",
      "| policy_entropy     | -0.9485912    |\n",
      "| policy_loss        | -0.0011716138 |\n",
      "| serial_timesteps   | 96256         |\n",
      "| time_elapsed       | 68.8          |\n",
      "| total_timesteps    | 96256         |\n",
      "| value_loss         | 3.5682274e-06 |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 0.000110805384 |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 999            |\n",
      "| ep_reward_mean     | -15.6          |\n",
      "| explained_variance | 0.00412        |\n",
      "| fps                | 1408           |\n",
      "| n_updates          | 753            |\n",
      "| policy_entropy     | -0.95145786    |\n",
      "| policy_loss        | -0.001489349   |\n",
      "| serial_timesteps   | 96384          |\n",
      "| time_elapsed       | 68.9           |\n",
      "| total_timesteps    | 96384          |\n",
      "| value_loss         | 4.2283973e-06  |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 6.5149106e-06 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -15.6         |\n",
      "| explained_variance | -0.216        |\n",
      "| fps                | 1324          |\n",
      "| n_updates          | 754           |\n",
      "| policy_entropy     | -0.9540201    |\n",
      "| policy_loss        | -0.0005200614 |\n",
      "| serial_timesteps   | 96512         |\n",
      "| time_elapsed       | 69            |\n",
      "| total_timesteps    | 96512         |\n",
      "| value_loss         | 3.7114905e-06 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00014559281 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -15.6         |\n",
      "| explained_variance | -0.15         |\n",
      "| fps                | 1407          |\n",
      "| n_updates          | 755           |\n",
      "| policy_entropy     | -0.95648354   |\n",
      "| policy_loss        | -0.0026873169 |\n",
      "| serial_timesteps   | 96640         |\n",
      "| time_elapsed       | 69.1          |\n",
      "| total_timesteps    | 96640         |\n",
      "| value_loss         | 6.3558787e-06 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 7.5850156e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -15.6         |\n",
      "| explained_variance | -0.00163      |\n",
      "| fps                | 1390          |\n",
      "| n_updates          | 756           |\n",
      "| policy_entropy     | -0.9587624    |\n",
      "| policy_loss        | -0.0006771594 |\n",
      "| serial_timesteps   | 96768         |\n",
      "| time_elapsed       | 69.2          |\n",
      "| total_timesteps    | 96768         |\n",
      "| value_loss         | 5.4740754e-06 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 2.4609039e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -15.6         |\n",
      "| explained_variance | 0.296         |\n",
      "| fps                | 1465          |\n",
      "| n_updates          | 757           |\n",
      "| policy_entropy     | -0.96117216   |\n",
      "| policy_loss        | -0.001321831  |\n",
      "| serial_timesteps   | 96896         |\n",
      "| time_elapsed       | 69.3          |\n",
      "| total_timesteps    | 96896         |\n",
      "| value_loss         | 4.357231e-06  |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 9.563264e-06   |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 999            |\n",
      "| ep_reward_mean     | -15.4          |\n",
      "| explained_variance | -0.0326        |\n",
      "| fps                | 1441           |\n",
      "| n_updates          | 758            |\n",
      "| policy_entropy     | -0.9637142     |\n",
      "| policy_loss        | -0.00035462517 |\n",
      "| serial_timesteps   | 97024          |\n",
      "| time_elapsed       | 69.3           |\n",
      "| total_timesteps    | 97024          |\n",
      "| value_loss         | 0.00011523598  |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 1.1579579e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -15.4         |\n",
      "| explained_variance | -0.25         |\n",
      "| fps                | 1447          |\n",
      "| n_updates          | 759           |\n",
      "| policy_entropy     | -0.9659627    |\n",
      "| policy_loss        | -0.0008940481 |\n",
      "| serial_timesteps   | 97152         |\n",
      "| time_elapsed       | 69.4          |\n",
      "| total_timesteps    | 97152         |\n",
      "| value_loss         | 6.9241196e-06 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00010674623 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -15.4         |\n",
      "| explained_variance | 0.095         |\n",
      "| fps                | 1465          |\n",
      "| n_updates          | 760           |\n",
      "| policy_entropy     | -0.9687009    |\n",
      "| policy_loss        | -0.0016041034 |\n",
      "| serial_timesteps   | 97280         |\n",
      "| time_elapsed       | 69.5          |\n",
      "| total_timesteps    | 97280         |\n",
      "| value_loss         | 1.9366912e-06 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 6.6517814e-06 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -15.4         |\n",
      "| explained_variance | 0.0776        |\n",
      "| fps                | 1454          |\n",
      "| n_updates          | 761           |\n",
      "| policy_entropy     | -0.97181493   |\n",
      "| policy_loss        | -0.0005919698 |\n",
      "| serial_timesteps   | 97408         |\n",
      "| time_elapsed       | 69.6          |\n",
      "| total_timesteps    | 97408         |\n",
      "| value_loss         | 6.5261056e-06 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 2.974793e-05  |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -15.4         |\n",
      "| explained_variance | 0.00839       |\n",
      "| fps                | 1426          |\n",
      "| n_updates          | 762           |\n",
      "| policy_entropy     | -0.97506046   |\n",
      "| policy_loss        | -0.0011342586 |\n",
      "| serial_timesteps   | 97536         |\n",
      "| time_elapsed       | 69.7          |\n",
      "| total_timesteps    | 97536         |\n",
      "| value_loss         | 4.752422e-06  |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 4.7500882e-05  |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 999            |\n",
      "| ep_reward_mean     | -15.4          |\n",
      "| explained_variance | 0.0598         |\n",
      "| fps                | 1478           |\n",
      "| n_updates          | 763            |\n",
      "| policy_entropy     | -0.9778027     |\n",
      "| policy_loss        | -0.00088576856 |\n",
      "| serial_timesteps   | 97664          |\n",
      "| time_elapsed       | 69.8           |\n",
      "| total_timesteps    | 97664          |\n",
      "| value_loss         | 7.5928e-06     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 5.778391e-05   |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 999            |\n",
      "| ep_reward_mean     | -15.4          |\n",
      "| explained_variance | -0.106         |\n",
      "| fps                | 1418           |\n",
      "| n_updates          | 764            |\n",
      "| policy_entropy     | -0.98060745    |\n",
      "| policy_loss        | -0.00095678866 |\n",
      "| serial_timesteps   | 97792          |\n",
      "| time_elapsed       | 69.9           |\n",
      "| total_timesteps    | 97792          |\n",
      "| value_loss         | 1.0015686e-05  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 5.2936784e-06  |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 999            |\n",
      "| ep_reward_mean     | -15.3          |\n",
      "| explained_variance | 0.0404         |\n",
      "| fps                | 1345           |\n",
      "| n_updates          | 765            |\n",
      "| policy_entropy     | -0.982746      |\n",
      "| policy_loss        | -4.4523855e-05 |\n",
      "| serial_timesteps   | 97920          |\n",
      "| time_elapsed       | 70             |\n",
      "| total_timesteps    | 97920          |\n",
      "| value_loss         | 0.00017950762  |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 1.2283907e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -15.3         |\n",
      "| explained_variance | -0.645        |\n",
      "| fps                | 1471          |\n",
      "| n_updates          | 766           |\n",
      "| policy_entropy     | -0.9839119    |\n",
      "| policy_loss        | -0.0006575668 |\n",
      "| serial_timesteps   | 98048         |\n",
      "| time_elapsed       | 70.1          |\n",
      "| total_timesteps    | 98048         |\n",
      "| value_loss         | 1.6005955e-05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 5.3772717e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -15.3         |\n",
      "| explained_variance | 0.375         |\n",
      "| fps                | 1395          |\n",
      "| n_updates          | 767           |\n",
      "| policy_entropy     | -0.98619854   |\n",
      "| policy_loss        | -0.0018031041 |\n",
      "| serial_timesteps   | 98176         |\n",
      "| time_elapsed       | 70.2          |\n",
      "| total_timesteps    | 98176         |\n",
      "| value_loss         | 3.6408985e-06 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 4.566832e-05  |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -15.3         |\n",
      "| explained_variance | -0.192        |\n",
      "| fps                | 1475          |\n",
      "| n_updates          | 768           |\n",
      "| policy_entropy     | -0.9884595    |\n",
      "| policy_loss        | -0.0019151017 |\n",
      "| serial_timesteps   | 98304         |\n",
      "| time_elapsed       | 70.2          |\n",
      "| total_timesteps    | 98304         |\n",
      "| value_loss         | 8.783756e-06  |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 8.492062e-05   |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 999            |\n",
      "| ep_reward_mean     | -15.3          |\n",
      "| explained_variance | 0.125          |\n",
      "| fps                | 1455           |\n",
      "| n_updates          | 769            |\n",
      "| policy_entropy     | -0.9913617     |\n",
      "| policy_loss        | -0.00041790016 |\n",
      "| serial_timesteps   | 98432          |\n",
      "| time_elapsed       | 70.3           |\n",
      "| total_timesteps    | 98432          |\n",
      "| value_loss         | 4.8190295e-06  |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 5.3668184e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -15.3         |\n",
      "| explained_variance | -0.376        |\n",
      "| fps                | 1403          |\n",
      "| n_updates          | 770           |\n",
      "| policy_entropy     | -0.9940998    |\n",
      "| policy_loss        | -0.001628807  |\n",
      "| serial_timesteps   | 98560         |\n",
      "| time_elapsed       | 70.4          |\n",
      "| total_timesteps    | 98560         |\n",
      "| value_loss         | 3.5892035e-06 |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 4.908678e-06   |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 999            |\n",
      "| ep_reward_mean     | -15.3          |\n",
      "| explained_variance | 0.376          |\n",
      "| fps                | 1406           |\n",
      "| n_updates          | 771            |\n",
      "| policy_entropy     | -0.99660075    |\n",
      "| policy_loss        | -0.00058903586 |\n",
      "| serial_timesteps   | 98688          |\n",
      "| time_elapsed       | 70.5           |\n",
      "| total_timesteps    | 98688          |\n",
      "| value_loss         | 2.882862e-06   |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 0.000109035514 |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 999            |\n",
      "| ep_reward_mean     | -15.3          |\n",
      "| explained_variance | 0.0665         |\n",
      "| fps                | 1398           |\n",
      "| n_updates          | 772            |\n",
      "| policy_entropy     | -0.9996058     |\n",
      "| policy_loss        | -0.0028860366  |\n",
      "| serial_timesteps   | 98816          |\n",
      "| time_elapsed       | 70.6           |\n",
      "| total_timesteps    | 98816          |\n",
      "| value_loss         | 6.759297e-06   |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 3.0654122e-05 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -15.1         |\n",
      "| explained_variance | 0.0228        |\n",
      "| fps                | 1422          |\n",
      "| n_updates          | 773           |\n",
      "| policy_entropy     | -1.0022157    |\n",
      "| policy_loss        | 3.564675e-05  |\n",
      "| serial_timesteps   | 98944         |\n",
      "| time_elapsed       | 70.7          |\n",
      "| total_timesteps    | 98944         |\n",
      "| value_loss         | 0.00015117906 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00026208232 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -15.1         |\n",
      "| explained_variance | 0.0876        |\n",
      "| fps                | 1331          |\n",
      "| n_updates          | 774           |\n",
      "| policy_entropy     | -1.0034481    |\n",
      "| policy_loss        | -0.0010462385 |\n",
      "| serial_timesteps   | 99072         |\n",
      "| time_elapsed       | 70.8          |\n",
      "| total_timesteps    | 99072         |\n",
      "| value_loss         | 2.3076967e-05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.002654158   |\n",
      "| clipfrac           | 0.021484375   |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -15.1         |\n",
      "| explained_variance | -0.115        |\n",
      "| fps                | 1466          |\n",
      "| n_updates          | 775           |\n",
      "| policy_entropy     | -1.0053685    |\n",
      "| policy_loss        | -0.012666695  |\n",
      "| serial_timesteps   | 99200         |\n",
      "| time_elapsed       | 70.9          |\n",
      "| total_timesteps    | 99200         |\n",
      "| value_loss         | 1.0690801e-05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0030577902  |\n",
      "| clipfrac           | 0.013671875   |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -15.1         |\n",
      "| explained_variance | -0.0936       |\n",
      "| fps                | 1376          |\n",
      "| n_updates          | 776           |\n",
      "| policy_entropy     | -1.0076066    |\n",
      "| policy_loss        | -0.0013305626 |\n",
      "| serial_timesteps   | 99328         |\n",
      "| time_elapsed       | 71            |\n",
      "| total_timesteps    | 99328         |\n",
      "| value_loss         | 2.726927e-06  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0015567594  |\n",
      "| clipfrac           | 0.0078125     |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -15.1         |\n",
      "| explained_variance | -0.0839       |\n",
      "| fps                | 1476          |\n",
      "| n_updates          | 777           |\n",
      "| policy_entropy     | -1.0106107    |\n",
      "| policy_loss        | -0.003962119  |\n",
      "| serial_timesteps   | 99456         |\n",
      "| time_elapsed       | 71.1          |\n",
      "| total_timesteps    | 99456         |\n",
      "| value_loss         | 1.3439691e-05 |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| approxkl           | 3.2413373e-05  |\n",
      "| clipfrac           | 0.0            |\n",
      "| ep_len_mean        | 999            |\n",
      "| ep_reward_mean     | -15.1          |\n",
      "| explained_variance | 0.0521         |\n",
      "| fps                | 1392           |\n",
      "| n_updates          | 778            |\n",
      "| policy_entropy     | -1.0136678     |\n",
      "| policy_loss        | -0.00095491466 |\n",
      "| serial_timesteps   | 99584          |\n",
      "| time_elapsed       | 71.2           |\n",
      "| total_timesteps    | 99584          |\n",
      "| value_loss         | 3.6408208e-06  |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0001293317  |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -15.1         |\n",
      "| explained_variance | 0.33          |\n",
      "| fps                | 1467          |\n",
      "| n_updates          | 779           |\n",
      "| policy_entropy     | -1.0173005    |\n",
      "| policy_loss        | -0.0014703992 |\n",
      "| serial_timesteps   | 99712         |\n",
      "| time_elapsed       | 71.2          |\n",
      "| total_timesteps    | 99712         |\n",
      "| value_loss         | 2.329115e-06  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.0010526144  |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -15.1         |\n",
      "| explained_variance | 0.0424        |\n",
      "| fps                | 1397          |\n",
      "| n_updates          | 780           |\n",
      "| policy_entropy     | -1.0215946    |\n",
      "| policy_loss        | -0.0032798273 |\n",
      "| serial_timesteps   | 99840         |\n",
      "| time_elapsed       | 71.3          |\n",
      "| total_timesteps    | 99840         |\n",
      "| value_loss         | 1.0361636e-05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| approxkl           | 0.00018039113 |\n",
      "| clipfrac           | 0.0           |\n",
      "| ep_len_mean        | 999           |\n",
      "| ep_reward_mean     | -15           |\n",
      "| explained_variance | -0.0778       |\n",
      "| fps                | 1400          |\n",
      "| n_updates          | 781           |\n",
      "| policy_entropy     | -1.0247594    |\n",
      "| policy_loss        | -0.0010744651 |\n",
      "| serial_timesteps   | 99968         |\n",
      "| time_elapsed       | 71.4          |\n",
      "| total_timesteps    | 99968         |\n",
      "| value_loss         | 0.00013643487 |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines.ppo2.ppo2.PPO2 at 0x7fb04b586e48>"
      ]
     },
     "execution_count": 40,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from stable_baselines import PPO2\n",
    "\n",
    "from stable_baselines.common.vec_env import DummyVecEnv\n",
    "from stable_baselines.common.policies import MlpPolicy\n",
    "\n",
    "env = gym.make('MountainCarContinuous-v0')\n",
    "env = Monitor(env, log_dir, allow_early_resets=True)\n",
    "env = DummyVecEnv([lambda: env])\n",
    "\n",
    "modelppo = PPO2(MlpPolicy, env, verbose=1)\n",
    "modelppo.learn(total_timesteps=100000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "c7zR6Sw4Zuqh",
    "outputId": "cc08902c-4df1-41e9-f554-ae5164349453"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "results_plotter.plot_results([log_dir], time_steps, results_plotter.X_TIMESTEPS, \"PPO MountainCar Continuous\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "colab_type": "code",
    "id": "mD650d9jZx0O",
    "outputId": "2065c3c1-d52d-4757-dc0c-a5adee605636"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_results(log_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S8lEGgiBEEDi"
   },
   "source": [
    "### **SAC**\n",
    "SAC was developed by UCBerkeley and Google to solve and achieve benchmark results in manipulation and locomotion tasks in real-world robots. It is a model free algorithm.\n",
    "\n",
    "It has the following Advantages:\n",
    "* Sample Efficiency: \n",
    "The learning is very fast in this algorithm and prototyping desired actions for achieving tasks is faster.\n",
    "* Not sensitive to Hyperparameters \n",
    "It uses Maximum entropy RL to minimise dependence on hyperparameters. This aids adaptation on real world tasks without much tuning\n",
    "* Off - Policy Learning\n",
    " We can reuse data for learning seperate task.This aids us to use past experiences and previously developed policy for other tasks\n",
    "\n",
    "It uses entropy in policy to calculate reward to encourage exploration. \n",
    "It has an actor-critic framework that aids to update policy and value function separately as discussed in previos sections.\n",
    "Using abouve notations this framework utilises equation:\n",
    "$J(θ)=∑_{t=1}^TE_{(s_t,a_t)∼ρπθ}[r(s_t,a_t)+αH(π_θ(.|s_t))]$\n",
    "\n",
    "where $H(.)$ is entropy metric and  α is the measure of importance to entropy metric popularly known as 'temparature' parameter\n",
    "Entropy maximisation leads to more exploration and assigning equal probabilities to actions that are equally good\n",
    "\n",
    "SAC has 3 functions to learn:\n",
    "\n",
    "1) policy  with parameters θ, $\\pi_θ$\n",
    "\n",
    "2) soft Q-value function parameterized by w, $Q_w$.\n",
    "\n",
    "3)Soft state value function parameterized by ψ, $V_ψ$; theoretically we can infer V by knowing Q and π, but in practice, it helps stabilize the training. \n",
    "\n",
    "Soft Q-value and soft state value are defined as:\n",
    "\n",
    "where $Q(s_t,a_t)=r(s_t,a_t)+γE_{s_{t+1}∼ρπ(s)}[V(s_{t+1})]$ -- From Bellman's Equation\n",
    "where\n",
    "$V(s_t)=E_{at∼π}[Q(s_t,a_t)−αlogπ(a_t|s_t)]$; --Soft state value function\n",
    "\n",
    "Thus, $Q(s_t,a_t)=r(s_t,a_t)+γE_{(s_{t+1},a_{t+1})∼ρπ}[Q(s_{t+1},a_{t+1})−αlogπ(a_{t+1}|s_{t+1})]$\n",
    "\n",
    "Here ρπ(s) and ρπ(s,a) denote the state and the state-action marginals of the state distribution induced by the policy π(a|s)\n",
    "\n",
    "The soft state value function is trained to minimize the mean squared error:\n",
    "\n",
    "$J_V(ψ)=E_{s_t∼D}[\\frac{1}{2}(V_ψ(s_t)−E[Q_w(s_t,a_t)−logπ_θ(a_t|s_t)])^2]$\n",
    "\n",
    "with gradient: \n",
    "\n",
    "$∇_ψJ_V(ψ)=∇_ψV_ψ(s_t)(V_ψ(s_t)−Q_w(s_t,a_t)+logπ_θ(a_t|s_t))$\n",
    "\n",
    "\n",
    "where D is the replay buffer.\n",
    "\n",
    "The soft Q function is trained to minimize the soft Bellman residual:\n",
    "\n",
    "$J_Q(w)=E_{(s_t,a_t)∼D}[\\frac{1}{2}(Q_w(s_t,a_t)−(r(s_t,a_t)+γE_{s_{t+1}∼ρπ(s)}[V_ψ^¯(s_{t+1})]))^2]$\n",
    "\n",
    "with gradient:\n",
    "\n",
    " $∇_wJ_Q(w)=∇_wQ_w(s_t,a_t)(Q_w(s_t,a_t)−r(s_t,a_t)−γV_ψ^¯(s_{t+1}))$\n",
    "\n",
    "where ψ¯ is the target value function which is the exponential moving average (or only gets updated periodically in a “hard” way), just like how the parameter of the target Q network is treated in DQN to stabilize the training.\n",
    "\n",
    "SAC updates the policy to minimize the KL-divergence:\n",
    "\n",
    "$ π_{new}= argmin_{π′∈Π}D_{KL}(π′(.|s_t)∥\\frac{exp(Q^{π_old}(s_t,.))}{Z^{π_old}(s_t)})$\n",
    "\n",
    "objective for update: \n",
    "$J_π(θ)=∇_θD_{KL}(π_θ(.|s_t)∥exp(Q_w(s_t,.)−logZ_w(s_t)))$\n",
    "\n",
    "  $= E_{a_t∼π}[−log(\\frac{exp(Q_w(s_t,a_t)−logZ_w(s_t))}{π_θ(a_t|s_t)})]$\n",
    "\n",
    "$  =E_{a_t∼π}[logπ_θ(a_t|s_t)−Q_w(s_t,a_t)+logZ_w(s_t)]\n",
    "$\n",
    "\n",
    "where Π is the set of potential policies that we can model our policy as to keep them tractable; for example, Π can be the family of Gaussian mixture distributions, expensive to model but highly expressive and still tractable.$ Z^{π_{old}}(s_t)$ is the partition function to normalize the distribution. It is usually intractable but does not contribute to the gradient. How to minimize $J_π(θ)$ depends our choice of Π.\n",
    "\n",
    "This update guarantees that $Q^{π_{new}}(s_t,a_t)≥Q^{π_{old}}(s_t,a_t)$\n",
    "\n",
    "Once we have defined the objective functions and gradients for soft action-state value, soft state value and the policy network, the soft actor-critic algorithm is straightforward:\n",
    "\n",
    "\n",
    " **Pseudocode of SAC algorithm:**\n",
    " ![alt text](https://lilianweng.github.io/lil-log/assets/images/SAC_algo.png)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "PwlRztT7KXSL",
    "outputId": "76846ff3-2366-4316-bf15-0f9d8d8d5aa0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| current_lr              | 0.0003        |\n",
      "| ent_coef                | 0.41950208    |\n",
      "| ent_coef_loss           | -1.4529761    |\n",
      "| entropy                 | 1.2387763     |\n",
      "| ep_rewmean              | -33.4         |\n",
      "| episodes                | 4             |\n",
      "| eplenmean               | 999           |\n",
      "| fps                     | 323           |\n",
      "| mean 100 episode reward | -33.4         |\n",
      "| n_updates               | 2897          |\n",
      "| policy_loss             | -5.129809     |\n",
      "| qf1_loss                | 0.00039952318 |\n",
      "| qf2_loss                | 0.0004130964  |\n",
      "| time_elapsed            | 9             |\n",
      "| total timesteps         | 2997          |\n",
      "| value_loss              | 0.00086907635 |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| current_lr              | 0.0003        |\n",
      "| ent_coef                | 0.12695381    |\n",
      "| ent_coef_loss           | -3.40457      |\n",
      "| entropy                 | 1.1151716     |\n",
      "| ep_rewmean              | -32.1         |\n",
      "| episodes                | 8             |\n",
      "| eplenmean               | 999           |\n",
      "| fps                     | 320           |\n",
      "| mean 100 episode reward | -32.1         |\n",
      "| n_updates               | 6893          |\n",
      "| policy_loss             | -6.2765255    |\n",
      "| qf1_loss                | 0.00049445016 |\n",
      "| qf2_loss                | 0.0004541692  |\n",
      "| time_elapsed            | 21            |\n",
      "| total timesteps         | 6993          |\n",
      "| value_loss              | 0.009803535   |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| current_lr              | 0.0003        |\n",
      "| ent_coef                | 0.039298378   |\n",
      "| ent_coef_loss           | -4.776618     |\n",
      "| entropy                 | 0.67387223    |\n",
      "| ep_rewmean              | -29.6         |\n",
      "| episodes                | 12            |\n",
      "| eplenmean               | 999           |\n",
      "| fps                     | 314           |\n",
      "| mean 100 episode reward | -29.6         |\n",
      "| n_updates               | 10889         |\n",
      "| policy_loss             | -5.3109293    |\n",
      "| qf1_loss                | 0.0001790321  |\n",
      "| qf2_loss                | 0.00015520139 |\n",
      "| time_elapsed            | 34            |\n",
      "| total timesteps         | 10989         |\n",
      "| value_loss              | 0.00058443286 |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| current_lr              | 0.0003        |\n",
      "| ent_coef                | 0.0129823955  |\n",
      "| ent_coef_loss           | -3.9031177    |\n",
      "| entropy                 | 0.018417276   |\n",
      "| ep_rewmean              | -24.9         |\n",
      "| episodes                | 16            |\n",
      "| eplenmean               | 999           |\n",
      "| fps                     | 314           |\n",
      "| mean 100 episode reward | -24.9         |\n",
      "| n_updates               | 14885         |\n",
      "| policy_loss             | -4.083563     |\n",
      "| qf1_loss                | 0.00021699828 |\n",
      "| qf2_loss                | 0.00020183605 |\n",
      "| time_elapsed            | 47            |\n",
      "| total timesteps         | 14985         |\n",
      "| value_loss              | 0.00049489073 |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| current_lr              | 0.0003        |\n",
      "| ent_coef                | 0.0051142434  |\n",
      "| ent_coef_loss           | -2.5940995    |\n",
      "| entropy                 | -0.5507101    |\n",
      "| ep_rewmean              | -20.5         |\n",
      "| episodes                | 20            |\n",
      "| eplenmean               | 999           |\n",
      "| fps                     | 315           |\n",
      "| mean 100 episode reward | -20.5         |\n",
      "| n_updates               | 18881         |\n",
      "| policy_loss             | -3.1642041    |\n",
      "| qf1_loss                | 0.00017732129 |\n",
      "| qf2_loss                | 0.00019686949 |\n",
      "| time_elapsed            | 60            |\n",
      "| total timesteps         | 18981         |\n",
      "| value_loss              | 5.1842107e-05 |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| current_lr              | 0.0003       |\n",
      "| ent_coef                | 0.0031348637 |\n",
      "| ent_coef_loss           | -0.25462168  |\n",
      "| entropy                 | -1.0011445   |\n",
      "| ep_rewmean              | -17.3        |\n",
      "| episodes                | 24           |\n",
      "| eplenmean               | 999          |\n",
      "| fps                     | 316          |\n",
      "| mean 100 episode reward | -17.3        |\n",
      "| n_updates               | 22877        |\n",
      "| policy_loss             | -2.5523882   |\n",
      "| qf1_loss                | 9.958176e-05 |\n",
      "| qf2_loss                | 8.169655e-05 |\n",
      "| time_elapsed            | 72           |\n",
      "| total timesteps         | 22977        |\n",
      "| value_loss              | 8.200086e-05 |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| current_lr              | 0.0003        |\n",
      "| ent_coef                | 0.0021861542  |\n",
      "| ent_coef_loss           | -1.2050161    |\n",
      "| entropy                 | -0.90153366   |\n",
      "| ep_rewmean              | -14.9         |\n",
      "| episodes                | 28            |\n",
      "| eplenmean               | 999           |\n",
      "| fps                     | 317           |\n",
      "| mean 100 episode reward | -14.9         |\n",
      "| n_updates               | 26873         |\n",
      "| policy_loss             | -1.9587526    |\n",
      "| qf1_loss                | 5.0386698e-06 |\n",
      "| qf2_loss                | 5.239408e-06  |\n",
      "| time_elapsed            | 85            |\n",
      "| total timesteps         | 26973         |\n",
      "| value_loss              | 6.769089e-05  |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| current_lr              | 0.0003        |\n",
      "| ent_coef                | 0.0019345345  |\n",
      "| ent_coef_loss           | -1.4701477    |\n",
      "| entropy                 | -0.85854983   |\n",
      "| ep_rewmean              | -13.1         |\n",
      "| episodes                | 32            |\n",
      "| eplenmean               | 999           |\n",
      "| fps                     | 317           |\n",
      "| mean 100 episode reward | -13.1         |\n",
      "| n_updates               | 30869         |\n",
      "| policy_loss             | -1.4985337    |\n",
      "| qf1_loss                | 1.860414e-05  |\n",
      "| qf2_loss                | 1.2920567e-05 |\n",
      "| time_elapsed            | 97            |\n",
      "| total timesteps         | 30969         |\n",
      "| value_loss              | 8.9458925e-05 |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| current_lr              | 0.0003        |\n",
      "| ent_coef                | 0.0019558342  |\n",
      "| ent_coef_loss           | -0.6024945    |\n",
      "| entropy                 | -0.9123299    |\n",
      "| ep_rewmean              | -11.7         |\n",
      "| episodes                | 36            |\n",
      "| eplenmean               | 999           |\n",
      "| fps                     | 317           |\n",
      "| mean 100 episode reward | -11.7         |\n",
      "| n_updates               | 34865         |\n",
      "| policy_loss             | -1.1284432    |\n",
      "| qf1_loss                | 6.583182e-05  |\n",
      "| qf2_loss                | 7.9659134e-05 |\n",
      "| time_elapsed            | 110           |\n",
      "| total timesteps         | 34965         |\n",
      "| value_loss              | 1.34814e-05   |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| current_lr              | 0.0003        |\n",
      "| ent_coef                | 0.0015583986  |\n",
      "| ent_coef_loss           | -0.66627884   |\n",
      "| entropy                 | -0.88579226   |\n",
      "| ep_rewmean              | -10.6         |\n",
      "| episodes                | 40            |\n",
      "| eplenmean               | 999           |\n",
      "| fps                     | 318           |\n",
      "| mean 100 episode reward | -10.6         |\n",
      "| n_updates               | 38861         |\n",
      "| policy_loss             | -0.8450286    |\n",
      "| qf1_loss                | 3.9066135e-06 |\n",
      "| qf2_loss                | 5.155359e-06  |\n",
      "| time_elapsed            | 122           |\n",
      "| total timesteps         | 38961         |\n",
      "| value_loss              | 6.0115362e-06 |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| current_lr              | 0.0003        |\n",
      "| ent_coef                | 0.0016534299  |\n",
      "| ent_coef_loss           | 0.11967403    |\n",
      "| entropy                 | -0.9183296    |\n",
      "| ep_rewmean              | -9.72         |\n",
      "| episodes                | 44            |\n",
      "| eplenmean               | 999           |\n",
      "| fps                     | 318           |\n",
      "| mean 100 episode reward | -9.7          |\n",
      "| n_updates               | 42857         |\n",
      "| policy_loss             | -0.6316979    |\n",
      "| qf1_loss                | 2.8502113e-06 |\n",
      "| qf2_loss                | 5.0056087e-06 |\n",
      "| time_elapsed            | 134           |\n",
      "| total timesteps         | 42957         |\n",
      "| value_loss              | 2.8613977e-06 |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| current_lr              | 0.0003        |\n",
      "| ent_coef                | 0.0014262247  |\n",
      "| ent_coef_loss           | 0.40893513    |\n",
      "| entropy                 | -0.9941643    |\n",
      "| ep_rewmean              | -8.98         |\n",
      "| episodes                | 48            |\n",
      "| eplenmean               | 999           |\n",
      "| fps                     | 318           |\n",
      "| mean 100 episode reward | -9            |\n",
      "| n_updates               | 46853         |\n",
      "| policy_loss             | -0.44546187   |\n",
      "| qf1_loss                | 1.992909e-06  |\n",
      "| qf2_loss                | 1.7210234e-06 |\n",
      "| time_elapsed            | 147           |\n",
      "| total timesteps         | 46953         |\n",
      "| value_loss              | 2.9458913e-06 |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| current_lr              | 0.0003        |\n",
      "| ent_coef                | 0.0015088752  |\n",
      "| ent_coef_loss           | 0.15787686    |\n",
      "| entropy                 | -0.9980421    |\n",
      "| ep_rewmean              | -8.35         |\n",
      "| episodes                | 52            |\n",
      "| eplenmean               | 999           |\n",
      "| fps                     | 318           |\n",
      "| mean 100 episode reward | -8.3          |\n",
      "| n_updates               | 50849         |\n",
      "| policy_loss             | -0.30713636   |\n",
      "| qf1_loss                | 7.332309e-06  |\n",
      "| qf2_loss                | 1.4332489e-05 |\n",
      "| time_elapsed            | 159           |\n",
      "| total timesteps         | 50949         |\n",
      "| value_loss              | 8.958499e-06  |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| current_lr              | 0.0003        |\n",
      "| ent_coef                | 0.0015259881  |\n",
      "| ent_coef_loss           | 0.040730864   |\n",
      "| entropy                 | -0.98294216   |\n",
      "| ep_rewmean              | -7.81         |\n",
      "| episodes                | 56            |\n",
      "| eplenmean               | 999           |\n",
      "| fps                     | 318           |\n",
      "| mean 100 episode reward | -7.8          |\n",
      "| n_updates               | 54845         |\n",
      "| policy_loss             | -0.19014211   |\n",
      "| qf1_loss                | 1.8961855e-06 |\n",
      "| qf2_loss                | 1.288241e-06  |\n",
      "| time_elapsed            | 172           |\n",
      "| total timesteps         | 54945         |\n",
      "| value_loss              | 1.931295e-06  |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| current_lr              | 0.0003        |\n",
      "| ent_coef                | 0.0015710384  |\n",
      "| ent_coef_loss           | 0.7870765     |\n",
      "| entropy                 | -0.99248004   |\n",
      "| ep_rewmean              | -7.34         |\n",
      "| episodes                | 60            |\n",
      "| eplenmean               | 999           |\n",
      "| fps                     | 318           |\n",
      "| mean 100 episode reward | -7.3          |\n",
      "| n_updates               | 58841         |\n",
      "| policy_loss             | -0.0985634    |\n",
      "| qf1_loss                | 9.677075e-08  |\n",
      "| qf2_loss                | 2.217967e-07  |\n",
      "| time_elapsed            | 185           |\n",
      "| total timesteps         | 58941         |\n",
      "| value_loss              | 1.0260549e-06 |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| current_lr              | 0.0003        |\n",
      "| ent_coef                | 0.0015803793  |\n",
      "| ent_coef_loss           | -2.378304     |\n",
      "| entropy                 | -0.9976729    |\n",
      "| ep_rewmean              | -6.92         |\n",
      "| episodes                | 64            |\n",
      "| eplenmean               | 999           |\n",
      "| fps                     | 318           |\n",
      "| mean 100 episode reward | -6.9          |\n",
      "| n_updates               | 62837         |\n",
      "| policy_loss             | -0.029286502  |\n",
      "| qf1_loss                | 1.0724913e-06 |\n",
      "| qf2_loss                | 5.3052156e-07 |\n",
      "| time_elapsed            | 197           |\n",
      "| total timesteps         | 62937         |\n",
      "| value_loss              | 6.604908e-06  |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| current_lr              | 0.0003        |\n",
      "| ent_coef                | 0.0015716618  |\n",
      "| ent_coef_loss           | -0.06988212   |\n",
      "| entropy                 | -0.9312438    |\n",
      "| ep_rewmean              | -6.56         |\n",
      "| episodes                | 68            |\n",
      "| eplenmean               | 999           |\n",
      "| fps                     | 318           |\n",
      "| mean 100 episode reward | -6.6          |\n",
      "| n_updates               | 66833         |\n",
      "| policy_loss             | 0.028252982   |\n",
      "| qf1_loss                | 1.4184609e-07 |\n",
      "| qf2_loss                | 1.8125586e-07 |\n",
      "| time_elapsed            | 209           |\n",
      "| total timesteps         | 66933         |\n",
      "| value_loss              | 1.1113892e-06 |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| current_lr              | 0.0003        |\n",
      "| ent_coef                | 0.0015375261  |\n",
      "| ent_coef_loss           | -0.7928102    |\n",
      "| entropy                 | -1.0042053    |\n",
      "| ep_rewmean              | -6.23         |\n",
      "| episodes                | 72            |\n",
      "| eplenmean               | 999           |\n",
      "| fps                     | 318           |\n",
      "| mean 100 episode reward | -6.2          |\n",
      "| n_updates               | 70829         |\n",
      "| policy_loss             | 0.075808704   |\n",
      "| qf1_loss                | 7.3660664e-07 |\n",
      "| qf2_loss                | 1.2053847e-06 |\n",
      "| time_elapsed            | 222           |\n",
      "| total timesteps         | 70929         |\n",
      "| value_loss              | 3.0690733e-06 |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| current_lr              | 0.0003        |\n",
      "| ent_coef                | 0.0015451758  |\n",
      "| ent_coef_loss           | -0.21481046   |\n",
      "| entropy                 | -0.9681363    |\n",
      "| ep_rewmean              | -5.94         |\n",
      "| episodes                | 76            |\n",
      "| eplenmean               | 999           |\n",
      "| fps                     | 318           |\n",
      "| mean 100 episode reward | -5.9          |\n",
      "| n_updates               | 74825         |\n",
      "| policy_loss             | 0.110379785   |\n",
      "| qf1_loss                | 1.6104029e-07 |\n",
      "| qf2_loss                | 8.9595426e-07 |\n",
      "| time_elapsed            | 234           |\n",
      "| total timesteps         | 74925         |\n",
      "| value_loss              | 6.4060546e-06 |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| current_lr              | 0.0003        |\n",
      "| ent_coef                | 0.0015485747  |\n",
      "| ent_coef_loss           | -0.34756288   |\n",
      "| entropy                 | -1.0161302    |\n",
      "| ep_rewmean              | -5.68         |\n",
      "| episodes                | 80            |\n",
      "| eplenmean               | 999           |\n",
      "| fps                     | 319           |\n",
      "| mean 100 episode reward | -5.7          |\n",
      "| n_updates               | 78821         |\n",
      "| policy_loss             | 0.14285251    |\n",
      "| qf1_loss                | 2.5785639e-07 |\n",
      "| qf2_loss                | 1.1007969e-05 |\n",
      "| time_elapsed            | 247           |\n",
      "| total timesteps         | 78921         |\n",
      "| value_loss              | 2.6747164e-06 |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| current_lr              | 0.0003        |\n",
      "| ent_coef                | 0.001537994   |\n",
      "| ent_coef_loss           | -0.42060035   |\n",
      "| entropy                 | -0.9313302    |\n",
      "| ep_rewmean              | -5.45         |\n",
      "| episodes                | 84            |\n",
      "| eplenmean               | 999           |\n",
      "| fps                     | 319           |\n",
      "| mean 100 episode reward | -5.4          |\n",
      "| n_updates               | 82817         |\n",
      "| policy_loss             | 0.16861458    |\n",
      "| qf1_loss                | 2.13518e-07   |\n",
      "| qf2_loss                | 1.1312575e-07 |\n",
      "| time_elapsed            | 259           |\n",
      "| total timesteps         | 82917         |\n",
      "| value_loss              | 2.0577231e-06 |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| current_lr              | 0.0003        |\n",
      "| ent_coef                | 0.0014562587  |\n",
      "| ent_coef_loss           | 0.10360202    |\n",
      "| entropy                 | -1.0238681    |\n",
      "| ep_rewmean              | -5.23         |\n",
      "| episodes                | 88            |\n",
      "| eplenmean               | 999           |\n",
      "| fps                     | 318           |\n",
      "| mean 100 episode reward | -5.2          |\n",
      "| n_updates               | 86813         |\n",
      "| policy_loss             | 0.19118893    |\n",
      "| qf1_loss                | 1.6900963e-06 |\n",
      "| qf2_loss                | 3.6855233e-06 |\n",
      "| time_elapsed            | 272           |\n",
      "| total timesteps         | 86913         |\n",
      "| value_loss              | 1.5515343e-06 |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| current_lr              | 0.0003        |\n",
      "| ent_coef                | 0.0015547861  |\n",
      "| ent_coef_loss           | 0.25289816    |\n",
      "| entropy                 | -1.0151391    |\n",
      "| ep_rewmean              | -5.04         |\n",
      "| episodes                | 92            |\n",
      "| eplenmean               | 999           |\n",
      "| fps                     | 319           |\n",
      "| mean 100 episode reward | -5            |\n",
      "| n_updates               | 90809         |\n",
      "| policy_loss             | 0.20565279    |\n",
      "| qf1_loss                | 3.7518402e-07 |\n",
      "| qf2_loss                | 3.9262454e-07 |\n",
      "| time_elapsed            | 284           |\n",
      "| total timesteps         | 90909         |\n",
      "| value_loss              | 2.125228e-06  |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| current_lr              | 0.0003        |\n",
      "| ent_coef                | 0.0014278089  |\n",
      "| ent_coef_loss           | -1.1675869    |\n",
      "| entropy                 | -0.8850742    |\n",
      "| ep_rewmean              | -4.86         |\n",
      "| episodes                | 96            |\n",
      "| eplenmean               | 999           |\n",
      "| fps                     | 319           |\n",
      "| mean 100 episode reward | -4.9          |\n",
      "| n_updates               | 94805         |\n",
      "| policy_loss             | 0.2187327     |\n",
      "| qf1_loss                | 2.8838807e-07 |\n",
      "| qf2_loss                | 2.1727612e-06 |\n",
      "| time_elapsed            | 297           |\n",
      "| total timesteps         | 94905         |\n",
      "| value_loss              | 2.7373835e-06 |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| current_lr              | 0.0003        |\n",
      "| ent_coef                | 0.0014980392  |\n",
      "| ent_coef_loss           | -0.037341207  |\n",
      "| entropy                 | -0.9790725    |\n",
      "| ep_rewmean              | -4.7          |\n",
      "| episodes                | 100           |\n",
      "| eplenmean               | 999           |\n",
      "| fps                     | 319           |\n",
      "| mean 100 episode reward | -4.7          |\n",
      "| n_updates               | 98801         |\n",
      "| policy_loss             | 0.22575101    |\n",
      "| qf1_loss                | 4.419196e-06  |\n",
      "| qf2_loss                | 6.723465e-08  |\n",
      "| time_elapsed            | 309           |\n",
      "| total timesteps         | 98901         |\n",
      "| value_loss              | 1.3330216e-06 |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines.sac.sac.SAC at 0x7fb049cf9390>"
      ]
     },
     "execution_count": 43,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from stable_baselines import SAC\n",
    "\n",
    "from stable_baselines.common.vec_env import DummyVecEnv\n",
    "from stable_baselines.sac.policies import  MlpPolicy \n",
    "\n",
    "env = gym.make('MountainCarContinuous-v0')\n",
    "env = Monitor(env, log_dir, allow_early_resets=True)\n",
    "env = DummyVecEnv([lambda: env])\n",
    "\n",
    "modelsac = SAC(MlpPolicy, env, verbose=1)\n",
    "modelsac.learn(total_timesteps=100000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "iF3ishGtfsnv",
    "outputId": "48a29b0b-fae4-429e-82b8-406807979244"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_plotter.plot_results([log_dir], time_steps, results_plotter.X_TIMESTEPS, \"SAC MountainCar Continuous\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "colab_type": "code",
    "id": "2sMmv2Gwf1xk",
    "outputId": "f1b6adb7-1561-42e7-87a6-57163d120dc2"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_results(log_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o9E5JuWMvuR_"
   },
   "source": [
    "### **INFERENCE:**\n",
    "\n",
    "We see that the DDPG does reach goal state around 180000 timestep versus PPO that reaches goal state at 62000 timestep versus SAC that reaches goal state in 70000 time step. The Learning rate in PPO is very gradual suggesting its carefullness. SAC however has quick learning time  and hence can be used for more real world applications as explained from our discussion above analysing these algorithms.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HNV9Tj-QJNox"
   },
   "source": [
    "### **QUIZ:** \n",
    "\n",
    "State true/False:\n",
    "\n",
    "1. SAC is a on-policy based RL algorithm\n",
    "\n",
    "    A.  False. It is Off Policy algorithm that uses past experience knowledge from previous experiences of another policy\n",
    "    \n",
    "\n",
    "2.  PPO is sensitive to hyperparameters such as heuristic values used in surrogate loss function?\n",
    "\n",
    "    A. False \n",
    "    \n",
    "\n",
    "3.  Q-learning can learn the optimal Q-function Q∗ without ever executing the optimal policy.\n",
    "\n",
    "    A. True. It arrives at optimal policy by updating Q table using TD like algorithms\n",
    "\n",
    "\n",
    "4. Off-policy algorithms can learn from data without interacting with the environment\n",
    "\n",
    "    A. True. They can update target policy by using experience of any other behaviour policy\n",
    "    \n",
    "\n",
    "5. DDPG is a purely off policy algorithm\n",
    "  \n",
    "    A. False. DDPG uses behavioral policy that is acquired from adding noise to actions achieved from target policy hence behavioral policy is not decorrelated from target policy.\n",
    "    \n",
    "  \n",
    "6. There are  2 states and 1 action in  MountainCarContinuous-v0 agent .\n",
    "\n",
    "    A.  True but these have Continuous values in ranges specified above.\n",
    "\n",
    "\n",
    "7. SAC is a Model Based Reinforcement Learning Algorithm\n",
    "\n",
    "    A. False\n",
    "    \n",
    "  \n",
    "8. TRPO with penalties on large policy updates and surrogate loss gradual optimisation are primary ideas of PPO\n",
    "\n",
    "    A. True\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XAzrSIzHK3VX"
   },
   "source": [
    "### REFERENCES:\n",
    "1)https://towardsdatascience.com/an-intuitive-explanation-of-policy-gradient-part-1-reinforce-aa4392cbfd3c\n",
    "\n",
    "2) https://towardsdatascience.com/reinforcement-learning-with-hindsight-experience-replay-1fee5704f2f8\n",
    "\n",
    "3)https://towardsdatascience.com/policy-gradients-in-a-nutshell-8b72f9743c5d\n",
    "\n",
    "4) Sutton, R. S. and Barto, A. G. (1998). Introduction to Reinforcement Learning. MIT Press, Cambridge, MA, USA, 1st edition.\n",
    "\n",
    "5)Silver, D., Lever, G., Heess, N., Degris, T., Wierstra, D., and Riedmiller, M. (2014). Deterministic policy gradient algorithms. In Xing, E. P. and Jebara, T., editors, Proceedings of the 31st International Conference on Machine Learning, volume 32 of Proceedings of Machine Learning Research, pages 387–395, Bejing, China. PMLR.\n",
    "6) Timothy P. Lillicrap, Jonathan J. Hunt, Alexander Pritzel, Nicolas Heess, Tom Erez, Yuval Tassa, David Silver, and Daan Wierstra, Continuous control with deep reinforcement learning, CoRR abs/1509.02971 (2015).\n",
    "\n",
    "7) [Edouard Leurent’s answer to Quora post “Why do we use the Ornstein Uhlenbeck Process in the exploration of DDPG?” ](https://qr.ae/TW8NAa)\n",
    "\n",
    "8)https://towardsdatascience.com/deep-deterministic-policy-gradients-explained-2d94655a9b7b\n",
    "\n",
    "9)Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor. Haarnoja et al. (2018)\n",
    "10)Soft Actor-Critic Algorithms and Applications. Haarnoja et al. (2019)\n",
    "\n",
    "11)https://www.youtube.com/watch?v=xvRrgxcpaHY&t=363s\n",
    "\n",
    "12) https://medium.com/@sanketgujar95/trust-region-policy-optimization-trpo-and-proximal-policy-optimization-ppo-e6e7075f39ed\n",
    "\n",
    "13) Schulman, J.; Wolski, F.; Dhariwal, P.; Radford, A.; and Klimov,\n",
    "O. 2017. Proximal policy optimization algorithms. arXiv preprint\n",
    "arXiv:1707.06347.\n",
    "\n",
    "14)https://mc.ai/rl-the-math-behind-trpo-ppo/\n",
    "\n",
    "15) https://stable-baselines.readthedocs.io/en/master/\n",
    "\n",
    "16) https://github.com/openai/gym/wiki/MountainCarContinuous-v0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VfZ7fFsLhkl4"
   },
   "source": [
    "\n",
    "### **LICENSE**\n",
    "\n",
    "#### **CREATIVE LICENSE**\n",
    "\n",
    "License terms can be found [here](https://creativecommons.org/licenses/by/4.0/legalcode).\n",
    "\n",
    "#### **SOFTWARE LICENSE**\n",
    "\n",
    "MIT License\n",
    "\n",
    "Copyright (c) 2020 Suprita Ganesh\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "of this software and associated documentation files (the \"Software\"), to deal\n",
    "in the Software without restriction, including without limitation the rights\n",
    "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "copies of the Software, and to permit persons to whom the Software is\n",
    "furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all\n",
    "copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "SOFTWARE.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "PORTFOLIO AUTONOMOUS LEARNING IN GAMES.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
